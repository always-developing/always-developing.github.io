[{"content":"Daily Knowledge Drop Usually braces {} are uses to define the scope of a specific statement (method, if statement, for loop etc) - but braces can also be used to define a scope without specifying a statement\n Example Below is a simple code snippet to demonstrate the scopes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  var outerVariable = 1; if(outerVariable == 1) { var innerVariable = 100; Console.WriteLine($\u0026#34;In the if statement, innerVariable: {innerVariable}\u0026#34;); } { //var outerVariable = 2; NOT allowed var innerVariable = 101; Console.WriteLine($\u0026#34;In scoped statement, innerVariable: {innerVariable}\u0026#34;); } //inIfVariable = 102; NOT allowed Console.WriteLine($\u0026#34;In the main scope, outerVariable: {outerVariable}\u0026#34;);    Line 1: a variable, outerVariable, is instantiated in the main outer scope Line 3-7: an if statement is used, which creates its own scope Line 5: a variable, innerVariable, is instantiated within the scope of the if statement Line 9-13: a scope is created with the use of braces and no specific statement Line 10: a variable, outerVariable cannot be declared here, as a variable of the same name is already declared in the outer scope Line 11: a variable, innerVariable (same name as used on line 5), is instantiated within the scope Line 15: the variable, innerVariable cannot be used here, as the visibility of this variable is confined to the scope in which it was created   Notes While not encouraging the reusing of variables names in the same scope, if it is required, braces can be used to create smaller scopes. This will limit the visibility of variables so that they can be reused within multiple smaller scopes.\nHowever this should not be abused, as it can make the code harder to read - often it is a better idea to declare a variable to share across all scopes (i.e a method), or convert a smaller scope into its own method.\n References Five C# Features You Might Not Know\n     Daily Drop 51: 13-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-13T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/13-scope-braces/","title":"Creating scopes with braces"},{"content":"Daily Knowledge Drop The C# ConcurrentDictionary implementation has a convenient AddOrUpdate method (unlike the Dictionary implementation) - this method allows for a value to try be added to the concurrent dictionary and if the key already exists, then update with a different value.\n Dictionary updates First we\u0026rsquo;ll take a look at how to handle updates when using a Dictionary.\nFirst, a Dictionary\u0026lt;string, int\u0026gt; is instantiated and a few items are added to the dictionary.\n1 2 3 4 5 6 7 8 9 10  var dict = new Dictionary\u0026lt;string, int\u0026gt;(); dict.Add(\u0026#34;zero\u0026#34;, 0); dict.Add(\u0026#34;one\u0026#34;, 1); dict.Add(\u0026#34;two\u0026#34;, 22); dict.Add(\u0026#34;three\u0026#34;, 3); dict.Add(\u0026#34;four\u0026#34;, 4); // This would result in an exception // dict.Add(\u0026#34;two\u0026#34;, 2);   If a duplicate key is used when adding, an exception will be thrown. To cater for this scenario, when adding its best to first check if the dictionary already contains the key, or to use the TryAdd method:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // Check if the dictionary contains the key // if not, then add the item if (!dict.ContainsKey(\u0026#34;two\u0026#34;)) { dict.Add(\u0026#34;two\u0026#34;, 2); } // Tries to add the item with a key // if this fails, then the key exists // and perform an update instead if (!dict.TryAdd(\u0026#34;2\u0026#34;, 2)) { dict[\u0026#34;two\u0026#34;] = 2; }    ConcurrentDictionary updates The ConcurrentDictionary operates similarly to that of a Dictionary (but is not the same, and has both positive and negative aspects when compared with the Dictionary), but has a useful AddOrUpdate method.\nFirst, a ConcurrentDictionary\u0026lt;string, int\u0026gt; is instantiated and a few items are added to the dictionary. The ConcurrentDictionary does not have an Add method, only a TryAdd:\n1 2 3 4 5 6  var conDict = new ConcurrentDictionary\u0026lt;string, int\u0026gt;(); conDict.TryAdd(\u0026#34;zero\u0026#34;, 0); conDict.TryAdd(\u0026#34;one\u0026#34;, 1); conDict.TryAdd(\u0026#34;two\u0026#34;, 22); conDict.TryAdd(\u0026#34;three\u0026#34;, 3); conDict.TryAdd(\u0026#34;four\u0026#34;, 4);   The two methods described above to check if the key already exists, can also be used with the ConcurrentDictionary, but now there is also a AddOrUpdate method available:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // Check if the ConcurrentDictionary contains the key // if not, then add the item if (!conDict.TryAdd(\u0026#34;2\u0026#34;, 2)) { conDict[\u0026#34;two\u0026#34;] = 2; } // Tries to add the item with a key // if this fails, then the key exists // and perform an update instead if (!conDict.ContainsKey(\u0026#34;two\u0026#34;)) { conDict.TryAdd(\u0026#34;two\u0026#34;, 2); } // Add the key \u0026#34;two\u0026#34; with a value of 2 // if it already exists, then take the old value and multiple by 2 conDict.AddOrUpdate(\u0026#34;two\u0026#34;, 2, (key, existingValue) =\u0026gt; existingValue * 2);   The AddOrUpdate method simplifies the code - the method tries to add the key and value, but if the key already exists, then the third parameter Func is called. In this case, the Func multiples the existing value by 2 (and updates the dictionary to now contain the value)\n Notes The main benefit of the ConcurrentDictionary over the Dictionary is that the ConcurrentDictionary is thread safe - it can be accessed by multiple threads without running into issues with values being updated at the same time by multiple threads. However, this additional functionality comes with a performance cost.\nIf needing to convert code from a Dictionary to a ConcurrentDictionary (perhaps because the system has now become multi-threaded), it can be an almost straight convert - however there is additional methods available on ConcurrentDictionary (such as AddOrUpdate), which could be leveraged to simplify the code.\n References ConcurrentDictionary\u0026lt;TKey,TValue\u0026gt; Class\n     Daily Drop 50: 12-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-12T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/12-addorupdate/","title":"ConcurrentDictionary AddOrUpdate method"},{"content":"Daily Knowledge Drop C# 11 (being released towards the end of 2022 with.NET7) is introducing the new list pattern which allows for matching against lists and arrays.\nOne can also match to zero or more elements (which can then be captured or discarded) in the list pattern, using the new slice pattern, two single dots (..)\nThe below examples are using C# 11 preview 2, so may change by final release.\n Pattern matching The list matching allows for pattern matching on an array or list.\nSee the below switch expression performing list matching:\n1 2 3 4 5 6 7 8 9 10 11 12  static string CheckSwitch(char[] values) =\u0026gt; values switch { [\u0026#39;0\u0026#39;, ..] =\u0026gt; \u0026#34;\u0026lt;1\u0026#34;, [\u0026#39;1\u0026#39;, \u0026#39;,\u0026#39;,..] =\u0026gt; \u0026#34;\u0026gt;=1 \u0026amp;\u0026amp; \u0026lt;2\u0026#34;, [\u0026#39;2\u0026#39;, \u0026#39;5\u0026#39;] =\u0026gt; \u0026#34;25\u0026#34;, [\u0026#39;7\u0026#39;, _ ] =\u0026gt; \u0026#34;starting with 7. Length 2\u0026#34;, [\u0026#39;7\u0026#39;, .. ] =\u0026gt; \u0026#34;starting with 7. Length \u0026gt;2\u0026#34;, [.., \u0026#39;9\u0026#39;] =\u0026gt; \u0026#34;ending with 9\u0026#34;, [\u0026#39;5\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;,\u0026#39;, .., \u0026#39;6\u0026#39;] =\u0026gt; \u0026#34; \u0026gt;500 \u0026amp;\u0026amp; \u0026lt;500.1 \u0026amp;\u0026amp; ends in 6\u0026#34;, [..] =\u0026gt; \u0026#34;unclassified\u0026#34; };    Line 4: The array starts with \u0026lsquo;0\u0026rsquo; then has zero or more elements (using the slice pattern syntax) Line 5: The array starts with \u0026lsquo;1\u0026rsquo; then the decimal point, followed by zero or more elements Line 6: The array starts with \u0026lsquo;2\u0026rsquo; and is followed by a \u0026lsquo;5\u0026rsquo; Line 7: The array starts with \u0026lsquo;7\u0026rsquo; and is followed by one element Line 8: The array starts with \u0026lsquo;7\u0026rsquo; and is followed by zero or more elements Line 9: The array is of any length, but ends with \u0026lsquo;9\u0026rsquo; Line 10: The array starts with the 4 characters \u0026lsquo;5\u0026rsquo;, \u0026lsquo;0\u0026rsquo;, \u0026lsquo;0\u0026rsquo; and the decimal point, followed by zero or more elements, and then ending in a \u0026lsquo;6\u0026rsquo; Line 11: The array pattern is not any of the above  As you can see, the slice pattern can be used as a \u0026ldquo;wild card\u0026rdquo; match for zero or more elements.\nThe above switch expression being used:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  char[] arr1 = { \u0026#39;0\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;1\u0026#39;, }; char[] arr2 = { \u0026#39;1\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;9\u0026#39; }; char[] arr3 = { \u0026#39;2\u0026#39;, \u0026#39;5\u0026#39;}; char[] arr4 = { \u0026#39;7\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;1\u0026#39; }; char[] arr5 = { \u0026#39;7\u0026#39;, \u0026#39;1\u0026#39; }; char[] arr6 = { \u0026#39;1\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;9\u0026#39; }; char[] arr7 = { \u0026#39;0\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;9\u0026#39; }; char[] arr8 = { \u0026#39;5\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;1\u0026#39; , \u0026#39;6\u0026#39; }; char[] arr9 = { \u0026#39;3\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;4\u0026#39; }; Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr1) } is {CheckSwitch(arr1)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr2) } is {CheckSwitch(arr2)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr3) } is {CheckSwitch(arr3)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr4) } is {CheckSwitch(arr4)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr5) } is {CheckSwitch(arr5)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr6) } is {CheckSwitch(arr6)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr7) } is {CheckSwitch(arr7)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr8) } is {CheckSwitch(arr8)}\u0026#34;); Console.WriteLine($\u0026#34;{ string.Join(\u0026#34;\u0026#34;, arr9) } is {CheckSwitch(arr9)}\u0026#34;);   Results in the following:\n1 2 3 4 5 6 7 8 9  0,1 is \u0026lt;1 1,29 is \u0026gt;=1 \u0026amp;\u0026amp; \u0026lt;2 25 is 25 70,481 is starting with 7. Length \u0026gt;2 71 is starting with 7. Length 2 109 is ending with 9 009 is \u0026lt;1 500,5316 is \u0026gt;500 \u0026amp;\u0026amp; \u0026lt;500.1 \u0026amp;\u0026amp; ends in 6 3,14 is unclassified   The switch expression matches from the top down. For example, \u0026lsquo;109\u0026rsquo; and \u0026lsquo;009\u0026rsquo; both end in \u0026lsquo;9\u0026rsquo;, however only \u0026lsquo;109\u0026rsquo; is classified as \u0026rsquo;ending with 9\u0026rsquo;. This is because the \u0026lsquo;009\u0026rsquo; is classified as \u0026lsquo;\u0026lt;0\u0026rsquo; which is the first match to be made, before the \u0026rsquo;ending in 9\u0026rsquo; check is performed.\n Capturing elements The slice pattern can also be used to capture, and then access the elements which were matched.\nIn the below example the list pattern matching is used to check if the list conform to a certain pattern - but the elements matched using the slice pattern are then captured in the digits variable:\n1 2 3 4 5 6 7  char[] arr10 = { \u0026#39;5\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;,\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;6\u0026#39; }; if (arr10 is [\u0026#39;5\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;,\u0026#39;, .. var digits, \u0026#39;6\u0026#39;]) { Console.WriteLine($\u0026#34;The full value is: { string.Join(\u0026#34;\u0026#34;, arr10) }\u0026#34;); Console.WriteLine($\u0026#34;The wildcard digits are: { string.Join(\u0026#34;\u0026#34;, digits) }\u0026#34;); }   The output:\n1 2  The full value is: 500,5316 The wildcard digits are: 531    References C# 11 Preview: List patterns\n     Daily Drop 49: 11-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-11T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/11-slice-pattern/","title":"Exploring the new list pattern"},{"content":"Daily Knowledge Drop Readonly variables on a class can be set, not only in the constructor, but also using the init keyword.\n Before init Prior to the introduction of the init keyword in C#9, if a class had a readonly variable, its value had to be set either:\n when declared in the constructor of the class  Consider the following class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class Song { // if not explicitly set, this variable will have  // default int value public readonly int Id; // explicitly set the value public readonly DateTime DateCreated = DateTime.Now; public string Name { get; set; } // set the value in the constructor public Song() { Id = 0; } // set both values in the constructor public Song(int id, string name) { Id = id; Name = name; } }    Line 8: The readonly DateCreated field is explicitly when declared Line 15 \u0026amp; Line 21: The readonly Id field is set in the constructor  When using an instance, as expected, the value cannot be set:\n1 2  var song = new Song(); //song.Id = 100; \u0026lt;\u0026lt; This results in an error   The issue with this, is that if you want to set the value of Id, you cannot use the object initialization format. The only way to set the value is using the constructor\n1 2 3 4 5 6 7 8  var song2 = new Song { Name = \u0026#34;Song2\u0026#34; // Id =.. \u0026lt;\u0026lt; Id is not available to set here }; // This is the only way to set the Id var song3 = new Song(17, \u0026#34;Song3\u0026#34;);    The init keyword The init keyword was introduced in C#9, which allows for the ability for a property to be set, but only on initialization.\nHere is the same Song class, but with the Name property changed to use init instead of set:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class Song { // if not explicitly set, this variable will have  // default int value public readonly int Id; // explicitly set the value public DateTime DateCreated { get; init; } public string Name { get; init; } // set the value in the constructor public Song() { Id = 0; } // set both values in the constructor public Song(int id, string name) { Id = id; Name = name; } }   An example of this in action:\n1 2 3 4 5 6 7 8 9 10  // Allowed var song = new Song(17, \u0026#34;Song\u0026#34;); // All good var song2 = new Song { Name = \u0026#34;Song2\u0026#34; }; //song2.Name = \u0026#34;Song3\u0026#34; \u0026lt;\u0026lt; NOT allowed    Readonly and init While readonly variables still cannot use the init keyword, they can still be set when other properties are initialized.\nIn the below Person class example, the readonly Age is calculated and set when the DateOfBirth property is set:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Person { private DateTime _dateOfBirth; public string Name { get; set; } public readonly int Age; public DateTime DateOfBirth { get =\u0026gt; _dateOfBirth; init { _dateOfBirth = value; // Set the value of the readonly field Age = (int.Parse(DateTime.Now.ToString(\u0026#34;yyyyMMdd\u0026#34;)) - int.Parse(_dateOfBirth.ToString(\u0026#34;yyyyMMdd\u0026#34;))) / 10000; } } }   Object initialization can now be used:\n1 2 3 4 5 6 7 8 9  var person = new Person(); Console.WriteLine(person.Age); var person2 = new Person { Name = \u0026#34;Person1\u0026#34;, DateOfBirth = new DateTime(1983, 08, 25) }; Console.WriteLine(person2.Age);   With the output being:\n1 2  0 38    Limitations As shown in the above example, there are some limitations when using this approach:\n The readonly field can only be set if another property has an init only setter The property with the init only setting, needs to be converted to have a private backing field, and the get of the property now needs to be manually done   Notes While not especially useful in every use case, when the need does arise, the ability to calculate and set a readonly property based on the initialization of another field, can prove to be very useful.\nEven though there is some modifications required to the class (as mentioned in the above limitations), implementing this requirement without the init keyword would result in even more code.\n References Init Only Setters\n     Daily Drop 48: 08-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-08T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/08-init-readonly/","title":"Setting readonly variable using init"},{"content":"Daily Knowledge Drop The ReaderWriterLockSlim class can be used to allow multiple threads to read a resource, while only allowing one thread to write to a resource.\nIn a previous Daily Drop post we looked at how the Interlocked can be used to lock a resource - ReaderWriterLockSlim is similar to this, but allows for finer control over how the resource is locked.\n Base setup In the setup, we have a Price class which stores a price. We want the class to allow multiple concurrent reads, but only allow one thread to update the price at a time.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  class Price { private int _price; private ReaderWriterLockSlim _lock = new ReaderWriterLockSlim(); public void PrintPrice() { _lock.EnterReadLock(); Console.WriteLine($\u0026#34;{DateTime.Now} =\u0026gt; The current price is: {_price}\u0026#34;); Thread.Sleep(1000); _lock.ExitReadLock(); } public void SetPrice(int price) { _lock.EnterWriteLock(); _price = price; Console.WriteLine($\u0026#34;{DateTime.Now} =\u0026gt; Price updated to: {_price}\u0026#34;); Thread.Sleep(1000); _lock.ExitWriteLock(); } }    Line 5: An instance of ReaderWriterLockSlim is declared for the class. Line 9 \u0026amp; Line 15: The code indicates to the lock that its entering and exiting a read portion. Multiple threads are allowed to enter this block at the same time Line 20 \u0026amp; Line 27: The code indicates to the lock that its entering and exiting a write portion. Only one thread will be allowed to enter this block at the same time  A Thread.Sleep statement has been added to each locked block to simulate a potentially long running process.\n Read example The below will run a test on the read portion of the code.\n1 2 3 4 5 6 7 8 9 10 11 12  var price = new Price(); price.SetPrice(100); var taskList = new List\u0026lt;Task\u0026gt;(); for (int x = 0; x \u0026lt; 10; x++) { taskList.Add(Task.Factory.StartNew(() =\u0026gt; { price.PrintPrice(); })); } Task.WaitAll(taskList.ToArray());   Here 10 threads are being created, and executed simultaneously to try read the price.\n1 2 3 4 5 6 7 8 9 10 11  2022/03/17 06:02:38 =\u0026gt; Price updated to: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100 2022/03/17 06:02:39 =\u0026gt; The current price is: 100   The output gives an indication how ReaderWriterLockSlim operates for reading - all 10 threads accessed the resource at the same time. This confirms that the read lock allows for multiple-threads to read at the same time.\n Write example Next we\u0026rsquo;ll look at a write example.\n1 2 3 4 5 6 7 8 9 10 11 12 13  var rando = new Random(); var price = new Price(); price.SetPrice(100); var taskList = new List\u0026lt;Task\u0026gt;(); for (int x = 0; x \u0026lt; 10; x++) { taskList.Add(Task.Factory.StartNew(() =\u0026gt; { price.SetPrice(rando.Next(1000)); })); } Task.WaitAll(taskList.ToArray());   Here 10 threads are being created, and run simultaneously to try write to the price (to a random value)\n1 2 3 4 5 6 7 8 9 10 11  2022/03/17 06:07:07 =\u0026gt; Price updated to: 100 2022/03/17 06:07:08 =\u0026gt; Price updated to: 984 2022/03/17 06:07:09 =\u0026gt; Price updated to: 701 2022/03/17 06:07:10 =\u0026gt; Price updated to: 335 2022/03/17 06:07:11 =\u0026gt; Price updated to: 335 2022/03/17 06:07:12 =\u0026gt; Price updated to: 877 2022/03/17 06:07:13 =\u0026gt; Price updated to: 621 2022/03/17 06:07:14 =\u0026gt; Price updated to: 463 2022/03/17 06:07:15 =\u0026gt; Price updated to: 316 2022/03/17 06:07:16 =\u0026gt; Price updated to: 919 2022/03/17 06:07:17 =\u0026gt; Price updated to: 38   The output gives an indication how ReaderWriterLockSlim operates for writing - the price was only updated once per second. The write block is blocking access to write to the resource for 1second (due to Thread.Sleep(1000)). This confirms that the write lock allows only one thread to access the resource at any one time.\n Other features ReaderWriterLockSlim provides additional functionality which we\u0026rsquo;ll touch on here, but won\u0026rsquo;t go into detail.\nTryEnterWriteLock ReaderWriterLockSlim has a method called TryEnterWriteLock which accepts a timeout parameter. This allows for a thread to try get a write lock on a resource, but only wait for a specified time before aborting.\nEnterUpgradeableReadLock Sometimes we might enter a read lock, but then have a branch of code which will need to write. The EnterUpgradeableReadLock() caters for this scenario. It allows for a read lock to be created (and thus allowing multiple threads to still access the resource), but then the lock can be upgrade to a write lock when required to block access to other threads, to allow for writing.\n Notes Using ReaderWriterLockSlim allows for greater flexibility over using the lock keyword or Interlocked class. The latter two only allow for a blanket lock of a resource preventing any other thread from concurrently accessing the resource.\nReaderWriterLockSlim allows for finer control, allowing multiple threads to read a resource, but locks the resource from multiple parallel writes.\n References ReaderWriterLockSlim Class\n     Daily Drop 47: 07-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-07T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/07-readerwriterlockslim/","title":"Managing multi-thread access with ReaderWriterLockSlim"},{"content":"Daily Knowledge Drop When using anonymous functions (lambda functions) - in certain use cases static anonymous functions can be used instead to improve performance of the application.\n Anonymous function Code In the below sample, a function OutputDatetime is called to output the current datetime.\nHowever the formatting of the output is determined by a Func (an anonymous function) in conjunction with either the formattedTime string or slimTime string (or any other string format which can be specified).\n1 2 3 4 5 6 7 8 9 10  string formattedTime = \u0026#34;The current time is: {0}\u0026#34;; string slimTime = \u0026#34;{0}\u0026#34;; OutputDatetime(inputText =\u0026gt; string.Format(formattedTime, inputText)); OutputDatetime(inputText =\u0026gt; string.Format(slimTime, inputText)); void OutputDatetime(Func\u0026lt;string, string\u0026gt; func) { Console.WriteLine(func(DateTime.Now.ToString())); }   When the Console.WriteLine is executed on line 9, the OutputDatetime method doesn't have visibility of either formattedTime or slimTime, which are used by func - they are not within the scope of OutputDatetime.\nThe compiler gets around this by creating a closure - more information can be found here\n Lowered When the code is lowered y the compiler, a class is created to encapsulate the local values needed by the function, in this case formattedTime and slimTime.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  [CompilerGenerated] private sealed class \u0026lt;\u0026gt;c__DisplayClass0_0 { public string formattedTime; public string slimTime; internal string \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__0(string inputText) { return string.Format(formattedTime, inputText); } internal string \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__1(string inputText) { return string.Format(slimTime, inputText); } } private static void \u0026lt;Main\u0026gt;$(string[] args) { \u0026lt;\u0026gt;c__DisplayClass0_0 \u0026lt;\u0026gt;c__DisplayClass0_ = new \u0026lt;\u0026gt;c__DisplayClass0_0(); \u0026lt;\u0026gt;c__DisplayClass0_.formattedTime = \u0026#34;The current time is: {0}\u0026#34;; \u0026lt;\u0026gt;c__DisplayClass0_.slimTime = \u0026#34;{0}\u0026#34;; \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__OutputDatetime|0_2(new Func\u0026lt;string, string\u0026gt;(\u0026lt;\u0026gt;c__DisplayClass0_.\u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__0)); \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__OutputDatetime|0_2(new Func\u0026lt;string, string\u0026gt;(\u0026lt;\u0026gt;c__DisplayClass0_.\u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__1)); } [CompilerGenerated] internal static void \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__OutputDatetime|0_2(Func\u0026lt;string, string\u0026gt; func) { Console.WriteLine(func(DateTime.Now.ToString())); }   The important parts to note are:\n Line 2: A private class is created which contains the two anonymous methods (Func) as methods Line 4 and 6: The values required by the methods are declared are values on the class Lines 22-23: The values on the class are set to the required values  The anonymous functions now have access to the values it requires, which are outside its scope.\n Issue at hand The problem with the above is that the two strings used in the anonymous function need to be captured and stored in the private class. This results in additional allocations which are potentially not required.\nC#9 introduced the ability to be able to set an anonymous function as static - however static functions are unable to capture state from the local (declaring) function, so any variables the static function uses must be declared as const.\nIf the use case allows for the making the use local variables constant, then the anonymous function can also be made static which will reduced unnecessary memory allocations.\n Static anonymous function Code Let\u0026rsquo;s convert the above example to make use of a static anonymous function:\n1 2 3 4 5 6 7 8 9 10  const string formattedTime = \u0026#34;The current time is: {0}\u0026#34;; const string slimTime = \u0026#34;{0}\u0026#34;; OutputDatetime(static inputText =\u0026gt; string.Format(formattedTime, inputText)); OutputDatetime(static inputText =\u0026gt; string.Format(slimTime, inputText)); void OutputDatetime(Func\u0026lt;string, string\u0026gt; func) { Console.WriteLine(func(DateTime.Now.ToString())); }    Line 1 \u0026amp; 2: The two local variables have been declared as const Line 4 \u0026amp; 5: The anonymous functions passed into OutputDatetime have been declared as static   Lowered Taking a look at the lowered code, the benefits of the static anonymous method can be seen:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  [Serializable] [CompilerGenerated] private sealed class \u0026lt;\u0026gt;c { public static readonly \u0026lt;\u0026gt;c \u0026lt;\u0026gt;9 = new \u0026lt;\u0026gt;c(); public static Func\u0026lt;string, string\u0026gt; \u0026lt;\u0026gt;9__0_0; public static Func\u0026lt;string, string\u0026gt; \u0026lt;\u0026gt;9__0_1; internal string \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__0_0(string inputText) { return string.Format(\u0026#34;The current time is: {0}\u0026#34;, inputText); } internal string \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__0_1(string inputText) { return string.Format(\u0026#34;{0}\u0026#34;, inputText); } } private static void \u0026lt;Main\u0026gt;$(string[] args) { \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__OutputDatetime|0_2(\u0026lt;\u0026gt;c.\u0026lt;\u0026gt;9__0_0 ?? (\u0026lt;\u0026gt;c.\u0026lt;\u0026gt;9__0_0 = new Func\u0026lt;string, string\u0026gt;(\u0026lt;\u0026gt;c.\u0026lt;\u0026gt;9.\u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__0_0))); \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__OutputDatetime|0_2(\u0026lt;\u0026gt;c.\u0026lt;\u0026gt;9__0_1 ?? (\u0026lt;\u0026gt;c.\u0026lt;\u0026gt;9__0_1 = new Func\u0026lt;string, string\u0026gt;(\u0026lt;\u0026gt;c.\u0026lt;\u0026gt;9.\u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__0_1))); } [CompilerGenerated] internal static void \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__OutputDatetime|0_2(Func\u0026lt;string, string\u0026gt; func) { Console.WriteLine(func(DateTime.Now.ToString())); }   This version of the private class, doesn\u0026rsquo;t contain the two string variables - thats two less allocations compared to the non-static version.\n Notes Wherever possible, static anonymous functions should be used over non-static anonymous functions to avoid the unnecessary memory allocations.\n References Static anonymous functions: New with C# 9\n     Daily Drop 46: 06-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-06T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/06-static-anon-functions/","title":"Static anonymous functions"},{"content":"Daily Knowledge Drop Instead of using the lock keyword to block a portion of code from negative effects of multi-threading, the Interlocked class can be used instead to simplify the code.\n Why even lock? So why would we need to even lock? consider the following example, regarding a bank account.\nThe bank account has a balance, and two methods to Deposit and Withdraw money from the account.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Account { public int Balance { get; set; } public void Deposit(int depositAmount) { Balance += depositAmount; } public void Withdraw(int withdrawAmount) { Balance -= withdrawAmount; } }   The following code simulates a high volume number of transactions on the bank account - it loops for 10000 iterations in total, creating tasks to deposit $5 and to withdraw $5. These tasks are created to run in parallel, and then at the end the application waits for all the tasks to complete, before printing out the balance.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  var account = new Account(); var taskList = new List\u0026lt;Task\u0026gt;(); for (var x = 0; x \u0026lt; 100; x++) { taskList.Add(Task.Factory.StartNew(() =\u0026gt; { for (var y = 0; y \u0026lt; 100; y++) { account.Deposit(5); } })); taskList.Add(Task.Factory.StartNew(() =\u0026gt; { for (var y = 0; y \u0026lt; 100; y++) { account.Withdraw(5); } })); } Task.WhenAll(taskList); Console.WriteLine(account.Balance);   As the code is depositing and withdrawing $5, 10000 each, one would expect the final balance to be $0. However this is not the case\nThe results will vary wildly, but we I executed the code I got the following output:\n1  -625   So why is the balance not 0? This occurs because the += and =- operations are not atomic.\n Atomic Process For something to be atomic, it needs to be a single operations which cannot be influenced by another thread.\nWhen doing the += for example, the sequence of events internally are:\n Set temporary variable to the Balance + the deposit amount Set the Balance value to that of the temporary variable.  The issue here is that this is a two step process, where another thread could come in between steps 1 and 2 and complete its += or -= operation altering the value of Balance from the expected value.\nTo mitigate this, we need to make this operation atomic, or use another atomic process to prevent the unwanted interference.\n lock keyword The process can be made atomic by using the lock keyword - this keyword is used to acquire an mutual exclusive lock on an given object, effectively preventing any other code from acquiring a lock executing the code until the lock is released.\nBelow is the updated Account class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class Account { private object @lock = new object(); public int Balance { get; set; } public void Deposit(int depositAmount) { lock (@lock) { Balance += depositAmount; } } public void Withdraw(int withdrawAmount) { lock (@lock) { Balance -= withdrawAmount; } } }    Line 3: A new object is introduced to the class, the sole purpose of which is to operate as the lock. Line 8-11 and Line 16-19: Whenever an operation needs to occur which modifies the Balance amount, the lock variable is now used in conjunction with the lock keyword.\nFor the duration of the lock statement, no other thread can acquire a lock, and as such is forced to wait before acquiring the lock, and performing its operation.  Executing the same sample 10000 iterations and updates, yields the expected result, a final balance of:\n1  0    Interlocked While the above process works as expected and gives us the expected result, there is an easier and cleaner way to do it, using the Interlocked class.\nBelow is the updated Account class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class Account { private int balance; public int Balance { get =\u0026gt; balance; } public void Deposit(int depositAmount) { Interlocked.Add(ref balance, depositAmount); } public void Withdraw(int withdrawAmount) { Interlocked.Add(ref balance, -withdrawAmount); } }    Line 3 and 5: The Balance property has been changed to use a private variable and an explicit getter. Line 9 and 14: When increasing or decreasing the balance amount, the Interlocked.Add method is now used. This takes in a reference to the value to update (which is why we required the step above, so we could use the ref keyword on the variable)  Interlocked.Add is atomic and will ensure that no other threads operation on balance while another operation is taking place. The result is exactly the same as when using the lock keyword, just with less code clutter and less manual work needing to be done by the developer.\n Using the Interlocked class is a small, but useful update which can be made to code to keep it as clean as possible, without polluting the classes with lock objects. However it is not the only way to create an atomic operation, and other methods should be explored if Interlocked is not suitable.\n References lock statement\nInterlocked Class\n.NET Parallel Programming with C#\n     Daily Drop 45: 05-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-05T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/05-interlocked/","title":"Interlocked vs using the lock keyword"},{"content":"Daily Knowledge Drop There is a built in Linked List implementation in C#, which can be used in certain situations to improve performance.\n What is a Linked List? A linked list is a general, linear data structure containing multiple elements, where the elements are linked to each other via pointers (the memory address of the element)\nThe C# implementation of a linked list is a double linked list, meaning each element points to the element in front of it in the list, as well as the element behind it in the lis (vs each element only pointing to the element in front of it in the list)\n NEXT NEXT NULL ┌─┬───────────┬─┐ ┌─┬───────────┬─┐ ┌─┬───────────┬─┐ │ │ │ ├─────►│ │ │ ├─────►│ │ │ ├───► NULL │ │ ELEMENT1 │ │ │ │ ELEMENT2 │ │ │ │ ELEMENT3 │ │ ◄───┤ │ │ │◄─────┤ │ │ │◄─────┤ │ │ │ └─┴───────────┴─┘ PREV └─┴───────────┴─┘ PREV └─┴───────────┴─┘ Each element points to the element in front of it, except the last element which has a NULL next pointer. Each element also points to the element behind it, except the first element which has a NULL previous pointer.\n Example Using the LinkedList in C# is very simple, and similar (but not the same!) to how a normal List would be instantiated and used.\nThe C# LinkedList implementation is generic, so the data type it is to hold is specified at instantiation.\n1 2 3 4 5 6 7 8 9 10 11 12  var linked = new LinkedList\u0026lt;string\u0026gt;(); linked.AddLast(\u0026#34;one\u0026#34;); linked.AddLast(\u0026#34;two\u0026#34;); linked.AddLast(\u0026#34;three\u0026#34;); linked.AddLast(\u0026#34;four\u0026#34;); linked.AddLast(\u0026#34;five\u0026#34;); foreach(var item in linked) { Console.WriteLine(item); }   Here a ListedList holding string is instantiated, and 5 items added, each time to the end of the list.\nThe implementation has a GetEnumerator method, so enumeration is available (see this post for more information on enumeration)\nIt is also possible to enumerate through the list, by starting with the first element, and using the Next pointer to move to each element in the list\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  var linked = new LinkedList\u0026lt;string\u0026gt;(); linked.AddLast(\u0026#34;one\u0026#34;); linked.AddLast(\u0026#34;two\u0026#34;); linked.AddLast(\u0026#34;three\u0026#34;); linked.AddLast(\u0026#34;four\u0026#34;); linked.AddLast(\u0026#34;five\u0026#34;); var currentItem = linked.First; while(currentItem != null) { Console.WriteLine(currentItem.Value); currentItem = currentItem.Next; }   In both examples above, the output is as follows:\n1 2 3 4 5  one two three four five    Pros and Cons There are positives and negatives to using a LinkedList when compared to the other list or collection types in C# (and in general). Some points to consider:\n Linked lists are not indexed: This means the list is not able to tell which value is at position X directly. The list has to be traversed from the start, until position X is reached to get the value. This can have a performance impact if traversal needs to be done often on a large list. Inserting also requires traversing: If an element needs to be inserted into any position other than the first or last, then the list, again, needs to be traversed to get to the correct location. Adding elements is fast: Adding an element to the front or end of the list is fast - this is because the LinkedList itself is not declared with a preset element count which needs to then be adjusted as new elements are added (like with a List), and more memory allocated.   Notes For most uses cases the C# List\u0026lt;\u0026gt; will be suitable, and not have a noticeable performance impact - however, the LinkedList should be considered when:\n Mostly (only) adding items to the beginning or end of a list Items are not accessed except when traversing the entire list (outputting all items) Performance matters   References Linked List Implementation in C#\n     Daily Drop 44: 04-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-04T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/04-linked-list/","title":"Linked Lists in C#"},{"content":"Daily Knowledge Drop When cancelling tasks using a CancellationTokenSource, rather than do a soft cancellation, an OperationCanceledException should be thrown.\n Cancellation Token A quick summary of cancellation tokens - they \u0026ldquo;enable cooperative cancellation between threads, thread pool work items or Task objects\u0026rdquo;.\nBasically cancellation tokens are instantiated outside a particular thread, and then passed into the thread, to allow for cancellation from outside the thread.\n Examples In each of the below examples, there is a \u0026ldquo;long\u0026rdquo; running process which runs for 10 seconds. A cancellation token is passed in and checked every 1 second to see if a cancellation has been requested - if requested, then an action will be perform to abort/cancel the long running process.\nSoft cancellation The first example will show how to do a \u0026ldquo;soft cancellation\u0026rdquo;.\nHere, if a cancellation is requested, the developer will decide how to manually cause the method to end its execution.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  var cts = new CancellationTokenSource(); var token = cts.Token; // start the long running process var longProcessTask = Task.Run(async () =\u0026gt; { for (var i = 0; i \u0026lt; 10; i++) { // check if a cancellation has been requested if (token.IsCancellationRequested) break; // exit from the loop Console.WriteLine(\u0026#34;Processing...\u0026#34;); await Task.Delay(1000); } }, token); Console.ReadKey(); cts.Cancel(); await longProcessTask; Console.WriteLine($\u0026#34;Task is completed: {longProcessTask.IsCompleted}\u0026#34;);   In the example, the longProcessTask is started, which runs for 10 seconds if uninterrupted.\n Line 18-19: If the user presses a key, the token is cancelled Line 10-11: If the token has been requested to cancel, break out of the loop causing the long processing and effectively cause the long running task to finish  The problem with this approach, is that there is no indication if the task actually finished to completion or not.\nIf the longProcessTask was required to finish, before another process was to kick off - we do not know if the longProcessTask finished due to executing to its end, or if it finished due to be cancelled early.\n OperationCanceledException Rather than a \u0026ldquo;soft cancellation, a OperationCanceledException should be used. This provides a clear way of determining if the task was cancelled or finished successfully.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  var cts = new CancellationTokenSource(); var token = cts.Token; // start the long running process var longProcessTask = Task.Run(async () =\u0026gt; { for (var i = 0; i \u0026lt; 10; i++) { // check if a cancellation has been requested if (token.IsCancellationRequested) throw new OperationCanceledException(); Console.WriteLine(\u0026#34;Processing...\u0026#34;); await Task.Delay(1000); } }, token); try { Console.ReadKey(); cts.Cancel(); await longProcessTask; Console.WriteLine($\u0026#34;Task is completed: {longProcessTask.IsCompleted}\u0026#34;); } catch (OperationCanceledException e) { Console.WriteLine($\u0026#34;{nameof(OperationCanceledException)} \u0026#34; + $\u0026#34;thrown with message: {e.Message}\u0026#34;); }   In the example, the longProcessTask is started, which runs for 10 seconds if uninterrupted.\n Line 18-31: The longProcessTask is awaited inside a try-catch block. Line 10-11: If the token has been requested to cancel, throw an OperationCanceledException Line 27-31: Catch the OperationCanceledException  With this method, when task is cancelled we can now tell vs the task actually finishing to completion.\n ThrowIfCancellationRequested There is a slight improvement which can be made on the above, which is the recommended way of dealing with a cancelled task, and that is to use the ThrowIfCancellationRequested method on a token.\nLooking at the source code for the method one can see that its basically doing the same as the above, just wrapped up neatly into a method.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  var cts = new CancellationTokenSource(); var token = cts.Token; // start the long running process var longProcessTask = Task.Run(async () =\u0026gt; { for (var i = 0; i \u0026lt; 10; i++) { // check if a cancellation has been requested token.ThrowIfCancellationRequested(); Console.WriteLine(\u0026#34;Processing...\u0026#34;); await Task.Delay(1000); } }, token); try { Console.ReadKey(); cts.Cancel(); await longProcessTask; Console.WriteLine($\u0026#34;Task is completed: {longProcessTask.IsCompleted}\u0026#34;); } catch (OperationCanceledException e) { Console.WriteLine($\u0026#34;{nameof(OperationCanceledException)} \u0026#34; + $\u0026#34;thrown with message: {e.Message}\u0026#34;); }    Notes We\u0026rsquo;ve looked at a number of ways to cancel a task. The soft cancellation, while successfully cancellation a task, has some limitations and the better option is to use a OperationCanceledException, facilitated by the ThrowIfCancellationRequested method.\n References Cancellation Tokens\n     Daily Drop 43: 01-04-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-04-01T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/04/01-task-cancellationtoken/","title":"Cancel a task with OperationCanceledException"},{"content":"Daily Knowledge Drop The with keyword can be used to create a new instance of an anonymous type where one of more properties have new values.\n Anonymous types First off, a brief explanation of anonymous types. Anonymous types are a way to encapsulate a set of read only properties into a single object without explicitly defining a type. The type name is generated internally by the compiler and the type of each property is inferred by the compiler.\nHere we define an anonymous type (as you can see, no type is specified) with the instance name song, and a number of properties:\n1 2 3 4 5 6 7 8 9  var song = new { Name = \u0026#34;Everlong\u0026#34;, Artist = \u0026#34;Foo Fighters\u0026#34;, Released = 1997 }; Console.WriteLine(song.Name); Console.WriteLine(song);   The song instance can be treated and operated on as a usual type instance, with each property accessible (as read-only):\n1 2  Everlong { Name = Everlong, Artist = Foo Fighters, Released = 1997 }    Using with As mentioned above, the properties on an anonymous class are read-only.\nThis is NOT permitted:\n1 2 3 4 5 6 7 8 9  var song = new { Name = \u0026#34;Everlong\u0026#34;, Artist = \u0026#34;Foo Fighters\u0026#34;, Released = 1997 }; // Compiler will not allow this! song.Name = \u0026#34;Monkey Wrench\u0026#34;;   This is where the with keyword becomes useful - with expressions allow for non-destructive mutation of an anonymous type!\nSuppose we wanted to instantiate an anonymous type for each song on the album - most of the information (Artist and Released) would be the same across each instance. The with keyword can be leveraged to create a new instance of the anonymous type, based on an existing instance, but with (some) new values.\n1 2 3 4 5 6 7 8 9 10  var song = new { Name = \u0026#34;Everlong\u0026#34;, Artist = \u0026#34;Foo Fighters\u0026#34;, Released = 1997 }; var song2 = song with { Name = \u0026#34;Monkey Wrench\u0026#34; }; var song3 = song with { Name = \u0026#34;My Hero\u0026#34; }; var song4 = song with { Name = \u0026#34;Walking After You\u0026#34; };   The output:\n1 2 3 4  { Name = Everlong, Artist = Foo Fighters, Released = 1997 } { Name = Monkey Wrench, Artist = Foo Fighters, Released = 1997 } { Name = My Hero, Artist = Foo Fighters, Released = 1997 } { Name = Walking After You, Artist = Foo Fighters, Released = 1997 }    Notes When dealing with anonymous types, which share the same data across instances, this technique of instantiating using with and an existing instance can save time as well as keep code cleaner.\n References Anonymous Types\n     Daily Drop 42: 31-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-31T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/31-anon-with/","title":"Anonymous types and with keyword"},{"content":"Daily Knowledge Drop A method can be marked with the Conditional attribute to have its invocation excluded by the compiler under the specified condition.\n Example Consider the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  ProcessPerson(new Person { Id = Guid.NewGuid(), Name = \u0026#34;John\u0026#34;, Age = 41 }); static void ProcessPerson(Person p) { SparseLogging(p); FullLogging(p); // Additional process of the Person p } static void SparseLogging(Person p) { Console.WriteLine($\u0026#34;Processing person record id: {p.Id}\u0026#34;); } [Conditional(\u0026#34;DEBUG\u0026#34;)] static void FullLogging(Person p) { Console.WriteLine($\u0026#34;Processing person record\u0026#34;); Console.WriteLine($\u0026#34;Id: {p.Id}\u0026#34;); Console.WriteLine($\u0026#34;Name: {p.Name}\u0026#34;); Console.WriteLine($\u0026#34;Age: {p.Age}\u0026#34;); } class Person { public Guid Id { get; set; } public string Name { get; set; } public int Age { get; set; } }    Line 1: A ProcessPerson method is called to perform operations on the person instance Line 10-11: Two methods are called, one to perform sparse logging and another to perform full logging Line 16-19: The SparseLogging method will just output the person id Line 21-27: The FullLogging method will output all full set of person information. This method has also been marked with the Conditional attribute, with the parameter DEBUG.  The parameter supplied to the attribute needs to be a preprocessor directives (conditional complication symbol). In this case the DEBUG symbol is only defined and set to true when compiling the code in DEBUG mode, otherwise the symbol is not defined.\nThe output for the above code is now different depending on if the code is running in debug vs release mode:\nDebug:\n1 2 3 4 5  Processing person record id: f6aae86e-68c7-46b6-afcf-ba0d1051a6dc Processing person record Id: f6aae86e-68c7-46b6-afcf-ba0d1051a6dc Name: John Age: 41   Release:\n1  Processing person record id: 4914e0ea-8664-47af-b2d0-581584e3095e   The method marked with the attribute does not get executed if the condition in the attribute is not met.\n Lowered code Using sharplab.io, we can see what the compiler is doing with the above code.\nOnly the relevant portion of code has been included - when compiled in debug mode, the ProcessPerson method looks as follows:\n1 2 3 4 5  private static void ProcessPerson(Person p) { SparseLogging(p); FullLogging(p); }   However, when compiled in release mode:\n1 2 3 4  private static void ProcessPerson(Person p) { FullLogging(p); }   The compiler excludes the invocation of the method completely from the code!\n Limitation There is a limitation to the use of the Conditional attribute - as the compiler is removing parts of code, the code left behind cannot rely on the removed code.\nAs such, methods have to return void to be marked with the Conditional attribute.\n Notes Often additional logging is performed locally, while development is taking place - using this attribute the logging can automatically be removed from the output when compiling and deploying for a production environment - a very useful feature to be aware of.\n References ConditionalAttribute Class\n     Daily Drop 41: 30-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-30T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/30-conditional-attribute/","title":"Conditional attribute to exclude method execution"},{"content":"Daily Knowledge Drop An underscore (_) can be used to separate digits when dealing with numeric literals to make it easier to read.\n Decimal literals When dealing with large numeric literals, it can sometimes be difficult to read them.\nConsider a value representing pi to 100 digits:\n1  var pi = 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679;   This can instead be represented as follows, with a 3 digit separator. This has no effect on the actual value, just how it appears:\n1  var pi3 = 3.141_592_653_589_793_238_462_643_383_279_502_884_197_169_399_375_105_820_974_944_592_307_816_406_286_208_998_628_034_825_342_117_067_9;   The same formatting can also be applied as a thousand separator, to make balances easier to read, for example:\n1  var balance = 75098217932.65;   This instead becomes:\n1  var balanceSeparated = 75_098_217_932.63;   Adding the separator has no effect on the underlying values, just increases the readability of the values.\n Hexadecimal and binary literals The formatting can also be applied to hexadecimal and binary literals:\nA hexadecimal literal:\n1 2  var hexValue = 0x2DFDBBC31; var hexValueSep = 0x_2_DF_DB_BC_31;   The 0x prefix indicates a hexadecimal literal, and as you can see the separator can be applied.\nThe same can be applied to a binary literal:\n1 2  var byteValue = 0b10011010010; var byteValueSep = 0b_100_1101_0010;   The 0b prefix indicates a binary literal.\n Notes A small feature learnt today, to assist in making code slightly more readable.\n References Integral numeric types (C# reference)\nWhat\u0026rsquo;s New in C# 7.0?\n     Daily Drop 40: 29-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-29T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/29-underscore-separator/","title":"Using underscore as a digit separator"},{"content":"Daily Knowledge Drop A new attribute StringSyntaxAttribute, being introduced in .NET7, allows for marking a C# string as containing a specific type of value. This results in:\n Syntax highlighting for the specific type Basic validation for the specific type.  At the time of this post, this feature is only available in .NET7 preview 1, and when using Visual Studio 2022 17.2.0 Preview 1.0. This may change between now and .NET7 release.\n Core libraries As part of .NET7, the core .NET libraries have been updated, where relevant, to make use of the new attribute.\nCurrently there are 3 supported types/languages, but the framework is extensible so more languages can be added:\n Regex Json DateTime  Most, if not all, methods in the core libraries which accept a string parameter of one of these types, now makes use of the attribute.\nThis allows for full syntax highlighting:\n Regex and Json example \nIn the above example, you can see how:\n A string being passes to the Regex constructor has syntax highlighting A bit more subtle, but the string representing a json value being passed to JsonSerializer.Deserialize also has syntax highlighting A string representing a json value being passed to a normal method does not have any syntax highlighting  In the case of DateTime, the attribute provides additional intellisense assistance:\n DateTime information \nBy marking a string with the attribute, basic validation is also applied, based on the language type:\n JSON syntax error/warning \nThe above string has malformed json (missing quote), but has been marked as containing a json value - Roslyn flags this with a warning to highlight the string has an invalid value according to the specific type.\n Non-attribute highlighting It is also possible to mark a normal string with syntax highlighting, outside of using the attribute. This is done by prefixing the string with /*lang=xxx*/ (where xxx is the language)\n Non-attribute usage \nHere, a normal string declaration has been marked as containing regex formatting and the string has been highlighted accordingly.\nA string parameter (not marked with StringSyntaxAttribute) has also had the syntax highlighting applied by using the /*lang=regex*/ method.\n Own libraries It is also possible to make use of the attribute in our own code, and mark string parameters as being of a certain type. This allows for a better developer experience for users of the libraries/methods:\n Attribute usage in own method \nAnd an example with json\n Attribute usage with json string \n Notes This is an amazing and incredibly useful feature, especially for the developers who work with the supported languages/types (Regex, JSON and DateTime at present). With this being extensible, I am excited to see where this goes and the supported languages increase!\n References .NET Tooling Community Standup - .NET Performance sneak peek!\n     Daily Drop 39: 28-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-28T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/28-stringsyntaxattribute/","title":"StringSyntaxAttribute for syntax highlighting"},{"content":"Daily Knowledge Drop When checking if an instances of a object is null, the is keyword should be used instead of the double equals == operator.\nThis is because the == operator can be overloaded to change its meaning, while the is keyword cannot.\n Comparing using == Consider a Person class, which contains Name and Age properties.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  Person p1 = null; Person p2 = new Person(); Person p3 = new Person { Name = \u0026#34;John\u0026#34;, Age = 33 }; if (p1 == null) { Console.WriteLine($\u0026#34;p1 == null\u0026#34;); } if (p2 == null) { Console.WriteLine($\u0026#34;p2 == null\u0026#34;); } if(p3 == null) { Console.WriteLine($\u0026#34;p3 == null\u0026#34;); }   In the above example, three Person instances are defined:\n One explicitly set to null (Line 1) One set to a default instance of Person (Line 2) One set with explicit values (Line 3)  Each of these is checked to see if they are null, using the == operator, with the output as follows:\n1 2  p1 == null p2 == null   Hold on\u0026hellip; The output is showing that p2 == null is true, when p2 is clearly not null! (is was instantiated with Person p2 = new Person();) How can this be?\nThe reason for this, is unknown to us, the author of the Person class has overloaded the == operator to function differently to the default expected behavior.\n Operator overloading If we take a look at the contents of the Person class in full:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Person { public string Name { get; set; } public int Age { get; set; } public static bool operator == (Person p, Person p1) { if((p?.Age == 0 \u0026amp;\u0026amp; p1 is null) || (p1?.Age == 0 \u0026amp;\u0026amp; p is null)) { return true; } return p?.Name == p1?.Name \u0026amp;\u0026amp; p?.Age == p1?.Age; } public static bool operator !=(Person p, Person p1) { return !(p?.Name == p1?.Name \u0026amp;\u0026amp; p?.Age == p1?.Age); } }   The == operator has been overloaded to change its meaning - Line 9 states that if either of the two Person instances being compared have an Age of 0, then no matter what, return false (meaning the two instances are not equal).\nIn the previous example the Person instance p2 has an Age of 0. Therefor according to the new logic for the == operator, no matter what the value of the Person being compared to, it will return false.\n Comparing using is The is operator should be used to do comparison, as it cannot be overloaded and have its definition changed:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  Person p1 = null; Person p2 = new Person(); Person p3 = new Person { Name = \u0026#34;John\u0026#34;, Age = 33 }; if (p1 is null) { Console.WriteLine($\u0026#34;p1 is null\u0026#34;); } if (p2 is null) { Console.WriteLine($\u0026#34;p2 is null\u0026#34;); } if (p3 is null) { Console.WriteLine($\u0026#34;p3 is null\u0026#34;); }   The output is as follows:\n1  p1 == null   This is the expected output, as p1 is the only instance which is truly null - the output is now accurate.\n Notes This is a small distinction between the two operators (== and is), and might not ever be an issue if you the author of the classes as well as the code using them. However in the case when using 3rd party classes, its safer to use the is keyword and ensure the code operates as expected.\n References Operator overloading\n     Daily Drop 38: 25-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-25T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/25-is-instead-of-equals/","title":"Null checking with the is keyword"},{"content":"Daily Knowledge Drop C#8, first introduced with .NET Core 3, added support for indices and ranges, which provide a succinct syntax for accessing single elements or ranges in a sequence.\nTwo new operators were introduced to support this functionality:\n ^: The index from end operator ..: The range operator   ^ operator The new ^ operator is an index from end operator, which specifies that an index is relative to the end of the sequence.\n1 2 3 4 5 6 7 8 9 10 11  var words = new string[] { \u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;sequence\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;word\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;demo\u0026#34;, \u0026#34;indices\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;ranges\u0026#34; }; Console.WriteLine(words[^1]); // last word (ranges) Console.WriteLine(words[^2]); // 2nd last word (and) Console.WriteLine(words[^3]); // 3rd last word (indices) Console.WriteLine(words[^4]); // (demo) Console.WriteLine(words[^5]); // (to)   The output is:\n1 2 3 4 5  ranges and indices demo to   ^1 indicates 1 index from the end, in other words the last item.\n^2 indicates 2 indexes from the end, the second last item, etc.\n^0 is used to represent the length of the sequence, and is equivalent to sequence.Length.\n .. operator The new .. operator is a range operator, which specifies the start and end of the range as its operands.\nConstant values Constant int values can be used with the .. operator:\n1 2 3 4 5 6 7 8 9 10  var words = new string[] { \u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;sequence\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;word\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;demo\u0026#34;, \u0026#34;indices\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;ranges\u0026#34; }; // get elements 0,1,2,3 and 4 (not 5) from the sequence var snippet = words[0..5]; // join the items in \u0026#34;snippet\u0026#34; and separate them with a space Console.WriteLine(string.Join(\u0026#34; \u0026#34;, snippet));   The output is:\n1  This is a sequence of   0..5 indicates a range of items 0 to 4. words[5] is not included in the range.\n \u0026lsquo;Index from end\u0026rsquo; values The range (..) operator can also be used in conjunction with the new ^ operator:\n1 2 3 4 5 6 7 8 9 10  var words = new string[] { \u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;sequence\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;word\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;demo\u0026#34;, \u0026#34;indices\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;ranges\u0026#34; }; // get the 3rd, 2nd and last words from the sequence var lastThreeWord = words[^3..^0]; // join the items in \u0026#34;lastThreeWord\u0026#34; and separate them with a space Console.WriteLine(string.Join(\u0026#34; \u0026#34;, lastThreeWord));   The output is:\n1  indices and ranges   As the last item specified by a Range, is not included in the range, the ^0 is used, to indicate the last item in the sequence when used in a Range.\n Range variable A Range can also be declared as a variable, which has a value set at runtime, then used:\n1 2 3 4 5 6 7 8 9 10 11 12 13  var words = new string[] { \u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;sequence\u0026#34;, \u0026#34;of\u0026#34;, \u0026#34;word\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;demo\u0026#34;, \u0026#34;indices\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;ranges\u0026#34; }; Range GetRange(int start, int end) { return start..end; } var dynamicWords = words[GetRange(2, 8)]; Console.WriteLine(string.Join(\u0026#34; \u0026#34;, dynamicWords));   The output is:\n1  a sequence of word to demo    String example The new operators are not only supported on arrays, but also can also be used on string, as well as Span\u0026lt;T\u0026gt; and ReadOnlySpan\u0026lt;T\u0026gt;\nA string example:\n1 2 3 4 5 6 7 8  string alwaysDeveloping = \u0026#34;alwaysdeveloping.net\u0026#34;; // get the last 4 characters Console.WriteLine(alwaysDeveloping[^4..^0]); // get the last character Console.WriteLine(alwaysDeveloping[^1]); Console.WriteLine(alwaysDeveloping[alwaysDeveloping.Length - 1]);   The output is:\n1 2 3  .net t t   As you can see from the output, alwaysDeveloping[^1] is equilveilant to alwaysDeveloping[alwaysDeveloping.Length - 1] - just a lot more concise and succinct.\n Notes While maybe not for everyday use, especially if not dealing with a lot of arrays (and other supported types) - the new operators can prove very useful when they are required, the resulting code being more succinct and less verbose.\n References Indices and ranges\n     Daily Drop 37: 24-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-24T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/24-indices-ranges/","title":"Indices and ranges"},{"content":"Daily Knowledge Drop A Func (or Action) can be used as an intermediary to keep code cleaner when dealing with multiple methods or delegates of the same signature.\n The setup The root of this post stems from a real-world situation I\u0026rsquo;d encountered. The examples below will be a simplified example of the situation but the setup is as follows:\n A handler is obtained from the dependency injection container A collection of none or many interceptors are obtained from the dependency injection container If no interceptors are obtained, then Invoke a HandleOperation method on the handler If any interceptors are obtained, then build up a \u0026ldquo;pipeline\u0026rdquo; of all interceptors and then the handler at the end of the pipeline. Each interceptor would perform any logic it might need to, and proceed to the next interceptor or handler, if at the end of the pipeline (similar to the ASPNET Core middleware pipeline functions)   The Code Non-working example Below is a simplified version of the above situation.\nIf there is an Interceptor supplied, then its InterceptValue method is called, otherwise the Handler HandleOperation method is called:\nThis will NOT compile:\n1 2 3 4 5 6 7 8 9 10 11 12  void PerformOperation(int x, IInterceptor interceptor = null) { var handler = new Handler(); var start = interceptor != null ? interceptor.InterceptValue : handler.HandleOperation; Console.WriteLine($\u0026#34;Log: About to perform the operation\u0026#34;); var result = start.Invoke(x); Console.WriteLine($\u0026#34;Log: The result of the operation is: {x}\u0026#34;); }   The error originating on line 5 is: Type of conditional expression cannot be determined because there is no implicit conversion between 'method group' and 'method group'\nEven though both methods, InterceptValue and HandleOperation have the same signature, they are considered completely different types.\nAs per the error message, the compiled can\u0026rsquo;t determine the type of var start because the two methods are different types and either could be assigned to var start.\nTo fix this, the compiler need to be explicitly how to convert the two different methods to one common underlying type.\n Working example To tell the compiler how to convert the two different methods to the same common type, the var just needs to be replaced with the common type.\nThe commonality between InterceptValue and HandleOperation is that they are both methods, which accept one int parameter, and return an int - luckily C# has a way to represent a method as a variable, usingFunc\u0026lt;int, int\u0026gt; (in this example).\nFor reference - just like an int represents a numerical value, a Func represents a method value. The generic parameters \u0026lt;int, int\u0026gt; refer to the parameter type and return type of the method.\n1 2 3 4 5 6 7 8 9 10 11 12 13  void PerformOperation(int x, IInterceptor interceptor = null) { var handler = new Handler(); Func\u0026lt;int, int\u0026gt; start = interceptor != null ? interceptor.InterceptValue : handler.HandleOperation; Console.WriteLine($\u0026#34;Log: About to perform the operation\u0026#34;); var result = start.Invoke(x); Console.WriteLine($\u0026#34;Log: The result of the operation is: {x}\u0026#34;); }    Lines 5-6 is saying declare a variable of type method, a method which takes one parameter of type int and returns an int - and the value of this variable is either InterceptValue or HandleOperation Line 10: invokes the Func (method) passing in the parameter value.  This will now compile and work!\n Notes Using Func or Action allow for the reduction of methods, with the same signatures, to a common type - this is useful in the situation where one might have to run through a long list of logic to determine which method to invoke. The method can be treated as a variable and assigned and reassigned as the logic is executed.\n      Daily Drop 36: 23-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-23T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/23-func-as-intermediary/","title":"Using Func\u003c\u003e as an intermediary"},{"content":"Daily Knowledge Drop The way in which the validity of a method parameter, and the way the consequent exception is thrown, has evolved over time and has become a lot simpler and cleaner to do.\nToday we\u0026rsquo;ll look at the evolution of the ArgumentNullException.\n Manual check and throw The first example is probably the most familiar way to do validate - check the value and then throw an exception if the validation passes.\n1 2 3 4 5 6 7 8 9  void ManualCheckAndThrow(ParameterClass param) { if(param == null) { throw new ArgumentNullException(\u0026#34;param\u0026#34;); } Console.WriteLine($\u0026#34;The parameter name is: {param.Name}\u0026#34;); }    Check and throw An improvement was included with .NET6, which is a method on ArgumentNullException itself, which performs the validation and only throws the exception if the value is null.\n1 2 3 4 5 6  void ManualThrowIfNull(ParameterClass param) { ArgumentNullException.ThrowIfNull(param, \u0026#34;param\u0026#34;); Console.WriteLine($\u0026#34;The parameter name is: {param.Name}\u0026#34;); }   This code is much cleaner than the first example, however its still a manual process to initialize the check.\n Automatic parameter checking .NET7 (currently only .NET7 Preview 1 - so things might still change) introduced the ability to mark the parameter as non-nullable. If the value is null, the ArgumentNullException is automatically thrown.\n1 2 3 4  void AutoNullCheck(ParameterClass param!!) { Console.WriteLine($\u0026#34;The parameter name is: {param.Name}\u0026#34;); }   In line 1, the parameter value is marked with a double exclamation mark !!. This is the indicator that an ArgumentNullException should be thrown automatically if the value is null.\n !! lowering Having a look at how the !! operator is lowered, using sharplab.io, we can see that the complier is converting the !! operator into an explicit check of the parameter, and throwing the exception if null.\nSo this method:\n1 2 3 4  void AutoNullCheck(ParameterClass param!!) { Console.WriteLine($\u0026#34;The parameter name is: {param.Name}\u0026#34;); }   Gets lowered to this (some non-related portions of code have been omitted):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  private void AutoNullCheck(ParameterClass param) { \u0026lt;PrivateImplementationDetails\u0026gt;.ThrowIfNull(param, \u0026#34;param\u0026#34;); Console.WriteLine(string.Concat(\u0026#34;The parameter name is: \u0026#34;, param.Name)); } [CompilerGenerated] internal sealed class \u0026lt;PrivateImplementationDetails\u0026gt; { internal static void Throw(string paramName) { throw new ArgumentNullException(paramName); } internal static void ThrowIfNull(object argument, string paramName) { if (argument == null) { Throw(paramName); } } }    Notes There has been a fair amount of negative feedback to the introduction of the !! operation, as seen here at the C#11 features post.\nPersonally, I don\u0026rsquo;t mind the new operator - if unfamiliar with it, it is not initially obvious what it does or how it\u0026rsquo;s effecting the code, but I feel this is a minor issue that can easily be overcome with online search and reading through the docs. The operator does improve the readability and cleanliness of the code.\n      Daily Drop 35: 22-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-22T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/22-argnullexception/","title":"ArgumentNullException improvements"},{"content":"Daily Knowledge Drop The dynamic keyword can be used to to automatically downcast a variable to the correct type when calling a method.\nThis technique is useful when having a variable of a base type, and a method needs to be called using a derived type.\nLets look at a few examples, which will help make things a bit clearer.\n Base setup In the examples below, the following hierarchy of classes is used:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  public class Vehicle { public void PrintVehicle() =\u0026gt; Console.WriteLine($\u0026#34;I am a {typeof(Vehicle).Name}\u0026#34;); } public class LandVehicle : Vehicle { public void PrintLandVehicle() =\u0026gt; Console.WriteLine($\u0026#34;I am a {typeof(LandVehicle).Name}\u0026#34;); } public class Car : LandVehicle { public void PrintCar() =\u0026gt; Console.WriteLine($\u0026#34;I am a {typeof(Car).Name}\u0026#34;); } public class SeaVehicle : Vehicle { public void PrintSeaVehicle() =\u0026gt; Console.WriteLine($\u0026#34;I am a {typeof(SeaVehicle).Name}\u0026#34;); } public class Boat : SeaVehicle { public void PrintBoat() =\u0026gt; Console.WriteLine($\u0026#34;I am a {typeof(Boat).Name}\u0026#34;); }   The hierarchy looks as follows. Each level has a print method which prints out which type it is:\n Vehicle:  Land Vehicle  Car   Sea Vehicle  Boat      We also have a VehicleHelper class, which will assist in dealing with Vehicles:\n1 2 3 4 5 6 7 8 9 10 11 12  public class VehicleHelper { public void PrintVehicle(Car c) { c.PrintCar(); } public void PrintVehicle(Boat b) { b.PrintBoat(); } }   This class can print a vehicle, but only if its a Car or a Boat.\n Working example Using the VehicleHelper, we can print out a Car or Boat as follows:\n1 2 3 4 5 6 7 8  var helper = new VehicleHelper(); Car car = new Car(); Boat boat = new Boat(); helper.PrintVehicle(car); Console.WriteLine(\u0026#34;=====\u0026#34;); helper.PrintVehicle(boat);   As one might expect, the output is as follows:\n1 2 3  I am a Car ===== I am a Boat    The problem Assume the VehicleHelper class was extended to include a factory method to return a Vehicle. We can ask it for a Vehicle of a particular type by using a string, and it will return that type.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class VehicleHelper { public void PrintVehicle(Car c) { c.PrintCar(); } public void PrintVehicle(Boat b) { b.PrintBoat(); } public Vehicle GetVehicle(string type) =\u0026gt; type switch { \u0026#34;vehicle\u0026#34; =\u0026gt; new Vehicle(), \u0026#34;land\u0026#34; =\u0026gt; new LandVehicle(), \u0026#34;car\u0026#34; =\u0026gt; new Car(), \u0026#34;sea\u0026#34; =\u0026gt; new SeaVehicle(), \u0026#34;boat\u0026#34; =\u0026gt; new Boat(), _ =\u0026gt; new Vehicle() }; }   This method can now be used to get new Vehicles:\n1 2  Vehicle vehCar = helper.GetVehicle(\u0026#34;car\u0026#34;); Vehicle vehBoat = helper.GetVehicle(\u0026#34;boat\u0026#34;);   The problem here, is that even though we are asking for a Car and the method instantiates and returns a Car, the return type is Vehicle - the Car (or boat, or any other type) gets upcast to type Vehicle.\nThis means the following will NOT compile:\n1 2 3 4 5  var helper = new VehicleHelper(); Vehicle vehCar = helper.GetVehicle(\u0026#34;car\u0026#34;); helper.PrintVehicle(vehCar); // ERROR on this line   The error on line 5 is cannot convert from 'Vehicle' to 'Car'.\nEven though vehCar was instantiated as a Car is was upcast to a Vehicle and there is no PrintVehicle method which accepts type Vehicle.\n The fix The dynamic keyword can be used to automatically downcast the Vehicle to the correct type, and have the correct method invoked.\n1 2 3 4 5 6 7 8  var helper = new VehicleHelper(); Vehicle vehCar = helper.GetVehicle(\u0026#34;car\u0026#34;); Vehicle vehBoat = helper.GetVehicle(\u0026#34;boat\u0026#34;); helper.PrintVehicle((dynamic)vehCar); Console.WriteLine(\u0026#34;=====\u0026#34;); helper.PrintVehicle((dynamic)vehBoat);   On lines 6 and 7, the Vehicle is cast to dynamic - the result is that the vehCar will be cast to Car, and the correct PrintVehicle method called, with the same pattern applying to vehBoat.\nThe output is as follows:\n1 2 3  I am a Car ===== I am a Boat   This is incredible useful - just by casting it to dynamic, the compiled will cast to the correct type and invoke the correct method!\n Notes dynamic has a bit of a negative reputation, but in this case it proves to be very useful. As always though, especially if this is used in a critical hot path, the performance should be benchmarked against other methods to determine if using dynamic makes sense. It might make more sense, for example, to manually check and cast the type (using the is keyword) and calling the appropriate method.\n      Daily Drop 34: 21-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-21T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/21-dynamic-downcast/","title":"Downcasting automatically with dynamic keyword"},{"content":"Daily Knowledge Drop The way in which base and inherited classes can automatically be cast up or down the hierarchy (depending on the situation) is referred to covariance and contravariance.\nMost developers have probably used the concepts of covariance and contravariance in their code, perhaps without even realising it. Looking at a some examples, will help explain in a bit more detail.\n Base setup In the examples below, the following hierarchy of classes is used:\n1 2 3 4 5 6 7 8 9  public class Vehicle { } public class LandVehicle : Vehicle { } public class SeaVehicle : Vehicle { } public class Car : LandVehicle { } public class Boat : SeaVehicle { }   Contravariance Contravariance applies to types going in, in other words parameters to methods.\nContravariance allows for methods with a parameter of a base class, to accept any type derived from the base class.\nSummary: Contravariance =\u0026gt; IN =\u0026gt; parameter declared as base, but derived can be used\nAn example:\n1 2 3 4 5 6 7  // declare a lambda function which takes in a Vehicle  var func = (Vehicle veh) =\u0026gt; Console.WriteLine(veh.ToString()); // the function will accept all types of vehicles func(new Vehicle()); func(new Car()); func(new SeaVehicle());   The lambda is declared with a parameter of Vehicle, but any type of derived vehicle will be accepted.\nBecause the lambda takes in a Vehicle if there is a method or property specific to a child which needs to be invoked, the Vehicle type needs to be checked and downcast the derived type\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  // the function will accept all types of vehicles OuputExtendedDetails(new Vehicle()); OuputExtendedDetails(new Car()); OuputExtendedDetails(new SeaVehicle()); // parameter of type Vehicle public void OuputExtendedDetails(Vehicle veh) { // each IF statement will try downcast and assign to the variable (lv in below case) // if allowed to do so if(veh is LandVehicle lv) { Console.WriteLine($\u0026#34;{lv.GetType()} travels on land\u0026#34;); } if (veh is Car car) { Console.WriteLine($\u0026#34;{car.GetType()} travels on land\u0026#34;); } if (veh is SeaVehicle sv) { Console.WriteLine($\u0026#34;{sv.GetType()} travels on sea\u0026#34;); } if (veh is Boat boat) { Console.WriteLine($\u0026#34;{boat.GetType()} travels on sea\u0026#34;); } Console.WriteLine(\u0026#34;Vehicle can travel\u0026#34;); }   The output is as follows:\n1 2 3 4 5 6  Vehicle can travel Car travels on land Car travels on land Vehicle can travel SeaVehicle travels on sea Vehicle can travel   A Car for instance:\n is a Vehicle so can be passed into the method is a LandVehicle (line 11-14) so ouput is written is a Car (line 16-18) so ouput is written  In short, this is contravariance - the ability to use a derived class as a parameter, where a base class has been specified.\n Covariance Covariance applies to types coming out, in other words return types from methods or assignments.\nCovariance allows for passing back a derived type where a base type is expected.\nSummary: Covariance =\u0026gt; OUT =\u0026gt; type declared as derived, but base can be used\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // Even though a Car and Boat // are being returned, they are assigned to Vehicle Vehicle car = GetCar(); Vehicle boat = GetBoat(); // get a Car public Car GetCar() { return new Car(); } // get a Boat public Boat GetBoat() { return new Boat(); }   Here, the return types are Car and Boat, but they can both be assigned to a variable of type Vehicle.\nThis is useful, for example, when we want to have a list of Vehicles. The list is declared of type Vehicle, and therefor can hold any type of vehicle:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // add a Car and Boat to a Vehicle list var vehList = new List\u0026lt;Vehicle\u0026gt;(); vehList.Add(GetCar()); vehList.Add(GetBoat()); // output the items foreach(var veh in vehList) { Console.WriteLine(veh.ToString()); } public Car GetCar() { return new Car(); } public Boat GetBoat() { return new Boat(); }   The output is as follows:\n1 2  Car Boat   In short, this is covariance - the ability to assign a derived type, to its base class.\n Contravariance - Generics Contravariance can also be applied to Generics, using the in keyword.\nUsing the in keyword allows for the usage of a less derived type than the one specified by the generic parameter.\nConsider the following setup (without the in keyword):\n1 2 3  public interface ITravel\u0026lt;TVehicle\u0026gt; { } public class Travel\u0026lt;TVehicle\u0026gt; : ITravel\u0026lt;TVehicle\u0026gt; { }   Using the above setup, the following will NOT compile:\n1 2 3 4 5 6 7 8 9 10  var carTravel = new Travel\u0026lt;Car\u0026gt;(); MoveCar(carTravel); var landTravel = new Travel\u0026lt;LandVehicle\u0026gt;(); MoveCar(landTravel); // THIS IS NOT ALLOWED public void MoveCar(ITravel\u0026lt;Car\u0026gt; travel) { Console.WriteLine(travel); }    Line 7-10: A method is declared which takes an instance of ITravel\u0026lt;Car\u0026gt;. Line 1-2: An instance of ITravel\u0026lt;Car\u0026gt; is declared and the MoveCar method is called without issue Line 4-5: An instance of ITravel\u0026lt;LandVehicle\u0026gt; is declared and the the MoveCar method is tried to be called. This is NOT ALLOWED.  As the generic parameter is not declared with the in keyword, it is not contravariant. By just adding the in keyword, the above will be allowed:\n1 2 3  public interface ITravel\u0026lt;in TVehicle\u0026gt; { } public class Travel\u0026lt;TVehicle\u0026gt; : ITravel\u0026lt;TVehicle\u0026gt; { }   Now, any type which is less derived than Car can be used instead of Car. The below is now 100% valid and will compiled with any issue:\n1 2 3 4 5 6 7 8 9 10 11 12 13  var carTravel = new Travel\u0026lt;Car\u0026gt;(); MoveCar(carTravel); var landTravel = new Travel\u0026lt;LandVehicle\u0026gt;(); MoveCar(landTravel); var vehTravel = new Travel\u0026lt;Vehicle\u0026gt;(); MoveCar(landTravel); public void MoveCar(ITravel\u0026lt;Car\u0026gt; travel) { Console.WriteLine(travel); }   The output:\n1 2 3  Travel`1[Car] Travel`1[LandVehicle] Travel`1[Vehicle]    Covariance - Generics Covariance can also be applied in Generics, using the out keyword.\nUsing the out keyword allows for the usage of a more derived type than the one specified by the generic parameter.\nConsider the following setup (without the out keyword):\n1 2 3  interface ITravel\u0026lt;TVehicle\u0026gt; { } class Travel\u0026lt;TVehicle\u0026gt; : ITravel\u0026lt;TVehicle\u0026gt; { }   Using the above setup, the following will NOT compile:\n1 2 3 4 5  ITravel\u0026lt;Vehicle\u0026gt; veh = new Travel\u0026lt;Vehicle\u0026gt;(); ITravel\u0026lt;Car\u0026gt; car = new Travel\u0026lt;Car\u0026gt;(); // THIS IS NOT ALLOWED veh = car;   The instance of Travel\u0026lt;Car\u0026gt; (a more derived type) cannot cannot be assigned to a variable using type Vehicle (a less derived type).\nAs the generic parameter is not declared with the out keyword, it is not covariant. By just adding the out keyword to the generic parameter, the above will be allowed:\n1 2 3  interface ITravel\u0026lt;out TVehicle\u0026gt; { } class Travel\u0026lt;TVehicle\u0026gt; : ITravel\u0026lt;TVehicle\u0026gt; { }   Now, any type which is a more derived type than Vehicle can be used instead of Vehicle. The below is now 100% valid and will compiled with any issue:\n1 2 3 4 5 6 7 8 9 10 11 12  ITravel\u0026lt;Vehicle\u0026gt; veh = new Travel\u0026lt;Vehicle\u0026gt;(); ITravel\u0026lt;Car\u0026gt; car = new Travel\u0026lt;Car\u0026gt;(); ITravel\u0026lt;SeaVehicle\u0026gt; sea = new Travel\u0026lt;SeaVehicle\u0026gt;(); Console.WriteLine(veh); Console.WriteLine(car); veh = car; Console.WriteLine(veh); veh = sea; Console.WriteLine(veh);   The output:\n1 2 3 4  Travel`1[Vehicle] Travel`1[Car] Travel`1[Car] Travel`1[SeaVehicle]    IEnumerable - Generics The above examples, while doing a satisfactory job in demonstrating the functionality, are not concrete examples.\nSo lets have a quick look at the .NET IEnumerable\u0026lt;\u0026gt; class, which is defined with the out keyword:\n1 2 3 4 5 6 7  namespace System.Collections.Generic { public interface IEnumerable\u0026lt;out T\u0026gt; : IEnumerable { // removed for brevity } }   This allows IEnumerable\u0026lt;\u0026gt; to be used as follows:\n1 2  IEnumerable\u0026lt;Car\u0026gt; cars = new List\u0026lt;Car\u0026gt;(); IEnumerable\u0026lt;Vehicle\u0026gt; vehicle = cars;   This is covariance in action - more derived type can be used and assigned to a less derived type.\n Notes In summary:\n Contravariance =\u0026gt; in =\u0026gt; parameter declared as base, but derived can be used Covariance =\u0026gt; out =\u0026gt; type declared as derived, but base can be used  Knowing about covariance and contravariance, especially when it comes to generics, is useful to know and can be leveraged to reduce duplicate code.\n References Out (generic modified)\nIn (generic modified)\nCovariance and Contravariance in C# Explained\n     Daily Drop 33: 17-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-18T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/18-co-contravariance/","title":"Covariance and Contravariance in C#"},{"content":"Daily Knowledge Drop SQL Server has two keywords available, OFFSET and FETCH which can be used to limit the number of rows returned by a query.\nThis functionality has been available in SQL Server 2012 and later, and Azure SQL Database.\n Limiting rows returned The OFFSET keyword can be used independently or in conjunction with the FETCH keyword, which cannot be used in isolation.\n OFFSET: determines how many rows to skip at the start of the dataset FETCH: determines how many rows to return, after the OFFSET rows have been skipped  Whether using only OFFSET or OFFSET + FETCH, in both situations, the ORDER BY clause is required.\n Examples In the following examples, the table has a simple auto incrementing int Id field which is used for ordering.\nConstant value 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  -- select all ids order from smallest to largest SELECTIdFROMOffSetDemoORDERBYIdASC-- Skip the first 10 rows, and return -- all other rows SELECTIdFROMOffSetDemoORDERBYIdASCOFFSET10ROWS-- Skip the first 10 rows, and return -- the next 20 rows only SELECTIdFROMOffSetDemoORDERBYIdASCOFFSET10ROWSFETCHNEXT20ROWSONLY    Variable values Instead of a constant number, the values used for OFFSET and FETCH can be variable:\n1 2 3 4 5 6 7 8 9 10  DECLARE@SkipRowsINT=10,@FetchRowsINT=20;-- Skip the first 10 rows, and return -- the next 20 rows only SELECTIdFROMOffSetDemoORDERBYIdASCOFFSET@SkipRowsROWSFETCHNEXT@FetchRowsROWSONLY    Expression values Expressions can also be used to calculate the OFFSET and FETCH values:\n1 2 3 4 5 6 7 8 9 10  DECLARE@PageNumberINT=5,@PageSizeINT=20;-- In this example, skip 100 records -- and return the next 20 SELECTIdFROMOffSetDemoORDERBYIdASCOFFSET@PageNumber*@PageSizeROWSFETCHNEXT@PageSizeROWSONLY   This makes paging on the dataset very easy.\n Subquery values Finally, the values can also be retrieved using a subquery\n1 2 3 4 5 6 7 8 9 10 11  -- Skip 10 rows and return -- the next X rows, determined -- but a value in the AppSettings table SELECTIdFROMOffSetDemoORDERBYIdASCOFFSET10ROWSFETCHNEXT(SELECTCONVERT(INT,[VALUE])FROMAppSettingsWHERE[Key]=\u0026#39;PageSize\u0026#39;)ROWSONLY    Notes The OFFSET + FETCH combination is a very easy, effective way and simple to add paging to a dataset, and offers a better alterative to having to use ROW_NUMBER to add paging.\n References SQL SELECT - ORDER BY Clause\n     Daily Drop 33: 17-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-17T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/17-sql-offset-fetch/","title":"Using SQL Server's OFFSET and FETCH"},{"content":"Daily Knowledge Drop A closure is a particular type of first class function, which is linked to the environment in which it was declared, and as such can reference variables in this environment, even if outside the scope of the function.\n First class function A closure is a first class function - this basically means C# treats the function as a data type, and as such can be used as if it were a data type. It can be assigned to a variable, passed as a parameter etc.\n1 2 3 4 5 6 7  var func1 = GetFunction(); Console.WriteLine(func1()); Func\u0026lt;string\u0026gt; GetFunction() { return () =\u0026gt; \u0026#34;String created by GetFunction\u0026#34;; }    Line 4: A method is defined, which returns a Func\u0026lt;string\u0026gt;. Func\u0026lt;string\u0026gt; is a shortcut for a method, which takes no parameters and returns a string. So the GetFunction method, will return another method (as a variable), which takes no parameters and returns as string Line 6: The Func\u0026lt;string\u0026gt; is defined, an anonymous method, which takes no parameters and returns a string Line 1: GetFunction is called and the returned function is assigned to variable func1 Line 2: func1 is invoked, and the returning string output to the console  The output is as follows:\n1  String created by GetFunction    Variables outside scope Looks look at some more examples, this time where the function uses a variable outside of its scope:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  var func2 = GetFunction2(); Console.WriteLine(func2()); var func3 = GetFunction3(17); Console.WriteLine(func3()); Func\u0026lt;string\u0026gt; GetFunction2() { int intValue = 12; return () =\u0026gt; $\u0026#34;String created by GetFunction, value of {intValue}\u0026#34;; } Func\u0026lt;string\u0026gt; GetFunction3(int intValue) { return () =\u0026gt; $\u0026#34;String created by GetFunction, value of {intValue}\u0026#34;; }   Both of the methods, GetFunction2 and GetFunction3 return a Func\u0026lt;string\u0026gt; which makes use of the intValue variable.\nWhen the Func is finally invoked, the variable intValue is no longer in scope of the Func (it was defined inside the scope of GetFunction2 and GetFunction3, which are both now out of scope) - however the value is accessed and output correctly - this is a closure.\n1 2  String created by GetFunction, value of 12 String created by GetFunction, value of 17   As mention in the intro, the Closure is linked to the environment in which it was declared, and as such has access to variables in that environment (intValue), even if outside of its direct scope.\n How it works So what does the compiler do to make this work?\nWe can use sharplab.io to see exactly how this code is lowered:\n1 2 3 4 5 6 7 8 9  var func2 = GetFunction2(); Console.WriteLine(func2()); Func\u0026lt;string\u0026gt; GetFunction2() { int intValue = 12; return () =\u0026gt; $\u0026#34;String created by GetFunction, value of {intValue}\u0026#34;; }   The lowered code is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  [assembly: CompilationRelaxations(8)] [assembly: RuntimeCompatibility(WrapNonExceptionThrows = true)] [assembly: Debuggable(DebuggableAttribute.DebuggingModes.IgnoreSymbolStoreSequencePoints)] [assembly: SecurityPermission(SecurityAction.RequestMinimum, SkipVerification = true)] [assembly: AssemblyVersion(\u0026#34;0.0.0.0\u0026#34;)] [module: UnverifiableCode] [CompilerGenerated] internal static class \u0026lt;Program\u0026gt;$ { private sealed class \u0026lt;\u0026gt;c__DisplayClass0_0 { public int intValue; internal string \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__1() { return string.Format(\u0026#34;String created by GetFunction, value of {0}\u0026#34;, intValue); } } private static void \u0026lt;Main\u0026gt;$(string[] args) { Console.WriteLine(\u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__GetFunction2|0_0()()); } internal static Func\u0026lt;string\u0026gt; \u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;g__GetFunction2|0_0() { \u0026lt;\u0026gt;c__DisplayClass0_0 \u0026lt;\u0026gt;c__DisplayClass0_ = new \u0026lt;\u0026gt;c__DisplayClass0_0(); \u0026lt;\u0026gt;c__DisplayClass0_.intValue = 12; return new Func\u0026lt;string\u0026gt;(\u0026lt;\u0026gt;c__DisplayClass0_.\u0026lt;\u0026lt;Main\u0026gt;$\u0026gt;b__1); } }   Obviously this can get more complicated and complex depending on the use case, but essentially what the compiler is doing is as follows:\n Lines 10-18: A \u0026ldquo;dummy\u0026rdquo; class (\u0026lt;\u0026gt;c__DisplayClass0_0) is created which contains the variable required, and the Func is converted to a method on the class Lines 25-29: A method is created which instantiates the above class, sets the variable value and then invokes the method (which was the Func) Lines 22: The above method is invoked, creating the class, setting the value and outputting the result   Variable not value One final example, show that the closure uses the variable, not the value:\n1 2 3 4  int localInt = 100; Func\u0026lt;string\u0026gt; localFunc = () =\u0026gt; $\u0026#34;The value of localInt is: {localInt}\u0026#34;; localInt = 150; Console.WriteLine(localFunc());    Lines 2: A Func is defined, which outputs the value of localInt. At the time the function is created, the localInt value is 100 Lines 3: localInt value is increased to 150 Lines 4: The Func is invoked, with the localInt value at 150  The output:\n1  The value of x is: 150   As mentioned, the closure uses the variable (which can change value) and not the value when it was created.\n Notes Closures are easy to use and implement, but this is enabled by the compiler doing lots of work behind the scenes. They are another useful tool to be aware of when coding and thinking through how the code might fit together.\n References A Simple Explanation of C# Closures\nHow to use closures in C#\n     Daily Drop 32: 16-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-16T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/16-closures/","title":"Closures explained"},{"content":"Daily Knowledge Drop The current convention/standard/best practice when it comes to naming private fields on a class, is to prefix the name with an underscore. Turns out, that this convention is all due to a misunderstanding!\n Explained In version 1.0 of the C# language specification, there was a reference to this and underscore. From page 213 of the spec:\n1 2 3 4 5 6 7 8 9  public class Nested { C this_c; public Nested(C c) { this_c = c; } public void G() { Console.WriteLine(this_c.i); } }   At the time, C# didn\u0026rsquo;t have the ability to uniquely identify private class members, so the initial convention was this_privateMember, as seen on line 2, 4 and 7.\nOver time as the language evolved, the this portion was dropped, and _privateMember was being used. No real reason for this, apart from a misunderstanding by some in thinking that the underscore was the main key in identifying a private class member.\nOver time, this has been widely adopted and is now the convention - but in reality the underscore was just used as a separator between this and the privateMember, to uniquely identify the variable as private.\n Notes Although the convention may have it roots in a misunderstanding, I still prefer it over using this.privateMember (or any other convention), so will continue to prefix my private variables with underscore.\n References Github Issue\nC# 1.0 specification\n     Daily Drop 31: 15-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-15T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/15-private-underscore/","title":"Private variables prefixed with underscore?"},{"content":"Daily Knowledge Drop There is a helper IsDefined method on the Enum class, which will check if a numerical value is valid for a specific enum type.\n IsDefined method Assume an enum is defined as below:\n1 2 3 4 5 6 7  public enum Direction { North, East, South, West }   The IsDefined can be invoked as follows:\n1 2 3 4  bool IsEnumDefined(int direction) { return Enum.IsDefined(typeof(Direction), direction); }   The method takes in the enum type, as well as the numerical value and validates if the enum defines a value for the numerical value.\nThis is pretty straightforward and useful, especially for confirming the validity of an enum is the data is being sent from a 3rd party as an int value.\n Performance While IsDefined is easy to use, one negative aspect is that it is slow. Very slow (in comparison).\nConsider this switch statement which effectively returns the same validation result as the IsDefined method:\n1 2 3 4 5 6 7 8 9 10 11 12 13  bool IsEnumSwitch(int direction) { switch(direction) { case 0: case 1: case 2: case 3: return true; default: return false; } }   Here the enum values are hardcoded, and the method checks if the supplied numerical value is part the hardcoded list.\nUsing BenchmarkDotNet to run a simple benchmark, we can see that the switch is orders of magnitude faster than the IsDefined method.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [Benchmark(Baseline=true)] public void IsEnumDefined_Benchmark() { for(int i = 0; i \u0026lt; 100; i++) { _ = IsEnumDefined(i); } } [Benchmark] public void SwitchStatement_Benchmark() { for (int i = 0; i \u0026lt; 100; i++) { _ = IsEnumSwitch(i); } }   The results:\n   Method Mean Error StdDev Ratio Gen 0 Allocated     IsEnumDefined_Benchmark 8,566.83 ns 119.527 ns 111.806 ns 1.000 0.3815 2,400 B   SwitchStatement_Benchmark 33.34 ns 0.670 ns 0.689 ns 0.004 - -     Switch expression A big negative aspect of the switch approach, is that if the enum is very large, the switch will end up just just as big. The switch expression can assist here (assuming all the enum values are consecutive):\n1 2 3 4 5  bool IsEnumSwitchExp(int direction) =\u0026gt; direction switch { \u0026lt;= 3 =\u0026gt; true, _ =\u0026gt; false, };   Here instead of listing each value of the enum, the numerical value is just checked to make sure its equal to or smaller than the maximum enum value.\nThe same test is executed:\n1 2 3 4 5 6 7 8  [Benchmark] public void SwitchExp_Benchmark() { for (int i = 0; i \u0026lt; 100; i++) { _ = IsEnumSwitchExp(i); } }   The results - the switch statement and switch expression are basically identical.\n   Method Mean Error StdDev Ratio Gen 0 Allocated     IsEnumDefined_Benchmark 8,566.83 ns 119.527 ns 111.806 ns 1.000 0.3815 2,400 B   SwitchExp_Benchmark 33.11 ns 0.672 ns 0.773 ns 0.004 - -   SwitchStatement_Benchmark 33.34 ns 0.670 ns 0.689 ns 0.004 - -    Notes While the IsDefined method is very useful, the trade off comes with (relative) slow performance. If this function is used often on a hot path, it might make more sense to trade it out for a switch statement or switch expression, even though it might take more work maintaining the code.\n References Bartosz Adamczewski tweet\n     Daily Drop 30: 14-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-14T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/14-enum-isdefined/","title":"Enum validity with IsDefined"},{"content":"Daily Knowledge Drop There are numerous ways of handling the multiple case switch statement/expression in C#, and these various methods have evolved over time as C# language features have been introduced and enhanced.\nToday we\u0026rsquo;ll look at a few of these ways, specifically around having multiple cases returning the same result.\n Switch statement With the traditional switch statement, each case needs to be specified explicitly (except for the default case). This can become very long and tedious if there are many different cases. Prior to C#7, this was the only option:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  public string TraditionalSwitch(int temperature) { if (temperature \u0026lt; 0) { return \u0026#34;Unnaturally cold\u0026#34;; } switch (temperature) { case 0: case 1: case 2: case 3: case 4: case 5: case 6: case 7: case 8: case 9: case 10: return \u0026#34;Cold\u0026#34;; case 11: case 12: case 13: case 14: case 15: case 16: case 17: case 18: case 19: case 20: return \u0026#34;Moderate\u0026#34;; case 21: case 22: case 23: case 24: case 25: case 26: case 27: case 28: case 29: case 30: return \u0026#34;Hot\u0026#34;; case 31: case 32: case 33: case 34: case 35: case 36: case 37: case 38: case 39: case 40: return \u0026#34;Very Hot\u0026#34;; default: return \u0026#34;Surface of the sun\u0026#34;; } }    Switch with when C#7 introduced the ability to use the when keyword, in conjunction with and (\u0026amp;\u0026amp;) and or (||) operators, which simplified and reduced the amount of code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public string WhenExpressionSwitch(int temperature) { switch (temperature) { case var t when temperature \u0026lt; 0: return \u0026#34;Unnaturally cold\u0026#34;; case var t when temperature \u0026gt; 0 \u0026amp;\u0026amp; temperature \u0026lt; 11: return \u0026#34;Cold\u0026#34;; case var t when temperature \u0026gt; 11 \u0026amp;\u0026amp; temperature \u0026lt; 21: return \u0026#34;Moderate\u0026#34;; case var t when temperature \u0026gt; 21 \u0026amp;\u0026amp; temperature \u0026lt; 31: return \u0026#34;Hot\u0026#34;; case var t when temperature \u0026gt; 31: return \u0026#34;Very Hot\u0026#34;; default: return \u0026#34;Surface of the sun\u0026#34;; } }    Switch assignment C#8 introduced the ability to assign the value returned from a switch, instead of just using it to control logic flow:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public string AssignmentSwitchExpression(int temperature) { var result = temperature switch { var t when temperature \u0026lt; 0 =\u0026gt; \u0026#34;Unnaturally cold\u0026#34;, var t when temperature \u0026gt; 0 \u0026amp;\u0026amp; temperature \u0026lt; 11 =\u0026gt; \u0026#34;Cold\u0026#34;, var t when temperature \u0026gt; 11 \u0026amp;\u0026amp; temperature \u0026lt; 21 =\u0026gt; \u0026#34;Moderate\u0026#34;, var t when temperature \u0026gt; 21 \u0026amp;\u0026amp; temperature \u0026lt; 31 =\u0026gt; \u0026#34;Hot\u0026#34;, var t when temperature \u0026gt; 31 =\u0026gt; \u0026#34;Very Hot\u0026#34;, _ =\u0026gt; \u0026#34;Surface of the sun\u0026#34; }; return $\u0026#34;It is {result}\u0026#34;; }    Switch expression C#8 also introduced the ability to create a switch expression from a method, again to simplify and reduce code:\n1 2 3 4 5 6 7 8 9  public string SwitchExpression(int temperature) =\u0026gt; temperature switch { _ when temperature \u0026lt; 0 =\u0026gt; \u0026#34;Unnaturally cold\u0026#34;, _ when temperature \u0026gt; 0 \u0026amp;\u0026amp; temperature \u0026lt; 11 =\u0026gt; \u0026#34;Cold\u0026#34;, _ when temperature \u0026gt; 11 \u0026amp;\u0026amp; temperature \u0026lt; 21 =\u0026gt; \u0026#34;Moderate\u0026#34;, _ when temperature \u0026gt; 21 \u0026amp;\u0026amp; temperature \u0026lt; 31 =\u0026gt; \u0026#34;Hot\u0026#34;, _ when temperature \u0026gt; 31 =\u0026gt; \u0026#34;Very Hot\u0026#34;, _ =\u0026gt; \u0026#34;Surface of the sun\u0026#34; };   In this example, the discard character (_), is also used instead of an unused variable as in the previous example.\nMulti value switch expression With C#8, multiple values can also be used when checking the switch condition. In the below example, the two values are converted to a tuple and then the tuple is used in the switch expression:\n1 2 3 4 5 6 7 8  public string SwitchExpression(int temperature, SkyOutlook sky) =\u0026gt; (temperature, sky) switch { _ when temperature \u0026lt; 0 \u0026amp;\u0026amp; sky == SkyOutlook.Sunny =\u0026gt; \u0026#34;Cold but hot\u0026#34;, _ when temperature \u0026lt; 0 \u0026amp;\u0026amp; sky == SkyOutlook.Rainy =\u0026gt; \u0026#34;Actually snowing\u0026#34;, _ when temperature \u0026gt; 31 \u0026amp;\u0026amp; sky == SkyOutlook.Sunny =\u0026gt; \u0026#34;Get to air-con\u0026#34;, _ =\u0026gt; \u0026#34;Unable to determine\u0026#34; };    Switch on a class - part 1 Another C#8 enhancement, was the ability to use a class in the switch expression and switch on a class property(s).\nConsider a Person class which contains a person\u0026rsquo;s name and age:\n1 2 3 4 5 6 7 8  public string ClassSwitchExpression(Person person) =\u0026gt; person switch { { Age: \u0026lt; 10 } =\u0026gt; \u0026#34;Younger than 10\u0026#34;, { Age: \u0026lt; 20 } =\u0026gt; \u0026#34;Younger than 20\u0026#34;, { Age: \u0026lt; 30 } =\u0026gt; \u0026#34;Younger than 30\u0026#34;, { Age: \u0026lt; 50 } =\u0026gt; \u0026#34;Younger than 50\u0026#34;, _ =\u0026gt; \u0026#34;Older than 50\u0026#34; };    Switch on a class - part 2 When using a class to switch on, its also possible to use properties of a child class in the condition.\nConsider the Person class has a Country property, which is the Country class. The Country class has a Hemisphere property indicating northern or southern hemisphere:\n1 2 3 4 5 6 7 8 9 10 11  public string EnhancedClassSwitchExpressionCountry(Person person) =\u0026gt; person switch { { Age: \u0026lt; 10 } =\u0026gt; \u0026#34;Younger than 10\u0026#34;, { Age: \u0026gt;= 10 and \u0026lt; 20 } =\u0026gt; \u0026#34;Between 10 and 20\u0026#34;, { Age: \u0026gt;= 20 and \u0026lt; 30, Country: { Hemisphere: \u0026#34;North\u0026#34; } } =\u0026gt; \u0026#34;Between 19 and 30, living in north hemisphere\u0026#34;, { Age: \u0026gt;= 20 and \u0026lt; 30, Country: { Hemisphere: \u0026#34;South\u0026#34; } } =\u0026gt; \u0026#34;Between 19 and 30, living in south hemisphere\u0026#34;, { Age: \u0026gt;= 30 and \u0026lt; 50 } =\u0026gt; \u0026#34;Between 29 and 40\u0026#34;, _ =\u0026gt; \u0026#34;Older than 50\u0026#34; };    Switch on a class - part 3 C#10 cleaned up the syntax, which allowed for easier access to the properties of the child class:\n1 2 3 4 5 6 7 8 9 10 11  public string EnhancedClassSwitchExpressionCountry2(Person person) =\u0026gt; person switch { { Age: \u0026lt; 10 } =\u0026gt; \u0026#34;Younger than 10\u0026#34;, { Age: \u0026gt;= 10 and \u0026lt; 20 } =\u0026gt; \u0026#34;Between 10 and 20\u0026#34;, { Age: \u0026gt;= 20 and \u0026lt; 30, Country.Hemisphere: \u0026#34;North\u0026#34; } =\u0026gt; \u0026#34;Between 19 and 30, living in north hemisphere\u0026#34;, { Age: \u0026gt;= 20 and \u0026lt; 30, Country.Hemisphere: \u0026#34;South\u0026#34; } =\u0026gt; \u0026#34;Between 19 and 30, living in south hemisphere\u0026#34;, { Age: \u0026gt;= 30 and \u0026lt; 50 } =\u0026gt; \u0026#34;Between 29 and 40\u0026#34;, _ =\u0026gt; \u0026#34;Older than 50\u0026#34; };    Notes From a basic switch statement to a switch expression, with multiple conditional enhancement the switch functionality has evolved and continues to evolve to make it more feature rich and easier to use for developers.\n References What\u0026rsquo;s new in C# 8.0\nWhat\u0026rsquo;s new in C# 9.0\nC#10 Extended property patterns\n     Daily Drop 29: 11-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-11T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/11-switch-multi-case/","title":"Evolution of multi case switch statements"},{"content":"Daily Knowledge Drop The term duck typing refers to the ability to allow for an object to be passed to a method which expects a certain type, even if the object doesn\u0026rsquo;t inherit from the type.\nThis is more prevalent in dynamic languages and less prevalent in strong type languages, such as C# - however it is still occasionally used.\n Duck typing summary The term duck typing is explained by the populate phrase: If it walks like a duck, and quacks like a duck, it must be a duck\nHow does this relate to code? If a method expects a certain object type as a parameter, and invokes a method on this parameter - with duck typing, a different object with the same method could be used instead of the specified type.\nIf object type B, looks like object type A, then it must be of type A - and can be used instead of type A.\n Valid example The following C# sample is valid in demonstrating duck typing, however it WILL NOT COMPILE, but it gives an example of how duck typing works:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public class Duck { public int NumberOfWings { get; set; } public void MakeSound() { Console.WriteLine(\u0026#34;Quack\u0026#34;); } } public class Car { public int NumberOfWheels { get; set; } public void MakeSound() { Console.WriteLine(\u0026#34;Vroom\u0026#34;); } } public class NoiseMaker { public void MakeNoise(Duck entity) { entity.MakeSound(); } } var duck = new Duck(); var car = new Car(); var noiseMaker = new NoiseMaker(); noiseMaker.MakeNoise(duck); // a strong type lang such as C# // does not approve of or allow this noiseMaker.MakeNoise(car);   With duck typing, the above scenario would be allowed. This is because:\n Both Duck and Car entities have a method called MakeSound(), with the same signature The MakeNoise() method only uses the common MakeSound() method, and not either of the fields which are not common (NumberOfWings or NumberOfWheels)  In this setup, according to MakeNoise(), a Car looks like a Duck, and therefor can be used instead.\n Invalid example If the MakeNoise method was altered to also access the NumberOfWings property, then duck typing would no longer apply:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class NoiseMaker { public void MakeNoise(Duck entity) { entity.MakeSound(); duck.NumberOfWings = 2; } } var duck = new Duck(); var car = new Car(); var noiseMaker = new NoiseMaker(); noiseMaker.MakeNoise(duck); // Not allowed by C#, BUT ALSO not // allowed according to duck typing  // as Car no longer looks like a Duck noiseMaker.MakeNoise(car);   With duck typing, the above scenario would NOT be allowed. This is because:\n Both Duck and Car entities have a method called MakeSound(), with the same signature The MakeNoise() method uses the common MakeSound() method, however is also uses the NumberOfWings property, which a Car doesn\u0026rsquo;t have.  In this setup a Car does not look like a Duck, according to MakeNoise()\n Valid C# example The above examples are not valid in C#, as it\u0026rsquo;s a strong-type language which doesn\u0026rsquo;t do a check by similarity, but rather by name/type.\nHowever there are examples of C# using Duck Typing. A good example of this is GetEnumerator, outlined in this post\nTo add the ability to use foreach on a class, all that is required is that a GetEnumerator method be added to the class, it\u0026rsquo;s not required to be of any type or implement any interface.\nIf it looks like an enumerator (has a GetEnumerator method), then it is an enumerator!\n Notes Duck typing is not especially useful or practical in C#, however its a useful general programming concept to know and also to know C# does leverage it occasionally.\n References How Duck Typing Benefits C# Developers\n     Daily Drop 28: 10-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-10T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/10-duck-typing/","title":"Duck typing in C#"},{"content":"Daily Knowledge Drop The loading of (large) objects can be deferred until they are actually used and required using the Lazy\u0026lt;\u0026gt; class\n Sample Use case In our use case, we have a FileEntity which contains details about a file in a specific location. There are two child entities which are properties to FileEntity:\n FileSize: stores the file size in bytes (and just stores a double value, so is small) FileContents: stores the contents of the file as a string (depending on the size of the file, this can obviously be very large)  The contents of the file will not always be used and are potentially very large - so let\u0026rsquo;s look at how we can defer loading the data until it is actually used and required.\n The setup 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  // the main file entity class public class FileEntity { // a normal FileContentsEntity private variable, // just wrapped in Lazy\u0026lt;\u0026gt;  private readonly Lazy\u0026lt;FileContentsEntity\u0026gt; _fileContents; public Guid Id { get; } public string FileLocation { get; } public FileSizeEntity FileSize { get; } // when accessed, return Lazy\u0026lt;FileContentsEntity\u0026gt;.Value public FileContentsEntity FileContents =\u0026gt; _fileContents.Value; public FileEntity(Guid id, string fileLocation, double fileSizeInBytes) { Console.WriteLine(\u0026#34;FileEntity constructed\u0026#34;); Id = id; FileLocation = fileLocation; FileSize = new FileSizeEntity(fileSizeInBytes); // instead of instantiating the fileContents, // instantiate Lazy\u0026lt;\u0026gt; with an startup method _fileContents = new Lazy\u0026lt;FileContentsEntity\u0026gt;(LoadFileContents); } // method to load the large data volume private FileContentsEntity LoadFileContents() { return new FileContentsEntity(FileLocation); } } // simple entity to store the file size public class FileSizeEntity { public double FileSizeInBytes { get; set; } public FileSizeEntity(double fileSizeInBytes) { Console.WriteLine(\u0026#34;FileSizeEntity constructed\u0026#34;); FileSizeInBytes = fileSizeInBytes; } } // simple entity to store the file contents public class FileContentsEntity { public string LargeStringValue { get; set; } public FileContentsEntity(string fileLocation) { Console.WriteLine($\u0026#34;FileContentsEntity loaded from \u0026#39;{fileLocation}\u0026#39;\u0026#34;); LargeStringValue = \u0026#34;LargeStringValue\u0026#34;; } }   To use Lazy\u0026lt;\u0026gt;, the setup is almost exactly the same as without using Lazy\u0026lt;\u0026gt;.\n Line 6: The object we want to load lazily, FileContentsEntity is wrapped in Lazy\u0026lt;\u0026gt; Line 17: Instead of instantiating FileContentsEntity directly, its instantiated to Lazy\u0026lt;\u0026gt; with a load method Line 31-34: Method which loads the (potentially large) file contents  Output So what does the Lazy\u0026lt;\u0026gt; actually enable, and how does it effect execution?\n1 2 3 4 5 6 7 8 9 10 11 12 13  Console.WriteLine(\u0026#34;== pre initialization ==\u0026#34;); var file1 = new FileEntity(Guid.NewGuid(), @\u0026#34;C:\\small-file.txt\u0026#34;, 100); var file2 = new FileEntity(Guid.NewGuid(), @\u0026#34;C:\\large-file.txt\u0026#34;, 1073741824); Console.WriteLine(\u0026#34;== post initialization ==\u0026#34;); Console.WriteLine(\u0026#34;\u0026#34;); Console.WriteLine(\u0026#34;Accessing file1 contents\u0026#34;); var file1Location = file1.FileContents; Console.WriteLine(\u0026#34;Accessing file2 location\u0026#34;); var fileContents = file2.FileLocation;    Line 3-4: Two FileEntity instances are created, one with a small file and one with a large file Line 10: With file1 the large FileContents is accessed Line 10: With file2 only the FileLocation is accessed  1 2 3 4 5 6 7 8 9 10  == pre initialization == FileEntity constructed FileSizeEntity constructed FileEntity constructed FileSizeEntity constructed == post initialization == Accessing file1 contents FileContentsEntity loaded from \u0026#39;C:\\small-file.txt\u0026#39; Accessing file2 location   The key take-away from the output, is that the large contents of file2 are never loaded, as they are never used.\n Thread safety There are additional considerations regarding thread safety and Lazy\u0026lt;\u0026gt;. These are not addressed in this post, but can be read in details in the reference below.\n Notes Lazy\u0026lt;\u0026gt; provides a simple and easy to use way to load objects only when they are uses - this is especially useful when the large object is not loaded on every code path. This can lead to better performance and memory usage.\n References LazyClass\n     Daily Drop 27: 09-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-09T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/09-lazy-class/","title":"Lazy loading objects with Lazy\u003c\u003e"},{"content":"Daily Knowledge Drop The format of how classes are displayed in the debugger can be customized, using a couple of methods.\n Sample All the samples below use an instance of the following simple entity class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // class definition public class Song { public int Id { get; set; } public string Name { get; set; } public string Artist { get; set; } public int YearReleased { get; set; } public int LengthInSeconds { get; set; } } // instance of the class var song = new Song { Id = 1, Name = \u0026#34;Everlong\u0026#34;, Artist = \u0026#34;Foo Fighters\u0026#34;, LengthInSeconds = 250, YearReleased = 1997 };   Default Display By default, the output of a class in the debugger uses the ToString method on a class. The default for this method on a class is the class namespace and name.\nThe output in the Watch Window as well as when hovering the cursor over the instance:\n Default output \nToString override The first approach in customizing the output is to override the ToString method on the class:\n1 2 3 4 5 6 7 8 9 10 11  public class Song { //... existing class properties omitted // ToString method overridden and customized public override string ToString() { return $\u0026#34;Song `{Name}` by \u0026#39;{Artist} released \u0026#34; + $\u0026#34;in \u0026#39;{YearReleased}\u0026#39; and is \u0026#39;{LengthInSeconds}\u0026#39; seconds long\u0026#34;; } }   This overridden ToString method is now used:\n ToString output \n DebuggerDisplay attribute In some use-cases, it might not be possible to use the ToString method, as it might be used in the functionality of the application in a specific format, and a different format is required for the debugger.\nThe next approach uses the DebuggerDisplay attribute - this is used to decorate the class with the format of the debugger display.\n1 2 3 4 5 6 7 8 9 10 11  [DebuggerDisplay(\u0026#34;{Name} by {Artist}\u0026#34;)] public class Song { //... existing class properties omitted public override string ToString() { return $\u0026#34;Song `{Name}` by \u0026#39;{Artist} released \u0026#34; + $\u0026#34;in \u0026#39;{YearReleased}\u0026#39; and is \u0026#39;{LengthInSeconds}\u0026#39; seconds long\u0026#34;; } }   The display in the debugger now uses the DebuggerDisplay format, while explicitly using the ToString method will return the ToString method format.\n DebuggerDisplay output \n External classes A 3rd party external class can also be targeted by the attribute.\nAssume Song is now a external 3rd party class (which cannot be modified), and has no DebuggerDisplay attribute:\n1 2 3 4 5 6 7 8 9 10  public class Song { //... existing class properties omitted public override string ToString() { return $\u0026#34;Song `{Name}` by \u0026#39;{Artist} released \u0026#34; + $\u0026#34;in \u0026#39;{YearReleased}\u0026#39; and is \u0026#39;{LengthInSeconds}\u0026#39; seconds long\u0026#34;; } }   In the Program.cs startup file, the \u0026lsquo;DebuggerDisplay` attribute is added with a specified Target:\n1 2 3 4 5 6 7 8 9 10 11 12  [assembly: DebuggerDisplay(\u0026#34;External: {Name} by {Artist}\u0026#34;, Target = typeof(Song))] var song = new Song { Id = 1, Name = \u0026#34;Everlong\u0026#34;, Artist = \u0026#34;Foo Fighters\u0026#34;, LengthInSeconds = 250, YearReleased = 1997 }; Console.WriteLine(song);   The format specified by the DebuggerDisplay outside the class, is now used:\n External DebuggerDisplay output \n Notes We\u0026rsquo;ve looked at a few useful ways in which the Visual Studio developer experience can be enhanced to improve the quality of life and productivity while working with a solution.\n(The same might be experienced in Visual Studio Code and Rider, but it was not tested as part of this post)\n References Debug attributes in .NET\n     Daily Drop 26: 08-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-08T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/08-debug-ouput/","title":"Customize debugger class display"},{"content":"Daily Knowledge Drop When requiring to abstract and inject a simple single method interface using dependency injection (DI), its possible to instead use a Func\u0026lt;\u0026gt; or a Delegate instead.\n Examples Suppose we want to inject the date time using dependency injection, instead of using DateTime.Now or DateTimeOffSet.Now.\nThere are a few reasons to do this:\n DateTime.Now returns the current system datetime. This does not account for users in different regions, daylight savings etc (this is a complex subject, see the NodaTime reference below for additional information) The current datetime is an external dependency - best practice is for all external dependencies to be abstracted, so that they can be mocked and successfully unit tested  There are a number of ways to tackle this requirement. In the below examples, we\u0026rsquo;ll take a look at the various approaches using System clock as well as a 3rd party library, NodaTime\nInterface The first approach is using an interface and implementation(s). This is the more traditional approach:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  // define the base interface public interface IClock { DateTimeOffset GetNow(); } // implementation using system clock public class SystemClock : IClock { public DateTimeOffset GetNow() { return DateTimeOffset.Now; } } // implementation using 3rd party NodaTime library public class NodaTimeClock : IClock { public DateTimeOffset GetNow() { return NodaTime.SystemClock.Instance .InUtc().GetCurrentOffsetDateTime().ToDateTimeOffset(); } }   This can then be added to the DI container and injected into the relevant constructor:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  var builder = WebApplication.CreateBuilder(args); builder.Services.AddTransient\u0026lt;IClock, NodaTimeClock\u0026gt;(); // OR // builder.Services.AddTransient\u0026lt;IClock, SystemClock\u0026gt;(); var app = builder.Build(); app.MapGet(\u0026#34;/currentdatetime\u0026#34;, (IClock clock) =\u0026gt; { return clock.GetNow(); }); app.Run();    Line 3-5: The relevant IClock implementation is added to the DI container. Line 9: The interface is injected into the constructor Line 1: The GetNow() method is called. The implementation can be switched out between NodaTimeClock and SystemClock without changing the endpoint method.  This will certainly work, and perhaps is even the \u0026ldquo;best\u0026rdquo; approach - but it does seem like overkill to create an interface and implementation for something as simple as getting the datetime.\n Func The next approach is injecting a Func\u0026lt;\u0026gt; into the DI container. A Func\u0026lt;\u0026gt; is a pointer to a method, which accepts zero or many parameters and has a return value.\nWe don\u0026rsquo;t need to interface and implementation, it can all be done while adding to the DI container (although you can certainly create a method separately and use that when adding to the DI container)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  var builder = WebApplication.CreateBuilder(args); // Add a Func which returns a DateTimeOffset // and define it as a lambda expression builder.Services.AddTransient\u0026lt;Func\u0026lt;DateTimeOffset\u0026gt;\u0026gt;( dt =\u0026gt; () =\u0026gt; { return DateTimeOffset.Now; }); // OR // builder.Services.AddTransient\u0026lt;Func\u0026lt;DateTimeOffset\u0026gt;\u0026gt;(dt =\u0026gt;  // () =\u0026gt; { return NodaTime.SystemClock.Instance // .InUtc().GetCurrentOffsetDateTime().ToDateTimeOffset(); }); var app = builder.Build(); // the Func can be injected app.MapGet(\u0026#34;/currentdatetime\u0026#34;, (Func\u0026lt;DateTimeOffset\u0026gt; now) =\u0026gt; { // call the Func like a method return now(); }); app.Run();    Line 5-6: The Func (pointer to a method) is added to the DI container, with the method being declared as well as a lambda expression Line 8-10: The same Func as above, just using NodaTime instead of the system clock Line 15: The Func is injected into the constructor Line 18: The Func is called like a method (as it is one)  Again , this approach will work - one drawback of this though, is the Func doesn\u0026rsquo;t give any context as to what the method actually does. Func\u0026lt;DateTimeOffset\u0026gt; doesn\u0026rsquo;t convey that when called, the current date time is being returned.\n Delegate The final approach is to use a delegate. A delegate is a type, which can be \u0026ldquo;instantiated\u0026rdquo; (just like other types), but points to a method not a value as such.\nFirst the delegate is defined:\n1  public delegate DateTimeOffset GetCurrentDateTime();   Next we inject into the DI container and tell it how to \u0026ldquo;instantiate\u0026rdquo; the type GetCurrentDateTime:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  var builder = WebApplication.CreateBuilder(args); builder.Services.AddTransient\u0026lt;GetCurrentDateTime\u0026gt;(dt =\u0026gt; () =\u0026gt; { return NodaTime.SystemClock.Instance .InUtc().GetCurrentOffsetDateTime().ToDateTimeOffset(); }); // OR //builder.Services.AddTransient\u0026lt;GetCurrentDateTime\u0026gt;(dt =\u0026gt;  // () =\u0026gt; { return DateTimeOffset.Now; }); var app = builder.Build(); app.MapGet(\u0026#34;/currentdatetime\u0026#34;, (GetCurrentDateTime now) =\u0026gt; { return now(); }); app.Run();    Line 3-5: GetCurrentDateTime is defined using the lambda expression, and injected into the DI container Line 7-8: The same as above, but using system clock Line 12: The delegate type is injected into the constructor Line 14: The delegate is called like a method (as it is one)  This approach has the benefit of the delegate being a type with a name which conveys what the method is doing -GetCurrentDateTime is informative.\n Notes Three different approaches to solving the same problem - there is no \u0026ldquo;right or wrong\u0026rdquo; (perhaps some are consider better best practice when compared with others). Each has their own pros and cons, which need to be evaluated and an informed decision made for each use case.\n References Dustin Moris Gorski tweet\nWhy does NodaTime exist?\n     Daily Drop 25: 07-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-07T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/07-di-func-delegate/","title":"Dependency Injection with Func and delegates"},{"content":"Daily Knowledge Drop Incremental source generators can be used to generated fixed code, which can be used in user code, which can then be used by the source generator to generate additional code.\nThis is done through the usage of RegisterPostInitializationOutput available to incremental generators.\nThis will make more sense as we look at an example. This example below is an extension of the example in last week\u0026rsquo;s \u0026ldquo;emitting source generated files\u0026rdquo; post.\n Source generators In short, a source generator is a piece of code which writes code. The functionality ships as part of Roslyn, the .NET Compiler Platform SDK.\nSource generators allow for the inspection of user code as compile time, and then based on specific criteria, can add additional code to the original code base, on the fly.\nLet\u0026rsquo;s look at a very simple example, and all it\u0026rsquo;s moving parts. In the example, based on a marker attribute being present on a class, an additional method called \u0026quot;WhoAmI\u0026quot; will be added to the class, which will return the class the method is a member of.\nAttribute declaration One big negative aspect of the above approach is where is the marker attribute mentioned declared?\nThe source generator is going to look for the marker attribute (called WhoAmIAttribute in this example), and then generate the additional source code based on this attribute. Generally there were two options for the location of this attribute:\n Make it a requirement that the user creates the attribute. The source generator will only look for the attribute by name, so as long as its named correctly, all is good Reference the attribute in another external dll/NuGet package  The incremental generator introduced in .NET6 provides another, (in some situations) more convenient way.\n Incremental generator Incremental generators are similar to normal source generators, but provide a hook which allows source code to be generated post initialization, before the full source generators execute.\nBasically, source code can be generated post initialization of the generator, separate to the actual code generated by the source generator.\nLet\u0026rsquo;s have a look at the incremental generator for the scenario described above.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  [Generator] public class WhoAmIIncrementalGenerator : IIncrementalGenerator { public void Initialize(IncrementalGeneratorInitializationContext context) { // Register the attribute source context.RegisterPostInitializationOutput(i =\u0026gt; { var attributeSource = @\u0026#34; namespace AutoGenerated { [AttributeUsage(AttributeTargets.Class)] public class WhoAmIAttribute : Attribute { public WhoAmIAttribute() { } } }\u0026#34;; i.AddSource(\u0026#34;WhoAmIAttribute.g.cs\u0026#34;, attributeSource); }); } }    Line 2: Instead of implementing ISourceGenerator, the generator implements IIncrementalGenerator Line 4: Instead of a GeneratorInitializationContext, the initialize method takes an IncrementalGeneratorInitializationContext parameter Line 7-20: The post initialization output is registered - in this case, it creates the marker attribute   Generation process The source generator and syntax receiver defined in the \u0026ldquo;emitting source generated files\u0026rdquo; post, stay exactly the same.\nPrior to the introduction of the incremental generator, the generation process would have been:\n Source generator(s) are initialized Marker attribute definition needs to be present (either by user or in an external library) Marker attribute is used in user code Source generator(s) are executed and scans user code for the marker attribute usage Relevant additional code is generated and output if marker attribute is found  However with the introduction of the incremental generator, the process changes slightly.\n Source generator(s) are initialized Incremental generator creates the marker attribute, this is now available to the user Marker attribute is used in user code Source generator(s) are executed and scans user code for the marker attribute Relevant additional code is generated and output if marker attribute is found   Constraints There are some constraints when using incremental generators:\n They cannot access user code - incremental generators do not have access to the user code base, and therefore can only generate fixed code Multiple project referencing issues - as the code being generated is fixed, if multiple projects in the solution reference the analyzer, the fixed code will be generated multiple times, causing the solution to be unable to compile   Notes Even with the limitations (for which there are techniques to over come) incremental generators are a useful tool when some pre-generator-execution logic need to occur.\n References Source Generators Solving the source generator \u0026lsquo;marker attribute\u0026rsquo; problem - Part 1\nSolving the source generator \u0026lsquo;marker attribute\u0026rsquo; problem - Part 2\n     Daily Drop 24: 04-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-04T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/04-incremental-generator/","title":"Incremental source generators"},{"content":"Daily Knowledge Drop To enable enumeration on a class (ability to foreach on the class), the only requirement is for a method named GetEnumerator to exist on the class.\nThere is no requirement for the class to implement any interface (IEnumerable, IEnumerator etc), just the presence of the method is enough.\n Without GetEnumerator Last week we looked at adding indexing to a class - adding enumeration is similar, so we\u0026rsquo;ll use similar examples.\nIn the examples below, we are using a ProductPrice entity. This class keeps some basic details of a product, as well as an array of prices, one price for each month of the year. So Prices[0] is the price for January, Prices[1] is the price for February and so on.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class ProductPrice { public int ProductId { get; set; } public string ProductName { get; set; } public decimal[] Prices { get; set; } public ProductPrice(int productId, string productName, decimal[] prices) { ProductId = productId; ProductName = productName; Prices = prices; } }   To iterate through each price for the product, we can do this via the Prices property exposed on the class.\n1 2 3 4 5 6 7  var pp = new ProductPrice(112, \u0026#34;Green t-shirt\u0026#34;, new decimal[] { 0, 0, 0, 100, 100, 80, 80, 50, 50, 100, 100, 60 }); foreach (var price in pp.Prices) { Console.WriteLine(price); }   This code will function just fine - however the ProductPrice class can be extended to make it more intuitive and easier to work with.\n With GetEnumerator The main purpose of the ProductPrice class is to store price information related to a product. So let\u0026rsquo;s update the class so that we can access a price directly, without going via the Price property.\nProductPrice class update:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class ProductPrice { public int ProductId { get; set; } public string ProductName { get; set; } // Now private private decimal[] Prices { get; } public ProductPrice(int productId, string productName, decimal[] prices) { ProductId = productId; ProductName = productName; Prices = prices; } public IEnumerator\u0026lt;decimal\u0026gt; GetEnumerator() { foreach (var price in Prices) yield return price; } }    Line 8: The Prices property is now private Line 17-21: A new method called GetEnumerator was added. The return type of the method is IEnumerator\u0026lt;T\u0026gt;, where T is the specific type being returned Line 19-20: The items in the underlying Prices array are yield returned one at a time  If unfamiliar with the yield keyword, in short it indicates that the method in which it appears is an iterator, and will return one item at a time, one for each iteration.\nThe ProductPrice class can now be used as follows:\n1 2 3 4 5 6 7 8  var pp = new ProductPrice(112, \u0026#34;Green t-shirt\u0026#34;, new decimal[] { 0, 0, 0, 100, 100, 80, 80, 50, 50, 100, 100, 60 }); // No need to go via Prices foreach (var price in pp) { Console.WriteLine(price); }    Line 5-8: The price can now be accessed directly, no need to go via Prices as before   Field enumeration Another use for GetEnumerator method is to be able to enumerate through each fields/property on a class.\nIn the below example, we have an Address class which has a number of string fields:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class Address { public string Number { get; set; } public string Line1 { get; set; } public string Line2 { get; set; } public string Suburb { get; set; } public string Town { get; set; } public string Province { get; set; } public Address(string number, string line1, string line2, string suburb, string town, string province) { Number = number; Line1 = line1; Line2 = line2; Suburb = suburb; Town = town; Province = province; } public IEnumerator\u0026lt;string\u0026gt; GetEnumerator() { yield return Number; yield return Line1; yield return Line2; yield return Suburb; yield return Town; yield return Province; } }    Line 31: The GetEnumerator method has been added even though this class doesn\u0026rsquo;t have an internal array of items to iterate over. Instead we will iterate over each property of the class.\nEach property of the class is yield returned one at a time (so each time the iterator is called, the next item will be returned)  This allows for accessing a property via an index. This can be leveraged to iteration through the properties on the class:\n1 2 3 4 5 6 7  var address = new Address(\u0026#34;11\u0026#34;, \u0026#34;Main Road\u0026#34;, \u0026#34;XYZ Estate\u0026#34;, \u0026#34;Suburb1\u0026#34;, \u0026#34;Town2\u0026#34;, \u0026#34;Province3\u0026#34;); foreach (var field in address) { Console.WriteLine(field); }   The output:\n1 2 3 4 5 6  11 Main Road XYZ Estate Suburb1 Town2 Province3    Notes Similarly to working with indexers, adding your own enumeration will generally not be required for everyday use. However its advantageous to know that the option exists, and is as simple as adding a GetEnumerator method to the class in question.\n      Daily Drop 23: 03-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-03T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/03-getenumerator/","title":"Enumeration on a custom class"},{"content":"Daily Knowledge Drop In additional to giving a parameter a default value, so that it can be omitted when calling a method, the Optional attribute can also be used allow for parameter omission.\n Parameter default values When defining a method, the parameters can be given a default value. This allows for the parameter to be omitted when calling the method:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  // both required MethodNoDefaults(\u0026#34;John\u0026#34;, 50); // all parameters are required when calling this method void MethodNoDefaults(string name, int age) { Console.WriteLine($\u0026#34;Parameters: Name=\u0026#39;{name}\u0026#39;, Age=\u0026#39;{age}\u0026#39;\u0026#34;); } //---------------------------------------- // name required, age optional MethodOneDefaultValue(\u0026#34;John\u0026#34;); // only the name parameter is required, age can be omitted // if omitted, the value of age will be -1 void MethodOneDefaultValue(string name, int age = -1) { Console.WriteLine($\u0026#34;Parameters: Name=\u0026#39;{name}\u0026#39;, Age=\u0026#39;{age}\u0026#39;\u0026#34;); } //---------------------------------------- // all parameters are optional MethodAllDefaultValues(\u0026#34;John\u0026#34;); MethodAllDefaultValues(age:20); MethodAllDefaultValues(); // both parameters are optional and can be omitted void MethodAllDefaultValues(string name = \u0026#34;\u0026#34;, int age = -1) { Console.WriteLine($\u0026#34;Parameters: Name=\u0026#39;{name}\u0026#39;, Age=\u0026#39;{age}\u0026#39;\u0026#34;); }   The output for the above method calls:\n1 2 3 4 5  Parameters: Name=\u0026#39;John\u0026#39;, Age=\u0026#39;50\u0026#39; Parameters: Name=\u0026#39;John\u0026#39;, Age=\u0026#39;-1\u0026#39; Parameters: Name=\u0026#39;John\u0026#39;, Age=\u0026#39;-1\u0026#39; Parameters: Name=\u0026#39;\u0026#39;, Age=\u0026#39;20\u0026#39; Parameters: Name=\u0026#39;\u0026#39;, Age=\u0026#39;-1\u0026#39;   One limitation of using the default value approach, is that optional parameters must appear after all required parameters. This might force the order of the parameters into an unwanted sequence.\n Optional attribute Instead of using default values, the Optional attribute can also be used to mark a parameter as optional:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  MethodOneOptional(\u0026#34;John\u0026#34;, 20); MethodOneOptional(age: 40); // first parameter is optional void MethodOneOptional([Optional]string name, int age) { Console.WriteLine($\u0026#34;Parameters: Name=\u0026#39;{name}\u0026#39;, Age=\u0026#39;{age}\u0026#39;\u0026#34;); } //---------------------------------------- MethodAllOptional(); // all parameters are optional void MethodAllOptional([Optional] string name, [Optional] int age) { Console.WriteLine($\u0026#34;Parameters: Name=\u0026#39;{name}\u0026#39;, Age=\u0026#39;{age}\u0026#39;\u0026#34;); }   The output being:\n1 2 3  Parameters: Name=\u0026#39;John\u0026#39;, Age=\u0026#39;20\u0026#39; Parameters: Name=\u0026#39;\u0026#39;, Age=\u0026#39;40\u0026#39; Parameters: Name=\u0026#39;\u0026#39;, Age=\u0026#39;0\u0026#39;   One advantage of using the Optional attribute, is that optional parameters can appear anywhere in the sequence of attributes, even before required parameters.\nThe disadvantage is that a default value cannot be specified for optional parameters and the type default value will be used.\n Notes The Optional attribute is another great option to know about, to be leveraged in the appropriate use case.\n      Daily Drop 22: 02-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-02T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/02-optional-param-attribute/","title":"Optional method parameters"},{"content":"Daily Knowledge Drop As part of .NET6, notification functionality was added to System.Text.Json, allowing for custom logic to be invoked during the serialization and deserializing of objects.\n New interfaces Four new interfaces were introduced which can be implemented, according to the requirements:\n IJsonOnSerialized IJsonOnSerializing IJsonOnDeserialized IJsonOnDeserializing  To receive notifications, the class being serialized/deserialized, needs to implement one or many of the above interfaces.\nExample For the examples below, consider a Song class, which has certain required fields in order to be valid.\nBefore the Song is serialized (to be sent to a message broker, for instance) we need to ensure it is valid, and the same when deserializing it (consuming from a message broker, for instance).\nValidation without notifications The class contains a ValidateSong method which will throw an exception if the class is not in a valid state.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  public class Song { public int Id { get; set; } public string Name { get; set; } public string Artist { get; set; } public int YearReleased { get; set; } public int LengthInSeconds { get; set; } public void ValidateSong() { var errorList = new List\u0026lt;string\u0026gt;(); if(string.IsNullOrEmpty(Name)) { errorList.Add(\u0026#34;\u0026#39;Name\u0026#39; field is required\u0026#34;); } if (string.IsNullOrEmpty(Artist)) { errorList.Add(\u0026#34;\u0026#39;Artist\u0026#39; field is required\u0026#34;); } if(YearReleased \u0026lt;= 1900) { errorList.Add(\u0026#34;\u0026#39;YearReleased\u0026#39; must be greater than 1900\u0026#34;); } if(errorList.Count \u0026gt; 0) { throw new InvalidOperationException( string.Join(Environment.NewLine, errorList)); } } }   With this approach, before serialization and after deserialization, the ValidateSong method will need to be manually invoked to ensure the instance is valid.\n1 2 3 4 5 6 7 8 9 10 11 12  var song = new Song { Id = 1, Artist = \u0026#34;Foo Fighters\u0026#34;, LengthInSeconds = 250 }; song.ValidateSong(); var json = JsonSerializer.Serialize(song, new JsonSerializerOptions { WriteIndented = true }); Console.WriteLine(json);   With the required Name and YearReleased fields not supplied, the above results in the following output:\n1 2 3 4 5 6 7  Unhandled exception. System.InvalidOperationException: \u0026#39;Name\u0026#39; field is required \u0026#39;YearReleased\u0026#39; must be greater than 1900 at JsonNotifications.Song.ValidateSong() in C:\\Development\\Projects\\Blog\\JsonNotifications\\JsonNotifications\\Song.cs:line 46 at Program.\u0026lt;Main\u0026gt;$(String[] args) in C:\\Development\\Projects\\Blog\\JsonNotifications\\JsonNotifications\\Program.cs:line 14    Validation with notifications The new System.Text.Json interfaces can be leveraged to automate and simplify the validation process.\nThe updated Song class:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  public class Song : IJsonOnDeserialized, IJsonOnSerialized { public int Id { get; set; } public string Name { get; set; } public string Artist { get; set; } public int YearReleased { get; set; } public int LengthInSeconds { get; set; } public void OnDeserialized() =\u0026gt; ValidateSong(); public void OnSerialized() =\u0026gt; ValidateSong(); private void ValidateSong() { var errorList = new List\u0026lt;string\u0026gt;(); if(string.IsNullOrEmpty(Name)) { errorList.Add(\u0026#34;\u0026#39;Name\u0026#39; field is required\u0026#34;); } if (string.IsNullOrEmpty(Artist)) { errorList.Add(\u0026#34;\u0026#39;Artist\u0026#39; field is required\u0026#34;); } if(YearReleased \u0026lt;= 1900) { errorList.Add(\u0026#34;\u0026#39;YearReleased\u0026#39; must be greater than 1900\u0026#34;); } if(errorList.Count \u0026gt; 0) { throw new InvalidOperationException( string.Join(Environment.NewLine, errorList)); } } }   A few changes have been made compared to the previous approach:\n Line 1: The IJsonOnDeserialized and IJsonOnSerialized interfaces are implemented Line 13 \u0026amp; 15: The two methods specified by the two interfaces are implemented. Both will call the ValidateSong method Line 17: ValidateSong has been made private (this could have been kept public to still allow for external validation though)  With the relevant IJsonOnDeserialized and IJsonOnSerialized interfaces implemented, the respective OnDeserialized and OnSerialized methods are now invoked automatically during the serialization/deserialization process, which in turn invokes the ValidateSong method.\n1 2 3 4 5 6 7 8 9 10  var song = new Song { Id = 1, Artist = \u0026#34;Foo Fighters\u0026#34;, LengthInSeconds = 250 }; var json = JsonSerializer.Serialize(song, new JsonSerializerOptions { WriteIndented = true }); Console.WriteLine(json);   The output is the same as before (but with a different stacktrace)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  Unhandled exception. System.InvalidOperationException: \u0026#39;Name\u0026#39; field is required \u0026#39;YearReleased\u0026#39; must be greater than 1900 at JsonNotifications.Song.ValidateSong() in C:\\Development\\Projects\\Blog\\JsonNotifications\\JsonNotifications\\Song.cs:line 46 at JsonNotifications.Song.OnSerialized() in C:\\Development\\Projects\\Blog\\JsonNotifications\\JsonNotifications\\Song.cs:line 23 at System.Text.Json.Serialization.Converters.ObjectDefaultConverter`1 .OnTryWrite(Utf8JsonWriter writer, T value, JsonSerializerOptions options, WriteStack\u0026amp; state) at System.Text.Json.Serialization.JsonConverter`1 .TryWrite(Utf8JsonWriter writer, T\u0026amp; value, JsonSerializerOptions options, WriteStack\u0026amp; state) at System.Text.Json.Serialization.JsonConverter`1 .WriteCore(Utf8JsonWriter writer, T\u0026amp; value, JsonSerializerOptions options, WriteStack\u0026amp; state) at System.Text.Json.JsonSerializer.WriteUsingSerializer[TValue](Utf8JsonWriter writer, TValue\u0026amp; value, JsonTypeInfo jsonTypeInfo) at System.Text.Json.JsonSerializer.WriteStringUsingSerializer[TValue](TValue\u0026amp; value, JsonTypeInfo jsonTypeInfo) at System.Text.Json.JsonSerializer.Serialize[TValue](TValue value, JsonSerializerOptions options) at Program.\u0026lt;Main\u0026gt;$(String[] args) in C:\\Development\\Projects\\Blog\\JsonNotifications\\JsonNotifications\\Program.cs:line 16   The same would be experienced during deserialization, if the JSON being deserialization results in a Song with an invalid state, the exception will be thrown.\n Notes A very useful addition to the System.Text.Json suite of functionality - which has many possibilities beyond the above simple use case.\nThis approach does creates a hard dependency on System.Text.Json in the entity though - maybe not a problem, but it would need to be kept in mind and and an informed choice made for each use case.\n References Entity Framework Core 6 features - Notifications for (De)Serialization\n     Daily Drop 21: 01-03-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-03-01T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/03/01-json-notifications/","title":"System.Text.Json notifications"},{"content":"Daily Knowledge Drop The Column attribute, as well as the new HasColumnOrder fluent API can be used to determine the specifically order of sequence of columns in the table.\n Configurations previously In previous version of Entity Framework Core (EF) the order in which the columns were defined on the entity, where the order in which they were created on the table\n1 2 3 4 5 6 7 8 9 10 11 12  public class Song { public string Artist { get; set; } public int YearReleased { get; set; } public int Id { get; set; } public int LengthInSeconds { get; set; } public string Name { get; set; } }   The Up method migration created to create the table would look as below.\nThe exception is the Id primary key (PK) field which is automatically put first in the list as it\u0026rsquo;s a PK.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  migrationBuilder.CreateTable( name: \u0026#34;Songs\u0026#34;, columns: table =\u0026gt; new { Id = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false) .Annotation(\u0026#34;SqlServer:Identity\u0026#34;, \u0026#34;1, 1\u0026#34;), Artist = table.Column\u0026lt;string\u0026gt;(type: \u0026#34;nvarchar(max)\u0026#34;, nullable: false), YearReleased = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false), LengthInSeconds = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false), Name = table.Column\u0026lt;string\u0026gt;(type: \u0026#34;nvarchar(max)\u0026#34;, nullable: false) }, constraints: table =\u0026gt; { table.PrimaryKey(\u0026#34;PK_Songs\u0026#34;, x =\u0026gt; x.Id); });    Configuring the order Column attribute The Column attribute can now be used to decorate the entity and specify the column order.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Song { public string Artist { get; set; } [Column(Order = 1)] public int YearReleased { get; set; } public int Id { get; set; } [Column(Order = 99)] public int LengthInSeconds { get; set; } [Column(Order = 0)] public string Name { get; set; } }   The migration now looks as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  migrationBuilder.CreateTable( name: \u0026#34;Songs\u0026#34;, columns: table =\u0026gt; new { Name = table.Column\u0026lt;string\u0026gt;(type: \u0026#34;nvarchar(max)\u0026#34;, nullable: false), YearReleased = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false), LengthInSeconds = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false), Id = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false) .Annotation(\u0026#34;SqlServer:Identity\u0026#34;, \u0026#34;1, 1\u0026#34;), Artist = table.Column\u0026lt;string\u0026gt;(type: \u0026#34;nvarchar(max)\u0026#34;, nullable: false) }, constraints: table =\u0026gt; { table.PrimaryKey(\u0026#34;PK_Songs\u0026#34;, x =\u0026gt; x.Id); });   As you can see the Column attribute takes precedent over any columns without the attribute, and are ordered lowest to highest. The Id PK column still gets automatically ordered to the top of the columns without any ordering specified.\nIf specifically marked with the Column attribute and an order, the order of the PK_ column would be the order manually specified.\n HasColumnOrder method If the entity can\u0026rsquo;t be changed and the Column attribute added (e.g. its a 3rd party class) the fluent API can be used to specify the column order.\nGoing back to the entity without any Column attributes:\n1 2 3 4 5 6 7 8 9 10 11 12  public class Song { public string Artist { get; set; } public int YearReleased { get; set; } public int Id { get; set; } public int LengthInSeconds { get; set; } public string Name { get; set; } }   Instead now in the OnModelCreating method of the DbContext OR in a separate IEntityTypeConfiguration implementation for the table, the column is manually specified using the HasColumnOrder method.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity\u0026lt;Song\u0026gt;() .Property(p =\u0026gt; p.YearReleased) .HasColumnOrder(1); modelBuilder.Entity\u0026lt;Song\u0026gt;() .Property(p =\u0026gt; p.LengthInSeconds) .HasColumnOrder(99); modelBuilder.Entity\u0026lt;Song\u0026gt;() .Property(p =\u0026gt; p.Name) .HasColumnOrder(0); }   The migration generated is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  migrationBuilder.CreateTable( name: \u0026#34;Songs\u0026#34;, columns: table =\u0026gt; new { Name = table.Column\u0026lt;string\u0026gt;(type: \u0026#34;nvarchar(max)\u0026#34;, nullable: false), YearReleased = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false), LengthInSeconds = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false), Id = table.Column\u0026lt;int\u0026gt;(type: \u0026#34;int\u0026#34;, nullable: false) .Annotation(\u0026#34;SqlServer:Identity\u0026#34;, \u0026#34;1, 1\u0026#34;), Artist = table.Column\u0026lt;string\u0026gt;(type: \u0026#34;nvarchar(max)\u0026#34;, nullable: false) }, constraints: table =\u0026gt; { table.PrimaryKey(\u0026#34;PK_Songs\u0026#34;, x =\u0026gt; x.Id); });   As expected, its the same as using the Column attribute.\n Notes This new feature, while not ground-breaking, is another very useful small tool in the EF suite to allow for customization in how the database is scaffolded - and more (as simple as possible) configuration options is always a welcome addition.\n References Entity Framework Core 6 features - Part 1\n     Daily Drop 20: 28-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-28T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/28-ef-column-order/","title":"EF Core 6 column order"},{"content":"Daily Knowledge Drop A number of enhancements have been made to LINQ as part of .NET6 - one of those is the ability to set a default value to be returned from .FirstOrDefault().\n Examples List\u0026lt;\u0026gt; is being used in the below examples, but the method is available on all compatible types, not just List\u0026lt;\u0026gt;.\nSimple type list 1 2 3 4 5 6 7 8 9 10 11 12  // list of 11 integers var intValues = new List\u0026lt;int\u0026gt; { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }; // older method, value found in list Console.WriteLine(intValues.FirstOrDefault(i =\u0026gt; i \u0026gt; 4)); // older method, value not found in list Console.WriteLine(intValues.FirstOrDefault(i =\u0026gt; i \u0026gt; 20)); // new method, value not found in list // explicit default value returned Console.WriteLine(intValues.FirstOrDefault(i =\u0026gt; i \u0026gt; 20, -1));    Line 5: Returns the first value greater than 4. A value from the list will be returned Line 8: Returns the first value greater than 20. No qualifying value exists in the list, so the default value of type int will be returned (0 in this case) Line 12: Returns the first value greater than 20. No qualifying value exists in the list, and as the new method override is being used, the explicitly supplied default value will be returned (-1 in this case)  The output:\n1 2 3  5 0 -1    Complex type list The same process can be applied to more complex type. The below example uses a Person record (but the same would apply to a traditional class as well)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  var personValues = new List\u0026lt;Person\u0026gt; { new Person(\u0026#34;Dave\u0026#34;,30), new Person(\u0026#34;Nate\u0026#34;,45), new Person(\u0026#34;Pat\u0026#34;,60), new Person(\u0026#34;Taylor\u0026#34;,25), new Person(\u0026#34;Chris\u0026#34;,39) }; // old method, value found in the list Console.WriteLine(personValues.FirstOrDefault(p =\u0026gt; p.Age == 30)); // old method, value not found in the list Console.WriteLine(personValues.FirstOrDefault(p =\u0026gt; p.Name.StartsWith(\u0026#34;J\u0026#34;))); // new method, value not found in list // explicit default Person value returned Console.WriteLine(personValues.FirstOrDefault(p =\u0026gt; p.Name.StartsWith(\u0026#34;J\u0026#34;), new Person(\u0026#34;John Doe\u0026#34;, 0))); public record Person(string Name, int Age);    Line 10: Returns the first Person with age of 30. A value from the list will be returned Line 13: Returns the first Person whose name starts with \u0026ldquo;J\u0026rdquo;. No qualifying value exists in the list, so the default value of Person will be returned (null in this case) Line 17-18: Returns the first Person whose name starts with \u0026ldquo;J\u0026rdquo;. No qualifying value exists in the list, and as the new method override is being used, the explicitly supplied default value will be returned (Person initialized with \u0026ldquo;John Doe\u0026rdquo; and 0 in this case)  The output. The blank line indicates the null record returned from the 2nd call to FirstOrDefault():\n1 2 3  Person { Name = Dave, Age = 30 } Person { Name = John Doe, Age = 0 }    Empty list This method can also be used to return a specific default value in the case of an empty list.\n1 2 3 4 5 6 7  var stringValues = new List\u0026lt;string\u0026gt;(); // no values in the list, default value returned Console.WriteLine(stringValues.FirstOrDefault()); // no values in the list, explicit default value returned Console.WriteLine(stringValues.FirstOrDefault(\u0026#34;empty\u0026#34;));    Line 4: Returns the first value in the list. The list is empty, so the default value of string will be returned (empty string in this case) Line 7: Returns the first value in the list. The list is empty, and as the new method override is being used, the explicitly supplied default value will be returned (\u0026ldquo;empty\u0026rdquo; in this case)  The output is as follows, the blank line indicating the empty string returned from the 1st call to FirstOrDefault():\n1 2  empty    Conclusion A small, simple update made to LINQ, but nevertheless a very useful feature which I\u0026rsquo;m sure will get a fair amount of usage.\n      Daily Drop 19: 25-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-25T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/25-firstordefault-default/","title":"LINQ improvements - FirstOrDefault defaults"},{"content":"Daily Knowledge Drop Entity Framework Core has the concept of interceptors which allow for the insertion of custom logic during the query execution process.\nThere a number of real world applications for the functionality, for example:\n Caching and retrieval of data Logging query or diagnostics information under certain conditions Modifying the query parameters, such as the timeout under certain conditions   Interceptor structure Creating an interceptor is straight forward - a class is created which implements the abstract class DbCommandInterceptor, and then overrides the required relevant method(s).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class ExecutionThresholdInterceptor : DbCommandInterceptor { // declare const message string private const string executionRangeExceededMessage = \u0026#34;Query ran longer than expected. Milliseconds: {0}, Query: {1}\u0026#34;; // override the method executed when the datareader has been executed public override DbDataReader ReaderExecuted(DbCommand command, CommandExecutedEventData eventData, DbDataReader result) { // check how long the query took to execute // if its longer than the threshold if( eventData.Duration.TotalMilliseconds \u0026gt; 10) { // Log a rudimentary error message Console.WriteLine(executionRangeExceededMessage, eventData.Duration.TotalMilliseconds, command.CommandText); } return result; } }    Line 1: Implement from DbCommandInterceptor Line 8-9: Override the ReaderExecuted method which is invoked after the query is executed Line 13: Check the query execution length Line 16-17: If the execution length is over the threshold, log the information  There are a number of methods available for overriding, where custom logic can be executed. Each are called at a different stage of the query creation and execution process:\n   Method Information     CommandCreated Called immediately after EF calls CreateCommand()   CommandCreating Called just before EF intends to call CreateCommand()   CommandFailed Called when execution of a command has failed with an exception   CommandFailedAsync Called when execution of a command has failed with an exception   DataReaderDisposing Called when execution of a DbDataReader is about to be disposed   NonQueryExecuted Called immediately after EF calls ExecuteNonQuery()   NonQueryExecutedAsync Called immediately after EF calls ExecuteNonQueryAsync()   NonQueryExecuting Called just before EF intends to call ExecuteNonQuery()   NonQueryExecutingAsync Called just before EF intends to call ExecuteNonQueryAsync()   ReaderExecuted Called immediately after EF calls ExecuteReader()   ReaderExecutedAsync Called immediately after EF calls ExecuteReaderAsync()   ReaderExecuting Called just before EF intends to call ExecuteReader()   ReaderExecutingAsync Called just before EF intends to call ExecuteReaderAsync()   ScalarExecuted Called immediately after EF calls ExecuteScalar()   ScalarExecutedAsync Called immediately after EF calls ExecuteScalarAsync()   ScalarExecuting Called just before EF intends to call ExecuteScalar()   ScalarExecutingAsync Called just before EF intends to call ExecuteScalarAsync()     Interceptor configuration Once we have an interceptor defined (implementing DbCommandInterceptor), the next step is to make EF Core aware of it. This is done on the DbContext:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class EFInterceptorsContext : DbContext { public DbSet\u0026lt;Song\u0026gt; Songs { get; set; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseSqlServer( @\u0026#34;Server=.\\SQLEXPRESS;Database=EFInterceptors;Integrated Security=True\u0026#34;) // add the interceptor(s) .AddInterceptors(thresholdInterceptor); } private static readonly ExecutionThresholdInterceptor thresholdInterceptor = new ExecutionThresholdInterceptor(); }    Line 10: The interceptor is added to the EF configuration Line 13-14: Interceptors are often stateless, so a single interceptor instance can be used for all DbContext instances  Executing a query using the DbContext, we get the following output to the console window from the interceptor:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  Query ran longer than expected. Milliseconds: 25,089, Query: SELECT [t].[Artist], [t0].[YearReleased], [t0].[Id] FROM ( SELECT [s].[Artist] FROM [Song] AS [s] GROUP BY [s].[Artist] ) AS [t] OUTER APPLY ( SELECT DISTINCT [s0].[Id], [s0].[Artist], [s0].[LengthInSeconds], [s0].[Name], [s0].[YearReleased] FROM [Song] AS [s0] WHERE [t].[Artist] = [s0].[Artist] ) AS [t0] ORDER BY [t].[Artist]    Suppress Execution It is possible to suppress the execution of a query from an interceptor - however other installed interceptors will still be executed, so they will each need to check if the exception has been suppressed by a previous interceptor.\nIn this example below, we\u0026rsquo;ll configure two interceptors to be run before the query is executed:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // This interceptor will suppress the execution of the query if the // query is looking at the \u0026#34;Song\u0026#34; table public class TableDownInterceptor : DbCommandInterceptor { private const string suppressMessage = \u0026#34;Table \u0026#39;{0}\u0026#39;is not currently \u0026#34; + \u0026#34;available for querying. Query being suppressed: {1}\u0026#34;; public override InterceptionResult\u0026lt;DbDataReader\u0026gt; ReaderExecuting(DbCommand command, CommandEventData eventData, InterceptionResult\u0026lt;DbDataReader\u0026gt; result) { // very rudimentary check if (eventData.Command.CommandText.Contains(\u0026#34;[Song]\u0026#34;)) { Console.WriteLine(suppressMessage, \u0026#34;Song\u0026#34;, eventData.Command.CommandText); // Suppress the results with a custom empty data reader result = InterceptionResult\u0026lt;DbDataReader\u0026gt; .SuppressWithResult(new TableDownDataReader()); } return result; } }    Line 12: Simple check to see if the command text contains the \u0026ldquo;Song\u0026rdquo; table Line 14: Output a message indicating the query is being suppressed Line 16-17: Suppress the original result, with a custom empty data reader (see code below)  The custom DataReader looks as follows. It does nothing by return an empty dataset:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  internal class TableDownDataReader : DbDataReader { public override int FieldCount =\u0026gt; throw new NotImplementedException(); public override int RecordsAffected =\u0026gt; 0; public override bool HasRows =\u0026gt; false; public override bool IsClosed =\u0026gt; throw new NotImplementedException(); public override int Depth =\u0026gt; 0; public override bool Read() =\u0026gt; false; public override int GetInt32(int ordinal) =\u0026gt; 0; public override bool IsDBNull(int ordinal) =\u0026gt; false; public override string GetString(int ordinal) =\u0026gt; string.Empty; public override bool GetBoolean(int ordinal) =\u0026gt; throw new NotImplementedException(); public override byte GetByte(int ordinal) =\u0026gt; throw new NotImplementedException(); public override long GetBytes(int ordinal, long dataOffset, byte[] buffer, int bufferOffset, int length) =\u0026gt; throw new NotImplementedException(); public override char GetChar(int ordinal) =\u0026gt; throw new NotImplementedException(); public override long GetChars(int ordinal, long dataOffset, char[] buffer, int bufferOffset, int length) =\u0026gt; throw new NotImplementedException(); public override string GetDataTypeName(int ordinal) =\u0026gt; throw new NotImplementedException(); public override DateTime GetDateTime(int ordinal) =\u0026gt; throw new NotImplementedException(); public override decimal GetDecimal(int ordinal) =\u0026gt; throw new NotImplementedException(); public override double GetDouble(int ordinal) =\u0026gt; throw new NotImplementedException(); public override Type GetFieldType(int ordinal) =\u0026gt; throw new NotImplementedException(); public override float GetFloat(int ordinal) =\u0026gt; throw new NotImplementedException(); public override Guid GetGuid(int ordinal) =\u0026gt; throw new NotImplementedException(); public override short GetInt16(int ordinal) =\u0026gt; throw new NotImplementedException(); public override long GetInt64(int ordinal) =\u0026gt; throw new NotImplementedException(); public override string GetName(int ordinal) =\u0026gt; throw new NotImplementedException(); public override int GetOrdinal(string name) =\u0026gt; throw new NotImplementedException(); public override object GetValue(int ordinal) =\u0026gt; throw new NotImplementedException(); public override int GetValues(object[] values) =\u0026gt; throw new NotImplementedException(); public override object this[int ordinal] =\u0026gt; throw new NotImplementedException(); public override object this[string name] =\u0026gt; throw new NotImplementedException(); public override bool NextResult() =\u0026gt; throw new NotImplementedException(); public override IEnumerator GetEnumerator() { throw new NotImplementedException(); } }   Now we configure a second interceptor which will check if the first interceptor has suppressed the result, before executing it\u0026rsquo;s own logic:\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class LoggingInterceptor : DbCommandInterceptor { public override InterceptionResult\u0026lt;DbDataReader\u0026gt; ReaderExecuting( DbCommand command, CommandEventData eventData, InterceptionResult\u0026lt;DbDataReader\u0026gt; result) { if (!result.HasResult) { Console.WriteLine(eventData.Command.CommandText); } return result; } }    Line 7: Check if the result entity already has a value (supplied by the previous interceptor) and if so, then don\u0026rsquo;t execute the interceptor logic, as the result has already been handled.  Multiple interceptors can be added to EF Core:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class EFInterceptorsContext : DbContext { public DbSet\u0026lt;Song\u0026gt; Songs { get; set; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseSqlServer( @\u0026#34;Server=.\\SQLEXPRESS;Database=EFInterceptors;Integrated Security=True\u0026#34;) // add the interceptor(s) .AddInterceptors(tableDownInterceptor, loggingInterceptor); } private static readonly LoggingInterceptor loggingInterceptor = new LoggingInterceptor(); private static readonly TableDownInterceptor tableDownInterceptor = new TableDownInterceptor(); }   Running the same query as before we get the following output:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  Table \u0026#39;Song\u0026#39; is not currently available for querying. Query being suppressed: SELECT [t].[Artist], [t0].[YearReleased], [t0].[Id] FROM ( SELECT [s].[Artist] FROM [Song] AS [s] GROUP BY [s].[Artist] ) AS [t] OUTER APPLY ( SELECT DISTINCT [s0].[Id], [s0].[Artist], [s0].[LengthInSeconds], [s0].[Name], [s0].[YearReleased] FROM [Song] AS [s0] WHERE [t].[Artist] = [s0].[Artist] ) AS [t0] ORDER BY [t].[Artist]   Only the output logic from TableDownDataReader is executed, and not the output logic from LoggingInterceptor.\n Additional example Another interceptor example which wil log the query executed when an exception occurs. Generally the exception will be surfaced, but without the actual query being executed - knowing this can assist in narrowing down the root cause of the exception:\n1 2 3 4 5 6 7 8 9 10  public class ExceptionInterceptor : DbCommandInterceptor { private const string exceptionMessage = \u0026#34;Exception occurred running the following command: {0}\u0026#34;; public override void CommandFailed(DbCommand command, CommandErrorEventData eventData) { Console.WriteLine(exceptionMessage, eventData.Command.CommandText); } }    Notes Interceptors are very easy to setup, and can offer a wide range of real world applications. There are potential performance overheads intercepting every single query (and logging it, for example) - but as with most features, there is always a tradeoff (in this case between performance and usefulness), and these would need to be evaluated for each specific use case.\n References Interceptors\nDbCommandInterceptor Class\n     Daily Drop 18: 24-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-24T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/24-efcore-interceptors/","title":"Entity Framework Core interceptors"},{"content":"Daily Knowledge Drop Any (relevant) class can be extended so that it can be accessed as an array, using Indexers, just by adding a property to the class.\n Without indexers In the examples below, we are using a ProductPrice entity. This class keeps some basic details of a product, as well as an array of prices, one price for each month of the year. So Prices[0] is the price for January, Prices[1] is the price for February and so on.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class ProductPrice { public int ProductId { get; set; } public string ProductName { get; set; } public decimal[] Prices { get; set; } public ProductPrice(int productId, string productName, decimal[] prices) { ProductId = productId; ProductName = productName; Prices = prices; } }   To access a price for a specific month, we can do this via the Prices property exposed on the class\n1 2 3 4 5 6 7 8  var pp = new ProductPrice(112, \u0026#34;Green t-shirt\u0026#34;, new decimal[] { 0, 0, 0, 100, 100, 80, 80, 50, 50, 100, 100, 60 }); int month = 5; if (pp.Prices.Length \u0026gt;= month) { Console.Write(pp.Prices[month]); }   This code will function just fine - however the ProductPrice class can be extended to make it more intuitive and easier to work with.\n With indexers The main purpose of the ProductPrice class is to store price information related to a product. So let\u0026rsquo;s update the class so that we can access a price directly, without going via the Price property.\nProductPrice class update:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class ProductPrice { public int ProductId { get; set; } public string ProductName { get; set; } // Now private private decimal[] Prices { get; } public ProductPrice(int productId, string productName, decimal[] prices) { ProductId = productId; ProductName = productName; Prices = prices; } // this allows the class to be accessed as an array public decimal this[int index] { get { // do the length check internally if(Prices.Length \u0026gt;= index) return Prices[index]; return 0; } } // ability to confirm the length of the class public int Length =\u0026gt; Prices.Length; }    Line 8: The Prices property is now private Line 18-26: The indexer has been added. It uses the this[int index] format Line 23-24: Custom logic to check if trying to access an out of bound index, then return 0 (instead of throwing an exception) Line 29: Expose a Length property which will return the number of prices  The ProductPrice class can now be used as follows:\n1 2 3 4 5 6 7  var pp = new ProductPrice(112, \u0026#34;Green t-shirt\u0026#34;, new decimal[] { 0, 0, 0, 100, 100, 80, 80, 50, 50, 100, 100, 60 }); int month = 5; int invalidMonth = 100; Console.WriteLine(pp[month]); Console.WriteLine(pp[invalidMonth]);    Line 6: The price can now be accessed directly on the class using [], no need to go via Prices as before Line 7: An invalid month can be sent without bounds checking, as the class will perform the check internally  The output for the above is\n1 2  80 0    Field indexer Another use for indexers is to index the fields/properties on a class.\nIn the below example, we have an Address class which has a number of string fields:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class Address { public string Number { get; set; } public string Line1 { get; set; } public string Line2 { get; set; } public string Suburb { get; set; } public string Town { get; set; } public string Province { get; set; } public Address(string number, string line1, string line2, string suburb, string town, string province) { Number = number; Line1 = line1; Line2 = line2; Suburb = suburb; Town = town; Province = province; } // add indexer functionality public string this[int index] { // build up an array of all the properties,  // and then access the corresponding item get =\u0026gt; (new string[] { Number, Line1, Line2, Suburb, Town, Province }) [index]; } public int Length =\u0026gt; 6; }   The indexer functionality has been added, but the class contains no arrays to index.\n Line 31: An array is built up of all the properties on the class, and then accessed via the index  This allows for accessing a property via an index. This can be leveraged to iteration through the properties on the class:\n1 2 3 4 5 6 7  var address = new Address(\u0026#34;11\u0026#34;, \u0026#34;Main Road\u0026#34;, \u0026#34;XYZ Estate\u0026#34;, \u0026#34;Suburb1\u0026#34;, \u0026#34;Town2\u0026#34;, \u0026#34;Province3\u0026#34;); for (int i = 0; i \u0026lt; address.Length; i++) { Console.WriteLine(address[i]); }   The output:\n1 2 3 4 5 6  11 Main Road XYZ Estate Suburb1 Town2 Province3    Notes While extending a class to use indexers will generally not be required for everyday use, its advantageous to know that indexers exist and are available for the use cases where they will make working with the class a lot easier and intuitive.\n References Using indexers (C# Programming Guide)\n     Daily Drop 17: 23-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-23T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/23-indexers/","title":"Indexers - access a class as an array"},{"content":"Daily Knowledge Drop The output location of code created by a Roslyn source generator can be customized, so that the output file can be included in source control (to be included in code reviews for example).\nThis post will give a brief overview of source generators, and then show the default behavior and how it can be customized.\nThis post will not go into detail regarding the finer details of source generators - if you would like more details on source generators, see the reference links below.\n Source generators In short, a source generator is a piece of code which writes code. The functionality ships as part of Roslyn, the .NET Compiler Platform SDK.\nSource generators allow for the inspection of user code as compile time, and then based on specific criteria, can add additional code to the original code base, on the fly.\nLet\u0026rsquo;s look at a very simple example, and all it\u0026rsquo;s moving parts. In the example, based on an attribute being present on a class, an additional method called \u0026quot;WhoAmI\u0026quot; will be added to the class, which will return the class the method is a member of.\nThis code is very basic and by no means production ready.\n Define the qualifier For a class to qualify for the new WhoAmI method, it will need to be decorated with an attribute - so first the attribute is defined. This is not specific to source generators, just a normal C#attribute.\n1 2 3 4 5  [AttributeUsage(AttributeTargets.Class)] public class WhoAmIAttribute : Attribute { public WhoAmIAttribute() { } }    Find qualifying classes The next step is to setup the rule to find qualifying classes. This is done using an ISyntaxReceiver implementation. Roslyn will parse the entire code base and for each separate syntax node (each part of code) will call the ISyntaxReceiver implementation.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class WhoAmISyntaxReceiver : ISyntaxReceiver { // This is to store the class which qualified public ClassDeclarationSyntax QualifyingClass { get; private set; } public void OnVisitSyntaxNode(SyntaxNode syntaxNode) { // if the node is a class declaration if (syntaxNode is ClassDeclarationSyntax cds) { // check if the class is decorated  // with an attribute called \u0026#34;WhoAmI\u0026#34; if (cds.AttributeLists.SelectMany(al =\u0026gt; al.Attributes.Where(a =\u0026gt; a.Name.ToString().Equals(\u0026#34;WhoAmI\u0026#34;, StringComparison.InvariantCultureIgnoreCase) )).Any()) QualifyingClass = cds; } } }    Line 9: The type of the node is checked, and if its not a ClassDeclaration we can ignore as it will automatically not qualify Line 13-17: Check if there are any attributes decorating the class and which are called \u0026ldquo;WhoAmI\u0026rdquo; Line 18: Store the ClassDeclarationSyntax details of the class which qualified  This implementation, as well as the generator are created in a separate project called WhoAmI.Generator.\n Generate the code Next, is to setup the actual generator. The generator will received input from the ISyntaxReceiver implementation, generate the code as a string, and then output a C# file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  [Generator] public class WhoAmIGenerator : ISourceGenerator { public void Execute(GeneratorExecutionContext context) { WhoAmISyntaxReceiver syntaxReceiver = (WhoAmISyntaxReceiver)context.SyntaxReceiver; // just double check the type is not null ClassDeclarationSyntax qualifyingClass = syntaxReceiver.QualifyingClass; if (qualifyingClass is null) { return; } // add the generated implementation to the compilation SourceText sourceText = SourceText.From($@\u0026#34; namespace EmitGenerated; public partial class {qualifyingClass.Identifier} {{ public string WhoAmI() {{ return this.GetType().Name; }} }}\u0026#34;, Encoding.UTF8); context.AddSource($\u0026#34;{qualifyingClass.Identifier}.Generated.cs\u0026#34;, sourceText); } public void Initialize(GeneratorInitializationContext context) { // register the generator to receive notification from WhoAmISyntaxReceiver context.RegisterForSyntaxNotifications(() =\u0026gt; new WhoAmISyntaxReceiver()); } }    Line 10: Get the qualifying class from the receiver Line 17-26: Generate the required code as a string Line 28: Output the C# file with the given name and code Line 34: Register the receiver with the generator  This implementation, as well as the receiver mentioned above, are created in a separate project called WhoAmI.Generator.\n Project Reference Now we have to register the generator in the main project. The WhoAmI.Generator project (which contains the generator and the receiver) can be referenced as a normal Project Reference initially. However, the csproj then needs to be edited to indicate that the referenced project is a generator and not a normal project reference.\nThe OutputItemType and ReferenceOutputAssembly values are added. The relevant section in the csproj file will look as follows:\n1 2 3 4  \u0026lt;ItemGroup\u0026gt; \u0026lt;ProjectReference Include=\u0026#34;..\\WhoAmI.Generator\\WhoAmI.Generator.csproj\u0026#34; OutputItemType=\u0026#34;Analyzer\u0026#34; ReferenceOutputAssembly=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;/ItemGroup\u0026gt;    Implement and output Finally, it\u0026rsquo;s time to use the generator.\nA partial class is created, and decorated with the attribute:\n1 2  [WhoAmI] public partial class RandomClass { }   Even though the class doesn\u0026rsquo;t directly contain a method called WhoAmI, the generator will create the method in a separate file (which is allowed as the class is partial):\n1 2  var rc = new RandomClass(); Console.WriteLine(rc.WhoAmI());   The output:\n1  RandomClass   We are now able to call the WhoAmI method to find out the type.\nLimitations The advantage of generators is that the code is automatically generated at compile time, however the side-effect of this is that the code is not emitted to a file on disk. The only way to see the code generated it to browse to the file under Dependencies =\u0026gt; Analyzers.\n Generated output \nUp until now this process has worked and might suite your needs just fine. But if you need the generated file(s) to be code reviewed and committed to source control, the current setup will not allow that.\nNext we\u0026rsquo;ll look at how the process can be configured to emit the file.\n Customization Emit the file First, lets configure that the file should be emitted. This is done by adding an EmitCompilerGeneratedFiles node to the csproj file of the application.\n1 2 3  \u0026lt;PropertyGroup\u0026gt; \u0026lt;EmitCompilerGeneratedFiles\u0026gt;true\u0026lt;/EmitCompilerGeneratedFiles\u0026gt; \u0026lt;/PropertyGroup\u0026gt;   The file is now generated in the following location:\n{BaseIntermediateOutpath}/generated/{Assembly}/{SourceGeneratorName}/{GeneratedFile}\nTypically this could be the obj folder:\n Default emit output \n Change the location The CompilerGeneratedFilesOutputPath node can be added to control where file should be emitted to:\n1 2 3 4  \u0026lt;PropertyGroup\u0026gt; \u0026lt;EmitCompilerGeneratedFiles\u0026gt;true\u0026lt;/EmitCompilerGeneratedFiles\u0026gt; \u0026lt;CompilerGeneratedFilesOutputPath\u0026gt;SourceGenerated\u0026lt;/CompilerGeneratedFilesOutputPath\u0026gt; \u0026lt;/PropertyGroup\u0026gt;   The file is now generated in the following location:\n{CompilerGeneratedFilesOutputPath}/{Assembly}/{SourceGeneratorName}/{GeneratedFile}\n Custom emit output \n Fix errors As it stands now, the application won\u0026rsquo;t compile due to the following error:\n1  Type \u0026#39;RandomClass\u0026#39; already defines a member called \u0026#39;WhoAmI\u0026#39; with the same parameter types   We have configured the file to be emitted to the custom location, however the file is still also being emitted into memory and compiled as part of the source.\nKnowing this, the above error now makes sense - we have two files used in compilation, generating the same method.\nThe final step is to exclude the files emitted to disk from being used in the compilation. An ItemGroup is added to the csproj file, which instructions any cs files emitted to disk by the source generator to be excluded from compilation.\n1 2 3 4 5 6 7 8  \u0026lt;PropertyGroup\u0026gt; \u0026lt;EmitCompilerGeneratedFiles\u0026gt;true\u0026lt;/EmitCompilerGeneratedFiles\u0026gt; \u0026lt;CompilerGeneratedFilesOutputPath\u0026gt;SourceGenerated\u0026lt;/CompilerGeneratedFilesOutputPath\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;ItemGroup\u0026gt; \u0026lt;Compile Remove=\u0026#34;$(CompilerGeneratedFilesOutputPath)/**/*.cs\u0026#34; /\u0026gt; \u0026lt;/ItemGroup\u0026gt;   The files will still be emitted to disk, and so can be included in source control and code reviews, but are now marked to be excluded in the compilation process.\n Notes Source generators are a powerful tool to be leveraged to solve certain use cases - however the tooling to support them is not always as powerful. The ability to emit the files to disk can be used to assist with the development inner look to ensure the output code is correct, as well as included as part of source control to be properly reviewed.\n References Source Generators\nSaving source generator output in source control\n     Daily Drop 16: 22-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-22T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/22-emit-source-generator-files/","title":"Customize source generator output location"},{"content":"Daily Knowledge Drop A new attribute called EntityTypeConfiguration was introduced in Entity Framework 6, which allows for easier configuration of custom entity configurations.\nLet\u0026rsquo;s take a look at how is simplifies the configuration of an entity.\n Configurations previously There are a number of steps performed when manually configuring an entity using Entity Framework Core (EF).\nNote: The entity structure below is not optimized or suitable for a production system, it is used just for sample purposes\nDefine the entity In this example, we are going to be using a Song entity.\nThis is straight forward and nothing EF related here.\n1 2 3 4 5 6 7 8 9 10 11 12  public class Song { public int Id { get; set; } public string Name { get; set; } public string Artist { get; set; } public int YearReleased { get; set; } public int LengthInSeconds { get; set; } }    Add the DbSet The next step is to make EF aware of this entity. We do this by creating a Dbset (using the entity) on the DbContext:\n1 2 3 4 5 6 7 8 9 10 11  public class EntityTypeConfigContext : DbContext { // This links the entity to EF public DbSet\u0026lt;Song\u0026gt; Songs { get; set; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseSqlServer( @\u0026#34;Server=.\\SQLEXPRESS;Database=EntityTypeConfig;Integrated Security=True\u0026#34;); } }    Customize entity configuration The next step is to create a configuration for the entity.\nThe default SQL column size for strings is nvarchar(max) - the below configuration changes this to 250 chars for the entity, for example.\n1 2 3 4 5 6 7 8 9  public class SongConfiguration : IEntityTypeConfiguration\u0026lt;Song\u0026gt; { public void Configure(EntityTypeBuilder\u0026lt;Song\u0026gt; builder) { builder.HasIndex(p =\u0026gt; p.Id, \u0026#34;Id\u0026#34;); builder.Property(p =\u0026gt; p.Name).HasMaxLength(250); builder.Property(p =\u0026gt; p.Artist).HasMaxLength(250); } }    Apply the configuration The final step is to apply the configuration to the DbContext:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class EntityTypeConfigContext : DbContext { public DbSet\u0026lt;Song\u0026gt; Songs { get; set; } protected override void OnModelCreating(ModelBuilder modelBuilder) { // when the model is creating, specify // the configuration should be used modelBuilder.ApplyConfiguration(new SongConfiguration()); } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseSqlServer( @\u0026#34;Server=.\\SQLEXPRESS;Database=EntityTypeConfig;Integrated Security=True\u0026#34;); } }    EntityTypeConfiguration attribute The above 4 steps will still work with EF Core 6, however the last step can now be simplified.\nInstead of manually adding each entity configuration to the OnModelCreating method on the context, the entity itself can be tagged with the EntityTypeConfiguration attribute.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // This attribute will ensure the \u0026#34;SongConfiguration\u0026#34; is used  // when configuring the \u0026#34;Song\u0026#34; entity in EF [EntityTypeConfiguration(typeof(SongConfiguration))] public class Song { public int Id { get; set; } public string Name { get; set; } public string Artist { get; set; } public int YearReleased { get; set; } public int LengthInSeconds { get; set; } }   The SongConfiguration configuration will now automatically be used for the Song entity by the EF when creating the database model.\n Notes While using the EntityTypeConfiguration attribute is cleaner and easier, and probably likely less to be overlooked by the developer, the technique will not work for everyone. Depending on the application design/architecture it might not make sense to \u0026ldquo;pollute\u0026rdquo; the entity wth any EF specific references.\nWhat is important though, is that there are now multiple options to leverage depending on what sense for your specific use case.\n References Entity Framework Core 6 features - Part 1\n     Daily Drop 15: 21-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-21T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/21-ef-core6-entitytypeconfig/","title":"EF Core 6 EntityTypeConfiguration Attribute"},{"content":"Daily Knowledge Drop There are a number of settings related to the .NET garbage collector (GC) which can be set at runtime using a variety of methods. Generally these do not need to be manually configured, but can be changed from the default to tweak and optimize performance of the application.\n Configurations The settings which can be configured are listed below (more detailed information can be found under references section below)\nGC flavour  Workstation or server GC: should the application use workstation or server garbage collection. Background GC: configures if background (concurrent) garbage collection is enabled.   Resource usage  Heap Count: limits the number of heaps created by the garbage collector. Affinitize ranges: specifies thee list of processors to use for garbage collector threads. CPU groups: configures whether he garbage collector used CPU groups or not. Affinitize: Specifies whether to affinitize garbage collection threads with processors (To affinitize a GC thread means that it can only run on its specific CPU). Heap limit: Specifies the maximum commit size, in bytes, for the GC heap and GC bookkeeping. Heap limit percent: Specifies the allowable GC heap usage as a percentage of the total physical memory. Per-object-heap limits: Specifies the garbage collectors allowable heap usage on a per-object-heap basis. The different heaps are the large object heap (LOH), small object heap (SOH), and pinned object heap (POH). Per-object-heap limit percents: Specifies the garbage collectors allowable heap usage on a per-object-heap basis. High memory percent: The physical memory load percentage above which garbage collection becomes more aggressive about doing full, compacting garbage collections to avoid paging. Retain VM: Configures whether segments that should be deleted are put on a standby list for future use or are released back to the operating system (OS).   Misc  Large pages: Specifies whether large pages should be used when a heap hard limit is set. Allow large objects: Configures garbage collector support on 64-bit platforms for arrays that are greater than 2 gigabytes (GB) in total size. Large object heap threshold: Specifies the threshold size, in bytes, that causes objects to go on the large object heap (LOH). Standalone garbage collector: Specifies a path to the library containing the garbage collector that the runtime intends to load.   Configuration methods There are 4 different ways to set the garbage collector variables - however, not all methods are available for all settings.\nLet\u0026rsquo;s have a look at the Workstation or server GC setting as an example, which can be configured using any of the 4 methods.\n   Method Setting name Values Version introduced     runtimeconfig.json System.GC.Server false - workstation / true - server .NET Core 1.0   MSBuild property ServerGarbageCollection false - workstation / true - server .NET Core 1.0   Environment variable COMPlus_gcServer 0 - workstation / 1 - server .NET Core 1.0   Environment variable DOTNET_gcServer 0 - workstation / 1 - server .NET 6   .NET Framework app.config \u0026lt;GCServer\u0026gt; element false - workstation / true - server      Notes For most applications in typical situations, the default GC configuration should provide optimal performance. However if trying to achieve peak performance of a running application, these settings can be used (and benchmarked along the way)\nPlease see the references section for more information on each of the settings, which method can be used to set them as well as the valid values.\n References Runtime configuration options for garbage collection\n     Daily Drop 14: 18-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-18T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/18-gc-variables/","title":"Garbage collection configuration"},{"content":"Daily Knowledge Drop To make use of the using statement in C#, all you need to do is implement the IDisposable interface on a class.\nThe using statement provides a convenient syntax to ensure the correct use of IDisposable objects. The object in question will exists for the scope of the using and then automatically be disposed once out of scope.\nThis functionality can also be leveraged to create scoped helper instances for certain use cases.\n Examples All the example below make use of a simple Order with multiple OrderLines entity structure.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class Order { public Guid Id { get; set; } public DateTime DateCreated { get; set; } public OrderLine[] Lines { get; set; } // Provide an convenient way to output the order public override string ToString() { return JsonSerializer.Serialize(this, new JsonSerializerOptions { WriteIndented = true }); } } class OrderLine { public Guid Id { get; set; } public DateTime DateCreated { get; set; } public Guid OrderId { get; set; } }   When an Order is created, the OrderLines should be created at the same time. Both entities are required to have the same DateCreated value and we also require the OrderLine.OrderId to be set to the Order.Id\nFor something so relatively simple, there are a couple of issues.\nSee the code below which DOES NOT COMPILE:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  var order = new Order { Id = Guid.NewGuid(), DateCreated = DateTime.Now, Lines = new[] { new OrderLine { Id = Guid.NewGuid(), DateCreated = DateTime.Now, // How to set this??? OrderId = ??? } } };   The issues:\n The two DateCreated values will not be the same (off by probably only a few nano or milliseconds, but still off) There is no way to easily set the OrderId value on the OrderLine entity  Variable snapshot These issues can quite easily be solved by using variables to snapshot values before the entity creation:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // snapshot values to be used later var datetimeCreated = DateTime.Now; var orderId = Guid.NewGuid(); var order = new Order { // use the snapshot orderId Id = orderId, // use the snapshot date created DateCreated = datetimeCreated, Lines = new[] { new OrderLine { Id = Guid.NewGuid(), // use the snapshot date created DateCreated = datetimeCreated, // use the snapshot orderId OrderId = orderId } } };   This will 100% work and is completely acceptable to do - however a cleaner way, which makes use of the using statement.\n Using snapshot First thing is to define a OrderInfoSnapshot class which implements IDisposable:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class OrderInfoSnapshot : IDisposable { private DateTime _created; private Guid _orderId; public DateTime Created =\u0026gt; _created; public Guid OrderId =\u0026gt; _orderId; public OrderInfoSnapshot() { _created = DateTime.Now; _orderId = Guid.NewGuid(); } public void Dispose() { // do cleanup etc here // look at resources for correct // Dispose usage } }    Line 1: Implement IDisposable Line 10-14: On creation of an instance, we snapshot the values we are interested in Line 16-20: Implement the IDisposable Dispose method. This is a very simple example, but more sophisticated cleanup can happen here - see the references for more details.  Now instead of using a number of variables for the various snapshots required, OrderInfoSnapshot can be used with a using statement:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  // create the snapshot using (var orderInfo = new OrderInfoSnapshot()) { var order = new Order { // grab the OrderId from the snapshot Id = orderInfo.OrderId, // Create from the snapshot DateCreated = orderInfo.Created, Lines = new[] { new OrderLine { Id = Guid.NewGuid(), // Create from the snapshot DateCreated = orderInfo.Created, // OrderId from the snapshot OrderId = orderInfo.OrderId } } }; Console.WriteLine(order); }   The OrderInfoSnapshot will automatically be disposed (which in this case doesn\u0026rsquo;t need to do much cleanup) once the end of the using scope is reached.\nAs mentioned, this is a very simple example, but if the OrderInfoSnapshot was required to access multiple other resources, all the connections could be cleaned up in the Dispose method.\n Alternative syntax Introduced in C# 8, there is an alternative syntax for usings - the end result and operation is exactly the same though.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // create the snapshot using var orderInfo = new OrderInfoSnapshot(); var order = new Order { Id = orderInfo.OrderId, DateCreated = orderInfo.Created, Lines = new[] { new OrderLine { Id = Guid.NewGuid(), DateCreated = orderInfo.Created, OrderId = orderInfo.OrderId } } }; Console.WriteLine(order);   The scope of the OrderInfoSnapshot instance is now the method it was created in, and it will still automatically be disposed when going out of scope.\n Notes Implementing IDisposable correctly is a bit more complicated than shown above - see the references for more details.\n Conclusion The IDisposable is not required on every class, but it makes sense and can be useful when you want to:\n Explicitly dispose of resources used when going out of scope Make use of the using syntax to be able to create a create a scoped entity (as in the above examples)   References IDisposable Interface\n     Daily Drop 13: 17-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-17T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/17-using-idisposable/","title":"Using with IDisposable"},{"content":"Daily Knowledge Drop A new method on Task called WaitAsync was introduced in .NET6. This method allows for waiting on a Task for a specific period of time before throwing a timeout exception.\nOn the surface, this might not seem very useful, but lets look at some examples to see how this new method can be leveraged.\n The issue Long running processes Suppose we have a long running method which returns a Task - in the below example we are simulating a download process which takes 5 seconds\n1 2 3 4 5 6 7 8 9 10 11  await LongRunningProcessAsync(); async Task LongRunningProcessAsync() { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Starting large download...\u0026#34;); for (int x = 0; x \u0026lt; 4; x++) { await Task.Delay(1000); } Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Download Complete\u0026#34;); }   As probably expected, the output is a follows, with 5 seconds gap between the start and completion of the \u0026ldquo;download\u0026rdquo;:\n1 2  06:51:29.4337633 =\u0026gt; Starting large download... 06:51:34.4755862 =\u0026gt; Download Complete   In the above example, the long running process is capped at 5 seconds, but in a real world situation, this would be an unknown number, dependant the size of the file downloading, network speed and availability etc.\nSo how can we force a cap on the download time, and if it takes longer than the cap the process is cancelled, and feedback can be given back to the user.\n Solutions Cancellation token The best way to handle cancellation of the task would be by using a CancellationToken.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  using (var cts = new CancellationTokenSource(TimeSpan.FromSeconds(1))) { try { await LongRunningProcessAsync(cts.Token); } catch (TimeoutException) { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; \u0026#34; + $\u0026#34;Download took too long and was cancelled\u0026#34;); } } async Task LongRunningProcessAsync(CancellationToken token) { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Starting large download...\u0026#34;); for (int x = 0; x \u0026lt; 4; x++) { if(token.IsCancellationRequested) { throw new TimeoutException(); } await Task.Delay(1000); } Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Download Complete\u0026#34;); }    Line 1: A new CancellationTokenSource is used, with a timeout of 1 second Line 5: The long running method is called, and has been updated to accept a CancellationToken, which is supplied Line 19: Every iteration, the token is checked to see if a cancellation was requested (which in this example would happen after 1 second) Line 21: If a cancellation has been requested, throw an exception and abort the long running process  The output is as follows:\n1 2  07:07:28.2537474 =\u0026gt; Starting large download... 07:07:29.3237966 =\u0026gt; Download took too long and was cancelled   PROS:\n The long running process stops when the cancellation occurs  CONS:\n The method needs to change to support a cancellation token as a parameter  In this example changing the method to support the cancellation token was straightforward, and many existing third party libraries already support cancellation tokens.\nBut how could the same problem be solved when the method does not support a cancellation token and cannot be changed?\n Parallel tasks One method is to start a second task which runs for a set period of time, in parallel to the long running process. We wait for one of the tasks to finish and based on which finished first, we can handle how to proceed.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  // start the process of creating cancellation token using (var cts = new CancellationTokenSource()) { try { // create a timeout delay task, which will run for 1 second var timeout = TimeSpan.FromSeconds(1); var timeoutTask = Task.Delay(timeout, cts.Token); // wait for either the timeout task OR the  // long running task to finish var firstTask = await Task.WhenAny(new[] { timeoutTask, LongRunningProcessAsync() }); // if the first task to finish was the timeout task,  // we can throw a timeout exception as the long running  // process has now exceeded the allowed timeout if (firstTask == timeoutTask) { throw new TimeoutException(); } else { cts.Cancel(); } } catch (TimeoutException) { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; \u0026#34; + $\u0026#34;Download took too long and was cancelled\u0026#34;); } } // This method is unable to change, so no CancellationToken can be used async Task LongRunningProcessAsync() { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Starting large download...\u0026#34;); for (int x = 0; x \u0026lt; 4; x++) { await Task.Delay(1000); } Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Download Complete\u0026#34;); }    Line 8: A delay/timeout task is started which will run for 1 second Line 12-13: The long running process and the timeout task are both awaited, and the code waits for the first one to finish Line 18: If the first task to finish is the timeout task, we know the long running process has run for longer than 1 second, and we need to feedback to the user Line 20: Timeout exception is thrown  Note: The above could have been done without the use of the CancellationTokenSource and use of cts.Token. However, whenever possible if a method (Task.Delay in this case) supports a cancellation token parameter, it should be used.\nThe output is as follows:\n1 2 3  07:56:40.5198266 =\u0026gt; Starting large download... 07:56:41.5520772 =\u0026gt; Download took too long and was cancelled 07:56:44.5803565 =\u0026gt; Download Complete   But wait - the download still completed?\nUnfortunately, because the method doesn\u0026rsquo;t accept a cancellation token (or provide some other way) to handle cancellations, there is no way to truly cancel it.\nWhat the above technique does, is allow the flow of execution to continue after waiting for the task for a certain period of time. The long running process task will still run to completion in the background.\nPROS:\n A long running task can be \u0026ldquo;cancelled\u0026rdquo; even without a cancellation token or any modifications to code  CONS:\n The long running task is not truly cancelled, it still executes in the background. Control is just given back to the main processing thread   Task.WaitAsync The new Task.WaitASync method performs the same function as the above technique, it is just much cleaner.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  try { // start the long running process, and wait on the task  // for a maximum of 1 second await LongRunningProcessAsync() .WaitAsync(TimeSpan.FromSeconds(1)); } catch (TimeoutException) { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; \u0026#34; + $\u0026#34;Download took too long and was cancelled\u0026#34;); } } // This method is unable to change, so no CancellationToken can be used async Task LongRunningProcessAsync() { Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Starting large download...\u0026#34;); for (int x = 0; x \u0026lt; 4; x++) { await Task.Delay(1000); } Console.WriteLine($\u0026#34;{DateTime.Now.TimeOfDay} =\u0026gt; Download Complete\u0026#34;); }   The output is as follows:\n1 2 3  18:02:46.4930592 =\u0026gt; Starting large download... 18:02:47.5520137 =\u0026gt; Download took too long and was cancelled 18:02:50.5424670 =\u0026gt; Download Complete   As can be seen, the resulting output is the same, however the code required is a lot more compact and cleaner. Unfortunately, even with this new method, without a cancellation token, the long running task will still execute in the background.\nPROS:\n A long running task can be \u0026ldquo;cancelled\u0026rdquo; even without a cancellation token  CONS:\n The long running task is not truly cancelled, it still executes in thee background. Control is just given back to the main processing thread   Conclusion The preferred solution for cancelling a long running task is to use a CancellationToken., and if this is available should always be used. However this is not always possible, and in that case the Task.WaitAsync is the best and cleanest way of handling a task \u0026ldquo;cancellation\u0026rdquo;.\n References New Task.WaitAsync method in .NET 6\n     Daily Drop 12: 16-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-16T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/16-task-wait-async/","title":"Task.WaitAsync in .NET6"},{"content":"Daily Knowledge Drop With the introduction of global usings in C#10, it is now also possible to defined a global alias to have a shortcut to a specific type, across an entire project.\n Global usings A quick intro to global usings - In C#10 the concept of global usings was introduced. It allows for a using statement to be prefixed with global, which then includes that using in all files automatically when compiled.\nAssume we have a file called GlobalUsings.cs:\n1  global using System.Threading.Tasks;   In the Program.cs:\n1 2 3 4  // No using System.Threading.Tasks here Console.WriteLine(\u0026#34;About to delay\u0026#34;); Task.Delay(1000); Console.WriteLine(\u0026#34;Delay finished\u0026#34;);   Here we can include all includes needed for the project in one file (GlobalUsings.cs), and keep all other files free of usings.\n Global alias This global using functionality can be leverage to create global aliases.\nAssume we are writing an application for a library - we need to incorporate the Dewey Decimal System through-out the application. The Dewey Decimal System is basically used to links book(s) to a specific shelf in the library, so they can be easily found - so we decide to use a Dictionary\u0026lt;string,List\u0026lt;string\u0026gt;\u0026gt; to represent this.\nThe dictionary key will be the shelf reference and the dictionary value will be the list of book titles on specific shelf\nNote: There are a number of ways to represent the Dewey Decimal System data, and a Dictionary\u0026lt;string,List\u0026lt;string\u0026gt;\u0026gt; is not necessarily the best or most performant, it is just used for demo purposes.\nThroughout code, if we wanted to present this, we could do the following:\n1 2 3  var hds = new Dictionary\u0026lt;string,List\u0026lt;string\u0026gt;\u0026gt;(); // OR Dictionary\u0026lt;string, List\u0026lt;string\u0026gt;\u0026gt; hds1 = new Dictionary\u0026lt;string, List\u0026lt;string\u0026gt;\u0026gt;();   This is a relatively long type to type out the entire time and to clutter up the code - an alternative is to create a global alias for this type.\nIn the GlobalUsings.cs file we create an alias called dewey and alias it to System.Collections.Generic.Dictionary\u0026lt;string, System.Collections.Generic.List\u0026lt;string\u0026gt;\u0026gt;\n1 2  global using dewey = System.Collections.Generic.Dictionary\u0026lt;string, System.Collections.Generic.List\u0026lt;string\u0026gt;\u0026gt;;   Now in our application, in any place we want to use System.Collections.Generic.Dictionary\u0026lt;string, System.Collections.Generic.List\u0026lt;string\u0026gt;\u0026gt; we can instead use the alias. Its defined as global so no additional usings are required:\n1  var hds = new dewey();   We can now operate on the dewey type as we would a System.Collections.Generic.Dictionary\u0026lt;string, System.Collections.Generic.List\u0026lt;string\u0026gt;\u0026gt;.\nThe alias dewey is pointing to the type System.Collections.Generic.Dictionary\u0026lt;string, System.Collections.Generic.List\u0026lt;string\u0026gt;\u0026gt; they are the same type, just with different names.\n Conclusion The concept of an alias is not new to C#, however the new ability to make it global to the entire project makes it a very convenient tool to create shortcuts, especially for the longer named types.\n References Global Using Directives\n     Daily Drop 11: 15-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-15T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/15-global-using-directives/","title":"Aliases with global using directives"},{"content":"Daily Knowledge Drop It is possible to filter the catch portion of the try-catch statement, as well as catch multiple exceptions at the same time using the C# when keyword.\n Multiple exceptions In our use case, there are two exception types we are particularly interested in IndexOutOfRangeException and DivideByZeroException.\nIf either of these exceptions occur, we want to log the exception, and carry on with the workflow. However if any other exception occurs, it should be logged and re-thrown to be handled higher up the call stack.\nMultiple catch Usually this would be done with multiple catch statements:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  try { // array only has 2 elements var array = new int[2]; // trying to access 3rd element. not allowed // this will be caught by the first catch statement array[3] = 100; } catch (IndexOutOfRangeException ex) { Console.WriteLine(\u0026#34;Caught IndexOutOfRangeException: Log and ignore\u0026#34; ); } catch (DivideByZeroException ex) { Console.WriteLine(\u0026#34;Caught DivideByZeroException: Log and ignore\u0026#34;); } catch (Exception ex) { Console.WriteLine(\u0026#34;Caught all other exceptions: Log and throw\u0026#34;); throw; }   Here there are three different catch statements each handling a different type of exception. However for the first two types of exception, the same logic needs to take place, so lets group these two exceptions together.\n When clause The when clause can be used to group multiple exceptions together:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  try { // divide by zero. not allow // this will be caught by the first catch statement // along with any IndexOutOfRange exceptions var zero = 0; var value = 100 / zero; } catch (Exception ex) when (ex is IndexOutOfRangeException || ex is DivideByZeroException) { Console.WriteLine(\u0026#34;Caught IndexOutOfRangeException or \u0026#34; + \u0026#34;DivideByZeroException: Log and ignore\u0026#34;); } catch (Exception ex) { Console.WriteLine(\u0026#34;Caught all other exceptions: Log and throw\u0026#34;); throw; }   On Lines 9-10, the type of the exception being caught is checked. If the exception type is one of the two we are interested in, the first catch block is entered, otherwise the exception falls through to the second catch block.\n Exception filtering In our use case, we have defined a custom exception, with a Status field. Based on the value of the Status field, one of three things should happen:\n log the exception log and re-thrown the exception ignore the exception.  Switch Usually for filtering a switch could be done within the catch statement:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  try { throw new StatusException(3); } catch (StatusException ex) { switch (ex.Status) { case 0: case 1: Console.WriteLine($\u0026#34;Logging exception with status: {ex.Status}\u0026#34;); Console.WriteLine(ex.Message); break; case 3: case 5: Console.WriteLine($\u0026#34;Ignoring exception with status: {ex.Status}\u0026#34;); break; default: Console.WriteLine($\u0026#34;Throwing exception with status: {ex.Status}\u0026#34;); throw; } } class StatusException : Exception { public int Status; public StatusException(int status) { Status = status; } }    The when clause can also be used to filter the catch statement, based on properties of the exception.\nWhen clause Below we are filtering which catch block should handling the exception based on the Status field value:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  try { throw new StatusException(1); } catch (StatusException ex) when (ex.Status == 0 || ex.Status == 1) { Console.WriteLine($\u0026#34;Logging exception with status: {ex.Status}\u0026#34;); Console.WriteLine(ex.Message); } catch (StatusException ex) when (ex.Status == 3 || ex.Status == 5) { Console.WriteLine($\u0026#34;Ignoring exception with status: {ex.Status}\u0026#34;); } catch (StatusException ex) { Console.WriteLine($\u0026#34;Throwing exception with status: {ex.Status}\u0026#34;); throw; } class StatusException : Exception { public int Status; public StatusException(int status) { Status = status; } }    Conclusion The when clause is a useful addition to the existing techniques to handle multiple exceptions and allow for decision making based on exception values.\n References Catch Multiple Exceptions in C#\n     Daily Drop 10: 14-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-14T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/14-exceptions-when/","title":"Filtering try-catch statement"},{"content":"Daily Knowledge Drop As part of the C# System.Runtime assembly, there are a number of Attributes which can be used to get information about the caller of a method.\nThe pattern for usage is the same for all attributes. To extract the metadata when a method is called, the following needs to be done:\n A new parameter needs to be added to the method (the type of the parameter depends on the attribute, see examples below) The new parameter must have a default value The new parameter must be decorated with the relevant Attribute   Attributes Lets look at a few examples. All examples built using .NET6 minimal console application.\nLine Number To get the caller line number, the CallerLineNumber attribute is used.\n1 2 3 4 5 6  LogMessageWithLineNumber(\u0026#34;Message 1\u0026#34;); static void LogMessageWithLineNumber(string message, [CallerLineNumber] int lineNumber = 0) { Console.WriteLine($\u0026#34;LineNumber={lineNumber}: {message}\u0026#34;); }   On Line 3, we can see a decorated parameter, with a default value has been added. This field will automatically be populated with the line number of the calling method\nThe output is as follows:\n1  LineNumber=4: Message 1    File Path To get the file path of the calling method, the CallerFilePath attribute is used.\n1 2 3 4 5 6  LogMessageWithPath(\u0026#34;Message 2\u0026#34;); static void LogMessageWithPath(string message, [CallerFilePath] string filepath = \u0026#34;\u0026#34;) { Console.WriteLine($\u0026#34;Path={filepath}: {message}\u0026#34;); }   The output is as follows:\n1  Path=C:\\Development\\Projects\\Blog\\CallerMetadata\\CallerMetadata\\Program.cs: Message 2    Method Name To get the calling method name, the CallerMemberName attribute is used.\n1 2 3 4 5 6  LogMessageWithPath(\u0026#34;Message 2\u0026#34;); static void LogMessageWithMethod(string message, [CallerMemberName] string memberName = \u0026#34;\u0026#34;) { Console.WriteLine($\u0026#34;Method={memberName}: {message}\u0026#34;); }   The output is as follows:\n1  Method=\u0026lt;Main\u0026gt;$: Message 3   As the example is using the .NET6 Console minimal project, there is no explicitly defined main method - hence the method reflecting as \u0026lt;Main\u0026gt;$\nLets look at another example.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  new ClassCall().DoubleHop(); class ClassCall { public void DoubleHop() { LogMessageWithMethod(\u0026#34;Message from class\u0026#34;); } static void LogMessageWithMethod(string message, [CallerMemberName] string memberName = \u0026#34;\u0026#34;) { Console.WriteLine($\u0026#34;Method={memberName}: {message}\u0026#34;); } }   In this example, the source of the call to LogMessageWithMethod is the DoubleHop method, as such the output is as follows:\n1  Method=DoubleHop: Message from class    Expression The last attribute is the most interesting and the most useful. The CallerArgumentExpression attribute is used to get the expression used as the argument to the method.\nIn the following example, the same string message \u0026ldquo;Message 4\u0026rdquo; will be logged, however the string will be generated differently each time the method is invoked.\n1 2 3 4 5 6 7 8 9 10 11 12  // Just send a string LogMessageWithExpression(\u0026#34;Message 4\u0026#34;); // Add two string together with the + operator LogMessageWithExpression(\u0026#34;Message\u0026#34; + \u0026#34; 4\u0026#34;); // Concatenate two string using Concat method LogMessageWithExpression(String.Concat(\u0026#34;Message\u0026#34;, \u0026#34; 4\u0026#34;)); static void LogMessageWithExpression(string value, [CallerArgumentExpression(\u0026#34;value\u0026#34;)] string expression = \u0026#34;\u0026#34;) { Console.WriteLine($\u0026#34;{{{value}}} was generated by {{{expression}}}\u0026#34;); }   In this case, the CallerArgumentExpression attribute takes a parameter itself, and that is the name of the parameter for which is should get the caller argument expression.\nThe output is as follows:\n1 2 3  {Message 4} was generated by {\u0026#34;Message 4\u0026#34;} {Message 4} was generated by {\u0026#34;Message\u0026#34; + \u0026#34; 4\u0026#34;} {Message 4} was generated by {String.Concat(\u0026#34;Message\u0026#34;, \u0026#34; 4\u0026#34;)}   We can see from the output, that the expression parameter gets populated with the code used to generate the parameter value (the expression for the parameter argument).\nThis can be invaluable when logging, as not only can a piece of information be logged, but also which piece of code is generating the information.\nOverriding parameter values In all of the above examples, as mentioned, the parameter decorated with the relevant attribute needs to have a default value. So what happens if a value is explicitly supplied for the parameter?\nAs one might expect, instead of using the default and allowing the attribute to populate the parameter, the explicitly supplied value is used.\nHere a value is explicitly supplied for the memberName parameter:\n1 2 3 4 5 6 7  LogMessageWithMethod(\u0026#34;Message 5\u0026#34;, \u0026#34;OwnMethodName\u0026#34;); static void LogMessageWithMethod(string message, [CallerMemberName] string memberName = \u0026#34;\u0026#34;) { Console.WriteLine($\u0026#34;Method={memberName}: {message}\u0026#34;); }   The output, as expected:\n1  Method=OwnMethodName: Message 5    Notes While simple to implement, using these features can be very intrusive, with the need to add additional parameters to relevant methods. However if required, these tools can provide invaluable information about the calling location.\n References Get C# Metadata From a Call Site\n     Daily Drop 9: 11-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-11T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/11-caller-metadata/","title":"Extract calling method metadata with C#"},{"content":"Daily Knowledge Drop Today we dive into a little-known C# feature, I\u0026rsquo;d previously never heard about called Channels.\nSo what is a channel? - In short, a channel is a feature which allows for passing of data between a producer and consumer(s). It is an efficient, thread-safe queuing mechanism.\n Usage The examples set out below are very simple, and do not reflect a real world scenario. They have eben kept as minimal as possible to display the core concepts of the Channel. The example consists of:\n an end point which when called will produce an item to the channel a background service which will constantly monitor the channel for new items and process them  Setup First a Channel needs to be created, and to be made available to both the producer and consumer.\nThis is done by declaring a singleton instance of the channel and adding it to the dependency injection container:\n1 2 3 4 5 6 7 8  // Create a new channel and add to to the DI container builder.Services.AddSingleton\u0026lt;Channel\u0026lt;Guid\u0026gt;\u0026gt;( Channel.CreateUnbounded\u0026lt;Guid\u0026gt;( new UnboundedChannelOptions() { SingleReader = true } ) ); // NOT related to channels directly, just used for this demo builder.Services.AddHostedService\u0026lt;ChannelProcessor\u0026gt;();    Line 3: The channel is created:  as Unbounded, meaning it has unlimited capacity * with the type of Guid (this could be any data type)   Line 4: Additional option are supplied, in this case specifying there will be only a single consumer ** Line 8: Our ChannelProcessor background service is added as a hosted service. This is NOT related to Channels directly, just the method being used here to read from the channel  * When creating a channel, the options UnBounded (has unlimited capacity) or *Bounded (which has limited capacity). Unbounded queues are potentially dangerous to use if the consumer is not able to keep up with the producer, resulting in the application running out of memory.\n** These options are not required, but by specifying them the factory method is able to specialize the implication created to be as optimal as possible.\nProducer Here an background service is used to read items from the channel:\n1 2 3 4 5 6 7  app.MapGet(\u0026#34;/{id}\u0026#34;, async (Guid Id, Channel\u0026lt;Guid\u0026gt; channel) =\u0026gt; { await channel.Writer.WriteAsync(Id); Console.WriteLine($\u0026#34;Item \u0026#39;{Id}\u0026#39; successfully written to the channel\u0026#34;); return await Task.FromResult($\u0026#34;Item \u0026#39;{Id}\u0026#39; successfully written to the channel\u0026#34;); });    Line 1: The singleton implementation of the channel is injected into the endpoint using dependency injection Line 3: The data is written to the channel  As simple as that. Now we need a process to consume the data.\n Consumer Here an endpoint is used to write an item to the channel.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class ChannelProcessor : BackgroundService { private readonly Channel\u0026lt;Guid\u0026gt; _channel; public QueueProcessor(Channel\u0026lt;Guid\u0026gt; channel) { _channel = channel; } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { await foreach (var item in _channel.Reader.ReadAllAsync(stoppingToken)) { Console.WriteLine($\u0026#34;Item {item} successfully read from the channel\u0026#34;); } } }    Line 5: The singleton implementation of the channel is injected into the background service using dependency injection Line 12: The background service will read items off the channel as they arrive and process them.   Output If we run the application and hit the endpoint (to produce to the channel), we will see that it is consumed and processed immediately:\n Channel demo output \nWe have a simple working example of data being shared efficiently and safely across threads.\n Notes This is a very simple example, and there is a lot more to Channels beyond this. Channels may not be a well-known feature, and not something which will be used in every day development - however just the knowledge they exist is a great starting point if you ever require them. They are a simple, but powerful mechanism for exchanging data across Tasks - and should definitely be leveraged if the use case arises.\n References An Introduction to System.Threading.Channels\nDevBlogs: An Introduction to System.Threading.Channels\n     Daily Drop 8: 10-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-10T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/10-channels/","title":"C# Channels - Produce \u0026 Consume data"},{"content":"Daily Knowledge Drop .NET6 introduced a new attribute called LoggerMessageAttribute, which leverages source generators and is designed to deliver a highly useable and performant logging solution.\nIt works by using source generators, triggered at compile time by the presence of LoggerMessageAttribute to generate the additional source code. This solution, due to the compile time generation, is able to eliminate performance hits, such as boxing, temporary memory allocation as well as copies which enables it to be typically considerably faster than the existing run time logging methods.\n Usage Basic usage The LoggerMessageAttribute is constrained to be used on a partial method in a partial class.\n1 2 3 4 5 6 7 8  public static partial class LoggerHelperStatic { [LoggerMessage(EventId = 0,Level = LogLevel.Critical,Message = \u0026#34;Unable to open a database connection to \u0026#39;{dbServer}\u0026#39; \u0026#34; + \u0026#34;after a timeout of {timeoutSeconds} seconds\u0026#34;)] public static partial void UnableToOpenDbConnection(ILogger logger, string dbServer, int timeoutSeconds); }    Lines 3-5: Here the information for the log is defined. In the above example, the EventId, LogLevel as well as the Log Message.  Thats all there is to it. This method can now be called from anywhere in code using LoggerHelperStatic.UnableToOpenDbConnection(...).\nEven though the method doesn\u0026rsquo;t have a body defined, the presence of the LoggerMessageAttribute will trigger the source generator, which will use the log information defined to generate the required source code for the body.\nExtended usage If the method is static, then an ILogger interface is required to be one of the parameters to the method. The method is not required to be static however, and if not made static the source generator will use an ILogger field within the containing class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public partial class LoggerHelperInstance { private readonly ILogger _logger; public LoggerHelperInstance(ILogger logger) { _logger = logger; } [LoggerMessage(EventId = 0, Level = LogLevel.Critical, Message = \u0026#34;Unable to open a database connection to `{dbServer}` \u0026#34; + \u0026#34;after a timeout of {timeoutSeconds} seconds\u0026#34;)] public partial void UnableToOpenDbConnection(string dbServer, int timeoutSeconds); }   In the above examples, the log level is also explicitly set to Critical in the LoggerMessageAttribute. Sometimes it may be required that the log level is specified at runtime - in this case the LogLevel can be omitted from the LoggerMessageAttribute definition, and included as a parameter to the method.\n1 2 3 4  [LoggerMessage(EventId = 0, Message = \u0026#34;Unable to open the file \u0026#39;{fileName} at location \u0026#39;{fileLocation}\u0026#39;\u0026#34;)] public static partial void UnableToOpenFile(ILogger logger, LogLevel logLevel, string fileName, string fileLocation);    How it works This all works due to a feature introduced in .NET5 - source generators. At compile time, a source generator will look for a specific condition in code, and output additional source code which is added to the original code base.\nIn the case of LoggerMessageAttribute, the condition is the presence of the attribute which then triggers the source generator to generate the body of the defined method - this is why the class and method are required to be partial.\nBelow is the generated code for the body of the LoggerHelperInstance =\u0026gt; UnableToOpenDbConnection method. It might be a bit of a challenging to read with the formatting, as I\u0026rsquo;ve left it in its original generated state.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  partial class LoggerHelperInstance { [global::System.CodeDom.Compiler.GeneratedCodeAttribute(\u0026#34;Microsoft.Extensions.Logging.Generators\u0026#34;, \u0026#34;6.0.5.2210\u0026#34;)] private static readonly global::System.Action\u0026lt;global::Microsoft.Extensions.Logging.ILogger, global::System.String, global::System.Int32, global::System.Exception?\u0026gt; __UnableToOpenDbConnectionCallback = global::Microsoft.Extensions.Logging.LoggerMessage.Define\u0026lt;global::System.String, global::System.Int32\u0026gt;(global::Microsoft.Extensions.Logging.LogLevel.Critical, new global::Microsoft.Extensions.Logging.EventId(0, nameof(UnableToOpenDbConnection)), \u0026#34;Unable to open a database connection to `{dbServer}` after a timeout of {timeoutSeconds} seconds\u0026#34;, new global::Microsoft.Extensions.Logging.LogDefineOptions() { SkipEnabledCheck = true }); [global::System.CodeDom.Compiler.GeneratedCodeAttribute(\u0026#34;Microsoft.Extensions.Logging.Generators\u0026#34;, \u0026#34;6.0.5.2210\u0026#34;)] public partial void UnableToOpenDbConnection(global::System.String dbServer, global::System.Int32 timeoutSeconds) { if (_logger.IsEnabled(global::Microsoft.Extensions.Logging.LogLevel.Critical)) { __UnableToOpenDbConnectionCallback(_logger, dbServer, timeoutSeconds, null); } } }   As one can see, it\u0026rsquo;s not a straightforward wrap of the ILogger.LogCritical method, but instead makes use of the LoggerMessage.Define method with a callback Action.\nPerformance gains So why does this method improve on performance?\nWith the normal traditional ILogger Log method:\n1 2 3  // Traditional ILogger.LogCritical call _logger.LogCritical(\u0026#34;Unable to open a database connection to `{dbServer}` \u0026#34; + \u0026#34;after a timeout of {timeoutSeconds} seconds\u0026#34;, \u0026#34;(local)\u0026#34;, 10);   The parameters are passed in as an object?[]:\n1 2 3  // The signature of the LogCritical method, part of Microsoft.Extensions.Logging public static void LogCritical(this ILogger logger, EventId eventId, string? message, params object?[] args)   In the above example, the string value \u0026quot;(local)\u0026quot; and the int value 10 are boxed from their respective values into an object as part of the object[]. They are then unboxed when being used - all of this has a performance overhead.\nAs the source generator, used in conjunction with LoggerMessageAttribute, can determine the types of the parameters at compile time, it can optimize the code being generated for the individual use case to avoid the need to box and unbox, and also avoid the performance hits that come with it. The same applies to any temporary memory allocation and copying which may be occurring when using the object?[] on the ILogger implementation.\n Constraints There are however some constraints which must be followed when using LoggerMessageAttribute:\n Logging methods must be static, partial, and return void. Logging method names must not start with an underscore. Parameter names of logging methods must not start with an underscore. Logging methods may not be defined in a nested type. Logging methods cannot be generic.  All in all though, these constraints are pretty reasonable and make sense when thought about in conjunction with what the source generator is doing.\n Notes There is more detailed functionality available with LoggerMessageAttribute, which is outlined in the reference link below - however the above should be a great starting point to using LoggerMessageAttribute and optimizing logging in your application.\n References Compile-time logging source generation\n     Daily Drop 7: 09-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-09T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/09-logger-message-attribute/","title":"Performant logging with LoggerMessageAttribute"},{"content":"Daily Knowledge Drop A GitHub Action can be configured to executed on a set schedule, and it\u0026rsquo;s as simple as adding a line to the workflow YAML using Cron syntax.\nAs part of the development of this blog, there was a requirement to execute an Action on a schedule - which turned out to be easier than anticipated.\n Cron Quick intro to Cron syntax - if you are already familiar with this you can jump straight to how to implement in workflow YAML\nThe Cron syntax is used to define a schedule and consists of 5 fields separated by a space, with each field representing a unit of time.\nCron syntax The structure is as follows:\nA B C D E A =\u0026gt; minute (0-59) B =\u0026gt; hour (0-23) C =\u0026gt; day of the month (1-31) D =\u0026gt; month (1-12 or JAN-DEC) E =\u0026gt; day of the week (0-6 or SUN-SAT)  Each position/unit can have one of the following operators:\n * = any value , = value list separator - = range of value / step values  Cron examples A few examples.\n 30 * * * *: executes at minute 30 of every hour of every day 15,45 03 * * 1,2: executes at minute 15 and 45 on hour 03 (3am) every Monday and Tuesday 10 18-20 * * SUN: executes at minute 10 on hour 18, 19 and 20 every Sunday 25/10 * * * *: executes every 10 minutes, starting at minute 25 (so minute 25, 35, 45, 55)  There are resources available online to assist in building up the Cron expression (see references below for an example website)\n YAML updates A GitHub Action is a way to automate a process related to a GitHub repository. In my example I use it to build and release this website every day.\nThe Action definition is stored as YAML as part of the repository, and defines the job(s) to perform as well as when to perform them.\nBelow is a snippet from this website\u0026rsquo;s YAML file, relating to when the job should be executed.\n1 2 3 4 5 6 7 8 9  # Controls when the workflow will runon:# Triggers the workflow on the scheduleschedule:- cron:\u0026#39;30 3 * * 1,2,3,4,5\u0026#39;# Allows for manual trigger of workflowworkflow_dispatch:# more omitted    Line 5 specifies that the Action should run every on the schedule specified: Monday - Friday at 03:30 Line 7 also indicates that the Action can be run manually   Notes Scheduling a Github Actions is really that simple. Actions are a powerful tool, and the ability to easily schedule them adds to their usefulness - anyone using GitHub repositories which require a workflow of any kind, should investigate how they can be leverage to automate (on a schedule if require) the required workflow.\n References Crontab Guru\nGitHub Action Scheduling\n     Daily Drop 6: 08-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-08T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/08-github-action-schedule/","title":"Scheduling with GitHub Actions"},{"content":"Daily Knowledge Drop You may have heard of C# the Tuple type, but there is also a ValueTuple type available, which has existed in C# since .NET 4.7!\nThe post will will take a brief look at the Tuple type and compare its functionality to that of the ValueTuple type.\n Tuple Tuple usage A Tuple is a data structure which has a specific number and sequence of elements. The data structure can contain up to 8 elements, but if more are required, nested tuple objects can be leveraged in the 8th element to extent the number of elements.\nIt is an effective, quick and simple way to create an immutable data entity structure without creating an entire class entity.\nWhat do I mean by this?\nAssume you have a method which needs to return a number of details related to a person. The go to solution would be to create a Person class with the relevant properties and return an instance of the class from the method.\nIf this class is only going to be used in one place, it might not make sense for an entire class to be defined - in this case a Tuple can be used instead.\nThe following example uses .NET6 C# console application with minimal startup:\n1 2 3 4 5 6 7 8 9 10 11 12 13  // Invoke the method and get the tuple back var personInfo = GetPersonInformation(); // Each element in the tuple can be accessed Console.WriteLine(personInfo.Item1); Console.WriteLine(personInfo.Item2); Console.WriteLine(personInfo.Item3); Console.WriteLine(personInfo); static Tuple\u0026lt;string, string, int\u0026gt; GetPersonInformation() { return new Tuple\u0026lt;string, string, int\u0026gt;(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); }    Line 8: The return time is defined as a Tuple which has 3 elements, two strings and an int Line 10: The Tuple is initialized with the values Line 3-5: The elements in the Tuple are accessed using the ItemX property, which corresponds to the element in position X  The output is as follows:\n1 2 3 4  Dave Grohl 53 (Dave, Grohl, 53)    Tuple creation In Line 10 in the above example, the Tuple was created and returned using the constructor method. These is another way - the static Tuple.Create method.\n1 2 3 4 5  // Using a generic constructor  var constructorTuple = new Tuple\u0026lt;string, string, int\u0026gt;(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); // Using the static Tuple Create method var createTuple = Tuple.Create(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53);   Both are equivalent, however the Create method is easier to use when dealing with nested Tuples.\n ValueTuple ValueTuple usage A ValueTuple operations the same as a Tuple on the surface, but there are a number of key differences between the two.\n ValueTuple is a struct (a value type), while a Tuple is a class (a reference type) ValueTuple is mutable (can be changed), while a Tuple is immutable (they are read-only) ValueTuple data members are fields, while Tuple data members are properties.  In the above example, Tuple can be replaced with ValueTuple and the code will still execute as before, with the same output:\n1 2 3 4 5 6 7 8 9 10 11  var personInfo = GetPersonInformation(); Console.WriteLine(personInfo.Item1); Console.WriteLine(personInfo.Item2); Console.WriteLine(personInfo.Item3); Console.WriteLine(personInfo); static ValueTuple\u0026lt;string, string, int\u0026gt; GetPersonInformation() { return new ValueTuple\u0026lt;string, string, int\u0026gt;(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); }   In addition to the differences mentioned above, theValueTuple also has additional ways in which it can be created, which allows working with the elements much easier.\n ValueTuple creation As seen above a ValueTuple can be created using the constructor:\n1  var consValueTuple = new ValueTuple\u0026lt;string, string, int\u0026gt;(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53);   It can also be created using the static Create method:\n1  var createValueTuple = ValueTuple.Create(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53);   In addition it can be created as follows\n1  var valueTuple = (\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53);   In all three of the above, the elements are still accessed using the Item1, Item2, etc properties. With a ValueTuple it is possible to give each element a name and access it by name.\nInstead of using the var keyword, we explicitly define the ValueTuple types, with names.\n1 2 3 4 5 6 7 8 9 10 11 12  (string FirstName, string LastName, int Age) nameValueTuple = (\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); // The elements can now be accessed by name Console.WriteLine(nameValueTuple.FirstName); Console.WriteLine(nameValueTuple.LastName); Console.WriteLine(nameValueTuple.Age); Console.WriteLine(nameValueTuple); // This will also still also work Console.WriteLine(nameValueTuple.Item1); Console.WriteLine(nameValueTuple.Item2); Console.WriteLine(nameValueTuple.Item3);   Any of the three initialization methods can be used to create the a ValueTuple with names.\n1 2 3 4 5 6 7 8 9 10  /// Create using the constructor (string FirstName, string LastName, int Age) consValueTuple = new ValueTuple\u0026lt;string, string, int\u0026gt;(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); // Create using the static method (string FirstName, string LastName, int Age) createValueTuple = ValueTuple.Create(\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); // Create using the abbreviated syntax (string FirstName, string LastName, int Age) valueTuple = (\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53);   A named ValueTuple can also be returned from a method:\n1 2 3 4 5 6 7 8 9 10 11 12  var personInfo = GetPersonInformation(); // now accessed by name Console.WriteLine(personInfo.FirstName); Console.WriteLine(personInfo.LastName); Console.WriteLine(personInfo.Age); Console.WriteLine(personInfo); static (string FirstName, string LastName, int Age) GetPersonInformation() { return (\u0026#34;Dave\u0026#34;, \u0026#34;Grohl\u0026#34;, 53); }    Notes Today we looked at the Tuple and ValueTuple structures, how they are different and the various ways they can be initialized.\nFor additional reading, see the references below.\n References Tuple Class\nValueTuple Class\nTuple in C#\n     Daily Drop 5: 07-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-07T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/07-valuetuple/","title":"C# ValueTuple"},{"content":"Daily Knowledge Drop The GroupBy support in Entity Framework Core 6 got an update, and has made things a lot easier.\nIn short, the following is now supported:\n Translate GroupBy followed by FirstOrDefault (or similar) over a group Supports selecting the top N results from a group Expands navigation\u0026rsquo;s after the GroupBy operator has been applied  Examples Setup In all the example below the setup is very simple - a single Song entity and corresponding database table. All sample below were tested with SQL Server.\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class Song { public int Id { get; set; } public string Name { get; set; } public string Artist { get; set; } public int YearReleased { get; set; } public int LengthInSeconds { get; set; } public override string ToString() { return $\u0026#34;Song `{Name}` by \u0026#39;{Artist} released \u0026#34; + $\u0026#34;in \u0026#39;{YearReleased}\u0026#39; and is \u0026#39;{LengthInSeconds}\u0026#39; seconds long\u0026#34;; } }   The results are based on data in the example dataset, and not necessarily reflective of real world values.\nThe below are examples in Entity Framework Core 3.1, where possible, and Entity Framework Core 6 (both are LTS versions).\n Count GroupBy Retrieve the number of songs per artist.\nEFCore 3.1 Code:\n1 2 3 4 5 6 7 8  var query = db.Songs .GroupBy(s =\u0026gt; s.Artist) .Select(e =\u0026gt; new { e.Key, Count = e.Count() }); foreach (var item in query.ToList()) { Console.WriteLine(item); }   SQL generated:\n1 2 3  SELECT[s].[Artist]AS[Key],COUNT(*)AS[Count]FROM[Song]AS[s]GROUPBY[s].[Artist]   Output:\n1 2  { Key = Foo Fighters, Count = 4 } { Key = John Mayer, Count = 3 }   EFCore 6 Code and resulting SQL generated are exactly the same.\n Top 1 GroupBy Retrieve an artist and the first year a song of theirs was released\nEFCore 3.1 Code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  var query = db.Songs .Select(s =\u0026gt; s.Artist).Distinct() .Select(e =\u0026gt; new { Artist = e, Year = db.Songs .Where(s =\u0026gt; s.Artist == e) .OrderBy(s =\u0026gt; s.YearReleased) .Select(y =\u0026gt; y.YearReleased) .FirstOrDefault() }); foreach (var item in query.ToList()) { Console.WriteLine(item); }   SQL generated:\n1 2 3 4 5 6 7 8 9 10  SELECT[t].[Artist],(SELECTTOP(1)[s].[YearReleased]FROM[Song]AS[s]WHERE([s].[Artist]=[t].[Artist])OR([s].[Artist]ISNULLAND[t].[Artist]ISNULL)ORDERBY[s].[YearReleased])AS[Year]FROM(SELECTDISTINCT[s0].[Artist]FROM[Song]AS[s0])AS[t]   Output:\n1 2  { Artist = Foo Fighters, Year = 1997 } { Artist = John Mayer, Year = 2003 }   EFCore 6 Code:\n1 2 3 4 5 6 7 8 9 10 11  var query = db.Songs .GroupBy(a =\u0026gt; a.Artist) .Select(g =\u0026gt; g.OrderBy(a =\u0026gt; a.YearReleased) .Select(s =\u0026gt; new { Artist = s.Artist, Year = s.YearReleased }) .FirstOrDefault() ); foreach (var item in query.ToList()) { Console.WriteLine(item); }   SQL generated:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  SELECT[t0].[Artist],[t0].[Year],[t0].[c]FROM(SELECT[s].[Artist]FROM[Song]AS[s]GROUPBY[s].[Artist])AS[t]LEFTJOIN(SELECT[t1].[Artist],[t1].[Year],[t1].[c]FROM(SELECT[s0].[Artist],[s0].[YearReleased]AS[Year],1AS[c],ROW_NUMBER()OVER(PARTITIONBY[s0].[Artist]ORDERBY[s0].[YearReleased])AS[row]FROM[Song]AS[s0])AS[t1]WHERE[t1].[row]\u0026lt;=1)AS[t0]ON[t].[Artist]=[t0].[Artist]   Output:\n1 2  { Artist = Foo Fighters, Year = 1997 } { Artist = John Mayer, Year = 2003 }   The LINQ is more intuitive and concise, while the SQL appears to be more complex. More complex SQL does not necessarily mean less performant though - as with everything it should be benchmarked with your expected data volume.\n Top N GroupBy Retrieve an artist and the first N years a song if theirs was released\nEFCore 3.1 It was a struggle to even get an example working for EF Core 3.1 for this scenario. It could be possible, but the fact it was so difficult to even try get it to work directly speaks to the need for the enhancements made in EF Core 6.\nEFCore 6 Code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  var query = db.Songs .GroupBy(a =\u0026gt; a.Artist) .Select(g =\u0026gt; new { Artist = g.Key, Years = g.OrderBy(a =\u0026gt; a.YearReleased) .Distinct() .Take(2) .Select(s =\u0026gt; s.YearReleased) }); foreach (var item in query.ToList()) { Console.WriteLine($\u0026#34;Artist = {item.Artist}, Years = {string.Join(\u0026#39;,\u0026#39;, item.Years)}\u0026#34;); }   SQL generated:\n1 2 3 4 5 6 7 8 9 10 11 12 13  SELECT[t].[Artist],[t0].[YearReleased],[t0].[Id]FROM(SELECT[s].[Artist]FROM[Song]AS[s]GROUPBY[s].[Artist])AS[t]OUTERAPPLY(SELECTDISTINCTTOP(2)[s0].[Id],[s0].[Artist],[s0].[LengthInSeconds],[s0].[Name],[s0].[YearReleased]FROM[Song]AS[s0]WHERE[t].[Artist]=[s0].[Artist])AS[t0]ORDERBY[t].[Artist]   Output:\n1 2  Artist = Foo Fighters, Years = 1997,1999 Artist = John Mayer, Years = 2003,2003    Notes The above are just a few very basic examples of the enhanced functionality. The official Microsoft EF Core 6 documentation referenced below has many more examples - however hopefully this has at least introduced the enhanced GroupBy support, and how EF Core 6 makes it easier to use.\nAs always, the recommendation is to benchmark the various LINQ techniques (and corresponding SQL) against your data structure and volumes, and make an informed decision about the best way to structure the LINQ.\n References Whats new in EF Crore 6 - improved GroupBy support\n     Daily Drop 4: 04-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-04T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/04-ef-core6-groupby/","title":"EF Core 6: GroupBy enhancements"},{"content":"Daily Knowledge Drop Instead of trying to manually setup the dependency injection container with configuration from the, for example, appsettings.json file, use the built in .NET functionality and use the IOptions interface instead - and get IOptionsSnapshot and IOptionsMonitor for free!\nThis post won\u0026rsquo;t go into details around the options pattern specifically, but it\u0026rsquo;s the recommended approach when dealing with application settings as it enables the application to adhere to two important software architecture principles:\n The Interface Segregation Principle (the I in SOLID) Separation of concerns  Onto some code examples - on startup when configuration the DI container:\n❌ Rather don\u0026rsquo;t do this: 1 2 3  var appOptions = new ApplicationOptions(); configuration.GetSection(\u0026#34;appConfiguration\u0026#34;).Bind(appOptions); services.AddSingleton(options);  \nWith the above, ApplicationOptions can be injected into the relevant constructor and the application settings accessed.\nNothing inherently \u0026ldquo;wrong\u0026rdquo; with this, it works and follows the options pattern. However there is a better way.\n✅ Rather do this: 1 2  var optionSection = configuration.GetSection(\u0026#34;appConfiguration\u0026#34;); services.Configure\u0026lt;ApplicationOptions\u0026gt;(optionSection);  \nWith the above, ApplicationOptions can NO longer be injected into the relevant constructor, instead IOptions\u0026lt;ApplicationOptions\u0026gt; (or one of the other two interfaces mentioned below) can be injected, allowing for access to the settings.\n Why use Configure So why use the IServiceCollection.Configure method instead of the Bind + AddSingleton methods as described above.\nJust by using the IServiceCollection.Configure method, one automatically gets ato leverage the functionality of the three options interfaces.\nFor all three examples below, the following section has been added to appsettings.json:\n1 2 3  \u0026#34;appConfiguration\u0026#34;: { \u0026#34;ApplicationName\u0026#34; : \u0026#34;OptionsDemo\u0026#34; }   And the options class, ApplicationOptions defined as follows:\n1 2 3 4  public class ApplicationOptions { public string ApplicationName { get; set; } }    IOptions\u0026lt;\u0026gt; ✅ Added as DI container as singleton\n❌ Does not allow reading of the configuration settings from source after the app has started.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  var builder = WebApplication.CreateBuilder(args); // get the \u0026#34;appConfiguration\u0026#34; section from the configuration  //(appsettings.json in this case) var optionSection = builder.Configuration.GetSection(\u0026#34;appConfiguration\u0026#34;); // add to DI as ApplicationOptions  builder.Services.Configure\u0026lt;ApplicationOptions\u0026gt;(optionSection); var app = builder.Build(); // endpoint, which has the IOptions injected into it from the // DI container app.MapGet(\u0026#34;/appname\u0026#34;, (IOptions\u0026lt;ApplicationOptions\u0026gt; options) =\u0026gt; { // .Value returns ApplicationOptions return options.Value.ApplicationName; }); app.Run();   When the endpoint /appname is called, the application name from the appsettings.json is returned, via IOptions.\nThis injects IOptions\u0026lt;ApplicationOptions\u0026gt; as a singleton, and if the value in the appsettings.json file changes while the application is running, the change will not be reflected in IOptions\u0026lt;ApplicationOptions\u0026gt;.\n IOptionsSnapshot\u0026lt;\u0026gt; ✅ Added as DI container as scoped\n✅ Supports named options\n✅ Configuration settings can be recomputed for each request (as the service is scoped)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  var builder = WebApplication.CreateBuilder(args); // get the \u0026#34;appConfiguration\u0026#34; section from the configuration  //(appsettings.json in this case) var optionSection = builder.Configuration.GetSection(\u0026#34;appConfiguration\u0026#34;); // add to DI as ApplicationOptions  builder.Services.Configure\u0026lt;ApplicationOptions\u0026gt;(optionSection); var app = builder.Build(); // endpoint, which has the IOptionsSnapshot injected into it from the // DI container app.MapGet(\u0026#34;/appname\u0026#34;, (IOptionsSnapshot\u0026lt;ApplicationOptions\u0026gt; options) =\u0026gt; { // .Value returns ApplicationOptions return options.Value.ApplicationName; }); app.Run();   This injects IOptionsSnapshot\u0026lt;ApplicationOptions\u0026gt; as scoped, and if the value in the appsettings.json file changes while the application is running, this change will be reflected in IOptionsSnapshot\u0026lt;ApplicationOptions\u0026gt;.\nIn other words, for each scope (http request) a new snapshot of the ApplicationOptions values is calculated from source, and injected.\n IOptionsMonitor\u0026lt;\u0026gt; ✅ Added as DI container as singleton\n✅ Supports named options\n✅ Supports options changed notifications\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  var builder = WebApplication.CreateBuilder(args); var optionSection = builder.Configuration.GetSection(\u0026#34;appConfiguration\u0026#34;); builder.Services.Configure\u0026lt;ApplicationOptions\u0026gt;(optionSection); var app = builder.Build(); app.Services.GetService\u0026lt;IOptionsMonitor\u0026lt;ApplicationOptions\u0026gt;\u0026gt;() .OnChange((ApplicationOptions options) =\u0026gt; { Console.WriteLine(options.ApplicationName); }); app.MapGet(\u0026#34;/appname\u0026#34;, (IOptionsMonitor\u0026lt;ApplicationOptions\u0026gt; options) =\u0026gt; { return options.CurrentValue.ApplicationName; }); app.Run();   This injects IOptionsMonitor\u0026lt;ApplicationOptions\u0026gt; as a singleton, but functions very much the same as IOptionsSnapshot. If the value in the appsettings.json file changes while the application is running, this change will be reflected in IOptionsMonitor\u0026lt;ApplicationOptions\u0026gt;.\nHowever IOptionsMonitor has the additional benefit of having an OnChange method, which accepts an Action\u0026lt;\u0026gt; which is called each time a value is changed. In other words, one can be notified of a value change.\nIn the above example, the lambda action method is called each time the value changes and writes the new value to the console (Line 11).\n Named Options Both IOptionsSnapshot and IOptionsMonitor support named options. What this means, is that multiple of the same options (but different values) can be added to the DI container with a name, and then retrieved by name.\nIf there are multiple sets of the same configuration structure, for example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026#34;cloudKeyConfiguration\u0026#34;: { \u0026#34;azure\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Microsoft\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;azurekey123\u0026#34; }, \u0026#34;aws\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Amazon\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;awskey456\u0026#34; }, \u0026#34;gcp\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Google\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;gcpkey789\u0026#34; } }   And the options class, CloudKeyOptions defined as follows:\n1 2 3 4 5 6  public class CloudKeyOptions { public string Name { get; set; } public string Key { get; set; } }   Usage is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  var builder = WebApplication.CreateBuilder(args); // add to DI container by name var optionSectionAzure = builder.Configuration.GetSection(\u0026#34;cloudKeyConfiguration:azure\u0026#34;); builder.Services.Configure\u0026lt;CloudKeyOptions\u0026gt;(\u0026#34;azure\u0026#34;, optionSectionAzure); var optionSectionAws = builder.Configuration.GetSection(\u0026#34;cloudKeyConfiguration:aws\u0026#34;); builder.Services.Configure\u0026lt;CloudKeyOptions\u0026gt;(\u0026#34;aws\u0026#34;, optionSectionAws); var optionSectionGcp = builder.Configuration.GetSection(\u0026#34;cloudKeyConfiguration:gcp\u0026#34;); builder.Services.Configure\u0026lt;CloudKeyOptions\u0026gt;(\u0026#34;gcp\u0026#34;, optionSectionGcp); var app = builder.Build(); app.MapGet(\u0026#34;/key/{provider}\u0026#34;, (string provider, IOptionsSnapshot\u0026lt;CloudKeyOptions\u0026gt; options) =\u0026gt; { return options.Get(provider)?.Key; }); app.Run();   IOptionsSnapshot\u0026lt;CloudKeyOptions\u0026gt; is injected, and a query string parameter is used to determine which named option to retrieve.\n References C# configuration fundamentals\nOptions Pattern In .NET\n     Daily Drop 3: 03-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-03T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/03-ioptions/","title":"Use IOptions\u003c\u003e for application configuration"},{"content":"Daily Knowledge Drop Heard about the new feature of C# called records, but not entirely sure whats its all about? Here\u0026rsquo;s the brief overview.\nRecords:\n Are reference types - just like normal classes Have equality based on value and not memory - unlike normal classes Are immutable (sometimes) - unlike normal classes Can be inherited - just like normal classes  Internally the compiler converts will convert a record declaration to a specialized class, so that it conforms to the above.\n Declaring a record Records can be declared similar to class declaration. Records created with nominal syntax are NOT immutable by default: 1 2 3 4 5  public record Song { public string Artist { get; set; } public string Title { get; set; } }  \nRecords can also be declared using positional syntax. These are immutable by default: 1  public record Song(string Artist, string Title);  \nInternally when using the positional syntax, a class is creates with init properties. This can also be done manually using nominal syntax to achieve the same result.\n Record ToString The ToString method of a record is overwritten (automatically) to output the record members, and not the record name (as with a class).\n  Consider the class declaration and usage (using .NET 6 minimal startup): 1 2 3 4 5 6 7 8 9 10  var song1 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); // This will output the class name: Song Console.WriteLine(song1.ToString()); public class Song { public string Artist { get; set; } public string Title { get; set; } }  \nThe above will output the class name: Song\n  Now lets look at a record declaration and usage (using .NET 6 minimal startup): 1 2 3 4 5 6 7  var song1 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); // This will output the class name: // Song { Artist = Foo Fighters, Title = Everlong } Console.WriteLine(song1.ToString()); public record Song(string Artist, string Title);  \nThe above will output the record values: Song { Artist = Foo Fighters, Title = Everlong }\n   Record equality Classes are equal if their memory location is equal (ie. they are the exact same object), while records are equal if the value of the members are equal.\n  Consider the class declaration and usage (using .NET 6 minimal startup): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  var song1 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); var song2 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); var song3 = song2; // This will output FALSE, as the objects don\u0026#39;t // point to the same memory Console.WriteLine(song1 == song2); // This will output TRUE, as the objects do // point to the same memory Console.WriteLine(song2 == song3); public class Song { public string Artist { get; set; } public string Title { get; set; } }  \nThe above for the above:\nFalse\nTrue\n  Now lets look at a record declaration and usage (using .NET 6 minimal startup): 1 2 3 4 5 6 7 8 9 10 11 12 13  var song1 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); var song2 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); var song3 = song2; // This will output TRUE, as the objects have // the same property values Console.WriteLine(song1 == song2); // This will output TRUE, as the objects have // the same property values Console.WriteLine(song2 == song3); public record Song(string Artist, string Title);  \nThe above for the above:\nTrue\nTrue\n   Immutability and cloning As mentioned, records declared with positional syntax are immutable.\n❌ This will not even compile: 1 2  var song1 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); song1.Title = \u0026#34;Learn to Fly\u0026#34;;  \n✅ This will compile and work: 1 2  var song1 = new Song(\u0026#34;Foo Fighters\u0026#34;, \u0026#34;Everlong\u0026#34;); var song2 = song1 with { Title = \u0026#34;Learn to Fly\u0026#34;};  \nThis is creating a copy of the song1 instance, and then changing the Title property value. The original object is not changed at all.\nWith nominal syntax declaration, both of the above are valid.\n Notes As part of C#10, record struct was introduced. If not specified, then the default is class.\n1 2 3 4 5 6 7 8  // This will declare a record class public record Song(string Artist, string Title); // This will declare a record class public record class Song(string Artist, string Title); // This will declare a record struct public record struct Song(string Artist, string Title);   There is a lot more detail to records (see the references below) but the above should give a rundown of the record highlights.\n References C# Records\nMicrosoft Docs - Records\n     Daily Drop 2: 02-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-02T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/02-record-intro/","title":"C# Records - the rundown"},{"content":"Daily Knowledge Drop When performing logging using the ILogger interface, to have more effective memory usage, ensure to check if logging is enabled for the relevant log level before calling the log method.\nFor example:\n❌ Don\u0026rsquo;t do this: 1  logger.LogWarning(\u0026#34;Value is outside expected range of \u0026#39;{0}\u0026#39; to \u0026#39;{1}\u0026#39;\u0026#34;, 100, 120);  \n✅ Do this: 1 2 3 4  if(logger.IsEnabled(LogLevel.Warning)) { logger.LogWarning(\u0026#34;Value is outside expected range of \u0026#39;{0}\u0026#39; to \u0026#39;{1}\u0026#39;\u0026#34;, 100, 120); }  \nBoth examples will:\n Output the message if the Warning log level is enabled Not output the message if the Warning log level is not enabled, for example if the Default log level in the appsettings.json has been set to Error.  The resulted output in both examples are the same, the message output when Warning log level is enabled, and the message is not output when the Warning log level is disabled - so why even do the additional IsEnabled check?\n Why check? Internally, the ILogger implementation will check if the requested log level (warning in the above examples) is enabled or not and output the message accordingly.\nThe problem with this, and the above examples, is the way in which the parameters are passed int the Log methods.\nAs you can see below, the method takes the message and then parameters as an object array:\n Object array params \nWhy is this not ideal?\nIn the above examples, the two parameter values (100 and 120) are integers which are store on the stack. However when sent to the method as parameters, they are boxed into objects which are then stored on the heap. This boxing means additional memory needs to be allocated, and also means this additional memory needs to be cleaned up by the garbage collector as some point.\nIncluding the logger.IsEnabled call will ensure the Log method is not called, the parameters are never boxed, and the additional memory is never allocated.\nWill this make a fundamental difference when outputting one warning message as in the above example? No.\nWill this make a fundamental difference when outputting thousands or tens of thousands of messages in your application? Probably\nAt least now with this knowledge, you can make an informed decision whether the additional checks are required or not for your specific use case. As always, if unsure benchmark the results (using BenchmarkDotNet for example) for your use case.\n Notes There are other potentially better ways to do logging - for example, this post on Structured logging using Serilog describes the problems when traditional logging, and how to implement Serilog to improve the logging experience.\nHowever, if you are currently using the default ILogger implementation, consider the above examples and the impact on memory.\n References You are doing .NET logging wrong. Let\u0026rsquo;s fix it\n     Daily Drop 1: 01-02-2022   At the start of 2022 I set myself the goal of learning one new coding related piece of knowledge a day.\nIt could be anything - some .NET/C# functionality I wasn't aware of, a design practice, a cool new coding technique, or just something I find interesting. It could be something I knew at one point but had forgotten, or something completely new, which I may or may never actually use.\nThe Daily Drop is a record of these pieces of knowledge - writing about and summarizing them helps re-enforce the information for myself, as well as potentially helps others learn something new as well.    ","date":"2022-02-01T01:00:00+02:00","permalink":"https://always-developing.github.io/dailydrop/2022/02/01-ilogger-isenabled/","title":"Use the ILogger IsEnabled method"},{"content":"Introduction This post will give an introduction to structured logging, why its needed and should be used. It will also go into detail how to implement and customize the output using Serilog.\n Default .NET Logging Before looking at structured logging, we\u0026rsquo;ll take a look at the default .NET logging implementation.\nThe default logger can be utilized by injecting ILogger\u0026lt;CategoryName\u0026gt; into the relevant constructor. The ILogger\u0026lt;\u0026gt; interface and its implementation are registered automatically with the .NET dependency injection container on startup.\nLet\u0026rsquo;s look at an example using the default minimal API project template (using .NET6). This is not representative of a real production scenario, and is used only for demo purposes (e.g. an exception generally should not be caught, logged and ignored)\nBelow is a modified version of the default GET endpoint which is included as part of the template.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  app.MapGet(\u0026#34;/weatherforecast\u0026#34;, (ILogger\u0026lt;Program\u0026gt; logger) =\u0026gt; { logger.LogDebug(\u0026#34;weatherforecast: Entered\u0026#34;); var forecast = Enumerable.Range(1, 5).Select(index =\u0026gt; new WeatherForecast ( DateTime.Now.AddDays(index), Random.Shared.Next(-20, 55), summaries[Random.Shared.Next(summaries.Length)] )) .ToArray(); logger.LogInformation($\u0026#34;Number of forecasts: \u0026#39;{forecast.Count()}\u0026#39;.\u0026#34; + $\u0026#34; Max temperature of: \u0026#39;{forecast.Max(x =\u0026gt; x.TemperatureC)}\u0026#39;\u0026#34;); try { if(forecast.Any(x =\u0026gt; x.TemperatureC \u0026gt; 50)) { throw new Exception(\u0026#34;Temperature is too high\u0026#34;); } } catch (Exception ex) { logger.LogError(ex.Message); } finally { logger.LogDebug(\u0026#34;weatherforecast: Exit\u0026#34;); } return forecast; }) .WithName(\u0026#34;GetWeatherForecast\u0026#34;);    Line 1: ILogger\u0026lt;\u0026gt; is injected. The same can be done using the constructor of any class. Line 3 \u0026amp; 30: A debug message is logged when the method is entered and exited. Line 14 \u0026amp; 15: An informational message is logged to give some context as to what the method output. Line 19-22: If any of the temperature values about to be returned are greater than 50C, throw a exception. Line 24-27: Catch any exceptions, and log the error message.  The output when the application is run, and the above method is invoked, is as follows:\n Default logger output \n The log level (e.g. debug, information, error) is reflected on the left hand side, in the various colours. The Program [0] shown refers to the CategoryName of the ILogger instance. This is determine by the full name (namespace + class name) of the generic parameter used when injecting ILogger\u0026lt;\u0026gt;.  In the above example, ILogger\u0026lt;Program\u0026gt; is injected, so the category is the full name of Program, which in this example is just Program. The [0] refers to an EventId (in this case, this has not been set)    The Logging section in the appsettings.json file can be used to determine the minimum log level for a specific category name, or for all categories. Below is a sample the appsettings.json Logging section:\n1 2 3 4 5 6  \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;Microsoft.AspNetCore\u0026#34;: \u0026#34;Error\u0026#34; } }   In the above example, as the default log level is \u0026ldquo;Information\u0026rdquo;, invoking logger.LogDebug would not output any data as debug has a lower log level than information.\nIn additional, any log calls which have a category name of \u0026ldquo;Microsoft.AspNetCore\u0026rdquo; will not be logged unless error or above is being logged.\nThis mechanism can be used to log different types of data, based on the category of the data.\nThere is more to the default .NET logging infrastructure, not covered in this post - see the references below which contain a link to the official .NET logging documentation.\n The issue with default logging The default logging described above works well, and there is nothing inherently \u0026quot;wrong\u0026quot; with it.\nHowever, the big problem is that there is no consistency with the structure of the information being output.\n What time was the message output? What application logged the message? Especially important if multiple application are logging to a central location How to identity if multiple message are related or linked to each other? How can we tell which messages are all related to a single http request, especially if multiple requests are being served at the same time?  There is also the question of how a collection of messages in various different formats can easily be indexed and searched.\nThese could all be addressed by manually making sure that each and every time any message is logged that it:\n Contains the date and time Contains the application name Contains a context/request id  However, there is still no guaranteed message structure and format - this is where structured logging steps in.\nStructured logging ensures that any information which is output, is always done so in a consistent, structured, well-defined format.\n Structured logging .NET doesn\u0026rsquo;t perform structured logging out the box, so a 3rd party library will be used - Serilog. Serilog has become the defacto standard for doing structured logging due to its ease of use, and configurability.\nSerilog works by replacing the default ILogger\u0026lt;\u0026gt; implementation with its own implementation - so no changes are required to any part of the code which use any ILogger methods. The application only needs to be configured on startup to use the Serilog implementation instead of the default one.\n     Serilog can be configured to send the log messages to one or multiple sink(s), which are data destinations. In the samples below only the console sink will be configured\n   In the below example. the Serilog, Serilog.AspNetCore and Serilog.Sinks.Console NuGet packages have been added to the project.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  using Serilog; var builder = WebApplication.CreateBuilder(args); builder.Services.AddEndpointsApiExplorer(); builder.Services.AddSwaggerGen(); builder.Host.UseSerilog((context, loggerConfig) =\u0026gt; { loggerConfig.WriteTo.Console(); }); var app = builder.Build(); // Configure the HTTP request pipeline. if (app.Environment.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(); }   Lines 1 as well as lines 8-11 were the only changes made to the application. The code is configuring the builder host (an IHostBuilder implementation) to Use Serilog, and then configures which sinks to Write To.\nAs Serilog.Sinks.Console is the only Serilog sink package added to the project, only \u0026ldquo;WriteTo.Console\u0026rdquo; is available.\nBy adding just these few lines, Serilog now takes over the implementation of ILogger\u0026lt;\u0026gt;, and the output now looks as follows:\n Default Serilog output \nThe format of the output is now always in a standard format, the Serilog default output template which is {Timestamp:HH:mm:ss} [{EventType:x8} {Level:u3}] {Message:lj}{NewLine}{Exception}\nHowever, the output template can be updated and customized, which will be explored in the next section.\n Refine and customize Object parameters One important aspect of Serilog, is that it will automatically serialize object parameters to JSON and reflect that in the output, while the default .NET ILogger implementation will call the ToString() method on the object.\nIn our sample, this actually results in the same output, as WeatherForecast is a record and it\u0026rsquo;s ToString() implementation will return a JSON representation of the record.\nIf the ILogger is used to log a record of type WeatherForecast:\n1  logger.LogInformation(\u0026#34;Forecast[0]: {@WeatherForecast}\u0026#34;, forecasts[0]);   The output message is the same, just in different output formats:\nDefault .NET ILogger:  Default logger record output \nSerilog:\n Serilog record output \nHowever, if WeatherForecast was a class, instead of a record, the output would be vastly different.\nAssume that WeatherForecast is now a class with the same fields as the record, and that forecasts[0] is an instance of class WeatherForecast:\nDefault .NET ILogger:  Default logger class output \nSerilog:\n Serilog class output \nThe default .NET ILogger outputs the ToString() result, while Serilog outputs a the result of serializing the object (as well as including the object type).\n Output customization There are a couple of ways to change the output format:\nOutput Format When specifying which sinks to write to, it is possible to overwrite the default output template for that sink. In the below example,\n The log level has been moved to the start of the template A constant application name (\u0026ldquo;StructuredLoggingDemo\u0026rdquo;) has been included Milliseconds now included in the time stamp  1 2 3 4 5  builder.Host.UseSerilog((context, loggerConfig) =\u0026gt; { loggerConfig.WriteTo.Console(outputTemplate: \u0026#34;[{EventType:x8} {Level:u3}] =\u0026gt; \u0026#34; + \u0026#34;StructuredLoggingDemo: {Timestamp:HH:mm:ss:ms} {Message:lj}{NewLine}{Exception}\u0026#34;); });   This results in the output looking as follows, with the updates mentioned above included:\n Custom output template \nSerilog, and by extension the template, can also be enriched with additional properties at runtime.\nBelow Serilog is enriched with:\n The application name, using reflection The application start up date (admittedly, not the most useful thing to include on every log message, but acceptable for a demo application)  These additional properties are then being utilized in the output template with the format {Enrich_Property_Name} ({ApplicationName} and {StartupDate} in the below example)\n1 2 3 4 5 6 7 8 9 10 11 12  builder.Host.UseSerilog((context, loggerConfig) =\u0026gt; { loggerConfig .Enrich.WithProperty(\u0026#34;ApplicationName\u0026#34;, Assembly.GetExecutingAssembly().GetName().Name) .Enrich.WithProperty(\u0026#34;StartupDate\u0026#34;, DateTime.Now.ToShortDateString()) .WriteTo.Console(outputTemplate: \u0026#34;[{EventType:x8} {Level:u3}] =\u0026gt; {ApplicationName} \u0026#34; + \u0026#34;({StartupDate}): {Timestamp:HH:mm:ss:ms}\u0026#34; + \u0026#34; {Message:lj}{NewLine}{Exception}\u0026#34;); });   This results in the output looking as follows, with the updates mentioned above:\n Enriched output template \nCustom enrichers can also be written to automatically enrich the logger with specific set of properties. There are also a number of enrichers available \u0026ldquo;out the box\u0026rdquo; as NuGet packages, which when included make the values available for use in the output template.\nFor example, the Serilog.Enrichers.Environment package will enrich the logger with System Environment properties.\nFormatters Serilog also the concept of formatters - which are used to change and customize the format of the output. In the preceding examples, the output has been in plain text - a formatter can be used to output the entire output message in JSON, for example.\nThere are a number formatters available \u0026ldquo;out the box\u0026rdquo; as NuGet packages.\nIn the below example, the Serilog.Formatting.Compact NuGet package has been referenced, and the CompactJsonFormatter added to the Serilog configuration.\n1 2 3 4 5 6 7 8 9  builder.Host.UseSerilog((context, loggerConfig) =\u0026gt; { loggerConfig .Enrich.WithProperty(\u0026#34;ApplicationName\u0026#34;, Assembly.GetExecutingAssembly().GetName().Name) .Enrich.WithProperty(\u0026#34;StartupDate\u0026#34;, DateTime.Now.ToShortDateString()) .WriteTo.Console(new CompactJsonFormatter()); });   This results in the output as follows:\n Compact JSON output \nAt first glance, this is harder to read - so why would we want to output the messages in this format?\n Benefits of structured output While the output above is definitely harder to read as is, in a production environment its not often that output would be written directly to the console. Its more often that the data would be sent to a log analyzing system (such as The ELK Stack, Datadog or one of the many alternatives) for consumption.\nThese systems allow for:\n The consumption of log data The analysis of log data Visualization of log data  With the entire output being structured as JSON (not just the message portion as in earlier examples), the entire output can now be easily indexed, searched, analyzed and visualized.\n1 2 3 4 5 6 7 8 9 10  { \u0026#34;@t\u0026#34;: \u0026#34;2022-01-22T04:44:31.8254123Z\u0026#34;, \u0026#34;@mt\u0026#34;: \u0026#34;Number of forecasts: \u0026#39;5\u0026#39;. Max temperature of: \u0026#39;43\u0026#39;\u0026#34;, \u0026#34;SourceContext\u0026#34;: \u0026#34;Program\u0026#34;, \u0026#34;RequestId\u0026#34;: \u0026#34;0HMETC7FHFGLL:00000003\u0026#34;, \u0026#34;RequestPath\u0026#34;: \u0026#34;/weatherforecast\u0026#34;, \u0026#34;ConnectionId\u0026#34;: \u0026#34;0HMETC7FHFGLL\u0026#34;, \u0026#34;ApplicationName\u0026#34;: \u0026#34;StructuredLoggingDemo\u0026#34;, \u0026#34;StartupDate\u0026#34;: \u0026#34;2022/01/22\u0026#34; }   In addition to the above benefits, there is also the performance aspect. The volume of output data as well as the output format and template format all have an impact on performance. This should be taken into account and benchmarked for each use case.\nIn my experience, the CompactJsonFormatter output was faster and had a better memory impact when compared with default .NET and default Serilog functionality.\n Log levels A note on log levels - Serilog provides the same functionality as the default .NET ILogger implementation, with regards to setting the minimum log level at a default global level, at a category name level and at a storage/sink level.\nThe configuration of Serilog is different to that of the default ILogger, but they both essentially provide the same capabilities.\nSee the references for additional documentation with more details.\n Conclusion There is a log more detail and functionality provided by both the default .NET ILogger implementation as well as the Serilog implementation. Additional resources are provided below should you want to dive deeper into the capabilities of either of the implementations.\nHowever after reading this post, you should now have an understanding of the basic functionality of each, how to refine and customize the output to suite your applications needs, as well as why structured logging can be beneficial to performance and data visibility.\n References Logging in .NET Core and ASP.NET Core - official documentation\n.NET Core and ASP.NET Core log levels\nSerilog Wiki\nSerilog log levels\nSerilog enrichers\nSerilog formatters\n","date":"2022-01-31T03:00:00+02:00","permalink":"https://always-developing.github.io/p/01-2022-structured-logging/","title":"Structured logging - an introduction"},{"content":"Introduction This post will give a brief introduction and explanation to Git and Git workflows, and then go into detail for the most prominent workflows (in my experience), when to use them, as well as the main pros and cons of each approach.\n Background Git introduction For those unfamiliar, Git (as defined on git-scm.com) is a free and open source distributed version control system, designed to handle everything from small to very large projects with speed and efficiency.\nThis post will not go into the details of Git, but some characteristics:\n Distributed Fast Efficient Cheap and simple branching Has a learning curve - but very easy to use once understood  Some notes:\n Point 4: This is the key to Git. Creating and working with branches is simple and quick. This is key to most well working workflow. Point 5: This is the opposite of what is described on git-scm.com, which states that Git is easy to learn. I have found that this is not the case, especially when coming from a background of a source control system such as SVN or Azure Devops TFVC. However once the basics are understood, then it is easy to use.   Git branches When using Git, there are usually two types of branches used:\n Long-lived branches: These are permanent branches in the repository. A repository will often have two long-lived branched called development and main (or master) Short-lived branches: These are temporary branches created for a specific purpose (such as adding a new feature), and are deleted once they have served their purpose. Generally these branches follow a naming standard, often feature/issue-number, feature/description - but this is flexible and up to do team to decide. However, whichever standard is chosen, it should be consistently used when naming branches.  Working through the various workflows below will add to and expand on the above definitions.\n Workflow introduction In this context, a workflow is simply a recipe or recommendation for how to use Git to accomplish work in a consistent and productive manner. Typically for software development, this work involves code being released into production, and is usually facilitated by a build server and CI/CD pipelines (using GitHub Actions, Azure Devops Pipelines, Jenkins, for example)\nBelow a number of popular widely accepted best practice workflows will be described (Git Flow and GitHub Flow), as well as two workflows I\u0026rsquo;ve personally experienced being used extensively in certain use cases.\n Workflows The diagram legend:\n Legend for the workflows \nA note on builds - In the below workflow explanations, when a build is mentioned, it can be done in one of two ways:\n Build configuration method: multiple artifacts are produced, each one with a different build configuration (dev, test, production). As multiple artifacts are being produced, this usually is a longer process, and a more legacy approach (but still valid). Environment variable method: one artifacts is produced, and the configuration (dev, test, production) is determined by an environment variable injected into the application on startup. The benefit of this approach is one can ensure that the exact same code is deployed to all environments, and as only one artifact is produced, the process is quicker. This is a newer approach.   Solo Flow Solo Flow explained:\nThis is the simplest of flows, and doesn\u0026rsquo;t involve any additional branches. Solo Flow is named as such as only one branch is involved (usually main) and typically this flow would be used by a solo developer. The single branch is long-lived and exists for the entirety of the repository.\nPros:\n Very simple to implement  Cons:\n Branch is not consistently stable * A hotfix could cause complications ** Doesn\u0026rsquo;t scale to multiple developers easily  When best to use:\n When only an individual developer is working in the repository When the code is not going to have \u0026ldquo;releases\u0026rdquo; - such as scratchpad, playpen or proof of concept/technology repositories   Solo Flow process:\n Solo Flow \n Code is committed directly into the main branch A build is done, and released to the relevant environment. Usually this is dev -\u0026gt; test -\u0026gt; production proceeding through each environment as the release is tested and signed off If a hotfix is required, the fix is committed to the main branch, tested and then released  Additional notes:\n  * Stability: At any given time, it is not known if the branch is stable or not as the code in the main branch would not necessarily have been tested. For example, in the diagram at point *, if a hotfix would be required, there is no guarantee that the current state of the branch is stable, as the previous build or commit may not have been tested.\n  ** Complications: Related to the previous point, if an urgent hot fix is required, it may cause complications as there could be untested commits which would \u0026quot;interfere\u0026quot; with the hot fix release. In the example, the previous commit, which is unrelated to the hotfix, would now need to be included in the hotfix release (tested or not), or a number of Git operations would need to be performed to try undo the untested code.\n   First Flow First Flow explained:\nThis is the simplest of flows which makes use of multiple branches. Named First Flow as it is most likely the first flow one might use involving multiple branches. Two long-lived branches exists with this flow, usually development and main, and exist for the entirety of the repository\nPros:\n Very simple to implement Main branch is fairly stable *  Cons:\n A hotfix may cause complications ** Doesn\u0026rsquo;t scale to multiple developers easily  When best to use:\n When only an individual or very small (1-3) number of contributors are working in the repository   First Flow process:\n First Flow \n The development branch is initially, once off, branched from the main branch Code is committed directly into the development branch A build is done, and released to the development environment Once dev-tested in the development environment, the code is merged (via a pull request) into the main branch Another build is then done and released to the relevant environment. Usually this is test/uat -\u0026gt; production proceeding through each environment as the release is tested and signed off If a hotfix is required, the fix is committed to the main branch, a build created, tested and then released. The hotfix code is also merged back into the development branch  Additional notes:\n  * Stability: As with the Solo Flow, the situation regarding stability is the same, at any given time, it is not known if the branch is stable or not. However, with the First Flow the code has been deployed to and tested in a development environment before being merged into main. This does obviously not mean its stable once merged into main, however it is more stable when compared with the Solo Flow.\nFor example, in the diagram at point *, when the hotfix is required, there is no guarantee that the current state of the branch is stable, as the previous build or commit may not have been tested.\n  ** Complications: As with the Solo Flow, if an urgent hot fix is required, it may cause complications as there could be untested commits which would \u0026quot;interfere\u0026quot; with the hot fix release. In the example, the previous commit, which is unrelated to the hotfix, would now need to be tested and included in the hotfix build., or the main branch would need to somehow be reverted back to before the commit\n   Gitflow Gitflow explained:\nThe Gitflow workflow is an industry standard workflow, and has gained in popularity in the past few years. It has fallen slightly out of popularity in favour of trunk based workflows (such as GitHub Flow described below), however it still has its place.\nIt especially works well when facilitating a more traditional release model, releasing to production on a known schedule (e.g. every two weeks). It is not suited to the model of releasing multiple times per day, as the flow of code through the workflow can take time.\nPros:\n Main branch is always stable * Scales well with large number of developers Handles hotfixes well ** Code reviews can be built into the workflow process ***  Cons:\n Complicated workflow Takes time to push code through the workflow  When best to use:\n When there are a number of contributors to the repository (although the workflow does also work with smaller teams as well) When the product is to be released on a known scheduled (e.g. every two weeks)   Gitflow process:\n Git Flow \n The development branch is initially, once off, branched from the main branch For any changes (apart from production hotfixes), a new short-live feature branch is created from the development branch Code is committed into the feature branch Once the coding is completed, the feature branch is merged into the development branch (via a pull request). Commits are not permitted directly into development branch, all code commits are done via pull requests A build is done and released to the development environment Once dev-tested in the development environment, a new short-lives release branch is created from the development branch A build is done from this release branch and released initially into the tst environment If testing is not successful, the release branch is abandoned and deleted A new feature branch will be created to address the cause of the release failing testing in step 8, and steps 2-8 are repeated Once testing has been completed successfully it is released into the production environment The release branch is then merged into the main branch (via a pull request) and deleted   Git Flow hotfix \nIf a hotfix is required, a short-lived hotfix branch is created from the main branch The code fix is committed into the hotfix branch, a build is done and released into the tst environment Once the build has been successfully tested, it is then released into the production environment The hotfix branch is then merged into the main as well as the development branch, and then deleted  Additional notes:\n  * Stability: With the Git Flow workflow, code is only merged into the main branch once is has been tested and released into production. Therefore at any given time, the code in the main branch should be stable and tested, and is a snapshot of the current state of the production environment.\n  ** Complications: With Git Flow, as the code in the main branch is always a snapshot of the current production environment, if an urgent hot fix is required, the main branch will not have any untested committed code which can cause complications with the hotfix release.\n  *** Code reviews: In step 4 above, the merging of the code is done via a pull request. The pull request mechanism easily facilities code reviews as it allows for review of all the code being merged before approval. As the pull request process is built into the Git Flow workflow, a code review process is also (optionally, but recommended) built into the process.\n   GitHub Flow Gitflow explained::\nThe GitHub Flow workflow is also an industry standard workflow - which came about and has gained in popularity due to its simplicity. Even though, as the name described, the GitHub Flow is primarily used when working with GitHub, it is not limited to only being used on GitHub and can be used on any platform with a Git repository.\nThis workflow works especially well when doing production deployments often, not largely based around a scheduled release. It is well suited to the model of releasing multiple times per day, as it is simple and fast to get code through the workflow.\nPros:\n Very simple process Main branch is always stable * Scales well with large number of developers Handles hotfixes well ** Code reviews can be built into the workflow process ***  Cons:\n Stricter controls and discipline required to make it work successfully ****  When best to use:\n When there are a number of contributors to the repository (although the workflow does also work with smaller teams as well) When the product is to be released often, not necessarily on a set schedule (daily or multiple times per day) When the team has mature processes, checks and balances in place (unit tests, code reviews, dev standards)   Gitflow process::\n GitHub Flow \n Only one long-lived main branch exists For any changes, a new short-live feature branch is created from the main branch Code is committed into the feature branch Either during or after the coding process a pull request is created to merge into main - but not approved (yet) Once the code has been reviewed and discussed, a build and release is performed, proceeding, usually, through the dev -\u0026gt; test -\u0026gt; production environments The pull request is approved and the code merged into main, and the feature branch deleted Hotfixes follow the same process as features, following steps 2-6  Additional notes:\n  * Stability: With the GitHub Flow workflow, one of the hard rules is that anything is main is deployable. Therefor at any given time, the code in the main branch has to be stable, and should be code is only merged into main once tested.\n  ** Complications: As the code is being released into production as it is being \u0026ldquo;completed\u0026rdquo; (and reviewed and tested), there is almost always not complications with hotfix releases, as the code in the main branch is a snapshot of the latest code. Hotfixes and features are treated and released the same way.\n  *** Code reviews: In step 4 above, the merging of the code is done via a pull request. The pull request mechanism easily facilities code reviews as it allows for review of all the code being merged before it is approved. As the pull request process is built into the GitHub Flow workflow, a code review process is also (optionally) built into the process. However, as this flow is a lot \u0026ldquo;faster\u0026rdquo; than the GitFlow, the code review process is highly recommended and should always be part of the release pipeline.\n  **** Controls: Even though the workflow is very simply, it requires strict controls and discipline from the team to make it work, even under tight deadlines (which is often when steps and reviews are skipped). Due to the workflow\u0026rsquo;s rapid release nature, the pull request discussions and code reviews are essential in making sure that the code released and merged into main is quality code. Relevant unit tests should also be a high priority (they should always be a high priority, but especially with this workflow) to facilitate quick, but thorough testing and turn around time to release into the production environment.\n   Conclusion You should now have an understanding of a number of different workflows, their pros and codes and when to best use them. The workflows described in this post are by no means the only ones available, but are the most common and practical in a real world environment.\nA workflow shouldn\u0026rsquo;t be a hindrance or a bottleneck, but should facilitate and improve the process of getting code released. As a developer or a team of developers, you will need try a number of workflows, and adopt one which makes sense and works for you or the team.\n References Git\nGitFlow\nGitHub Flow\n","date":"2022-01-15T03:00:00+02:00","permalink":"https://always-developing.github.io/p/01-2022-git-workflow/","title":"Git workflows - explained"},{"content":"Symbol server explained What are symbols? When building a .NET project, symbol files (generally files with the extension of .pdb) are automatically created by the compiler. These symbol files contain metadata information about the source code (indexes, function names, line numbers, etc) and are used when debugging and stepping through code, by linking the debugger (e.g. Visual Studio) to the source code.\nGenerally, these symbol files are only available when developing locally, and building a project in debug configuration - that is, unless they are uploaded to a symbol server.\nWhat is a symbol server? A symbol server is a central location to store symbols - having the symbols available allow for the stepping into a referenced NuGet package code without having the source code available locally.\nThe source code doesn\u0026rsquo;t need to be part of the solution being built, or even on the local machine - the symbol file, made available by the symbol server will allow for full \u0026lsquo;step into\u0026rsquo; debugging experience.\n Why use a symbol server As mentioned above, having the symbols available via the server, allows for stepping into a referenced package\u0026rsquo;s source code without having the source directly available locally. Why would one need or want this to be possible?\n Help the package author debug and assist when issues are experienced using the package. This is especially useful in the corporate environment where the author of a package is potentially closer to the developers and applications using the package, and is required to assist with the usage and functioning of the package. Help users of the package understand in more depth what the package does and how. Especially useful in an Open Source environment where the author of the package is most likely further removed from the user of the package. With the user of the package having the option of stepping into the package source code, it facilitates more easily understanding the package and allows for the user more easily help themselves if any issues arise.  Even though each point above highlights the use case in a specific environment (corporate vs Open Source), both points can apply to either environment.\n     This post will focus on using Azure Devops as a build and symbol server, but other build and symbol servers can also be used and will mostly follow a similar processes to the one described in this post.\n    Producing symbols Configuring code The first step in the process, is to configure the project to produce symbols with the required metadata to allow for the debugging experience.\nTo do this, the required Source Link NuGet package must be added to the project. There are a number of different options available, based on where the repository is hosted.\nFor a repository hosted in a Git repository in Azure Devops, a reference to Microsoft.SourceLink.AzureRepos.Git is added.\n1 2 3 4  \u0026lt;PackageReference Include=\u0026#34;Microsoft.SourceLink.AzureRepos.Git\u0026#34; Version=\u0026#34;1.1.1\u0026#34;\u0026gt; \u0026lt;PrivateAssets\u0026gt;all\u0026lt;/PrivateAssets\u0026gt; \u0026lt;IncludeAssets\u0026gt;runtime; build; native; contentfiles; analyzers; buildtransitive\u0026lt;/IncludeAssets\u0026gt; \u0026lt;/PackageReference\u0026gt;        The Source Link reference added is required only as a development dependency and is only used during the build process. This is the reason the PrivateAssets property is set to All - this prevents the package consuming applications from also needing to install Source Link as a dependency.\n    Configuring CI/CD pipeline The next step is to have the CI/CD process produce the symbols, and then upload them to the symbol server.\n  Producing the symbols\nUsually when developing locally, .pdb files are only generated when running in debug configuration, when the code is un-optimized. However, When releasing a package, it should be built in release configuration with optimized code.\nWith the relevant Source Link package reference added (Microsoft.SourceLink.AzureRepos.Git), the code can be built in release configuration and have the symbols produced. The build can either be done using:\n dotnet build:\nExecute the dotnet build command with a build configuration of Release  Azure Devops dotnet task \n Azure Devops dotnet task detail  Visual Studio build:\nExecute the Visual Studio build task with build configuration of Release, and with the MSBuild Argument of /p:SourceLinkCreate=true  Azure Devops VS build task \n Azure Devops VS build task detail     Publishing the symbols:\nThe Index sources and publish symbols task is then used to publish the symbols to either a file share, or the Azure Devops symbol server  Azure Devops publish symbol task \n Azure Devops publish symbol detail \nGenerally the publishing of artifacts would be part of the release pipeline, and not the build. However the Index sources and publish symbols task is only available in the build pipeline.\n   Consuming symbols Configuring Visual Studio The final step is to configure Visual Studio with the details on how and when to download and use the symbols. Perform the following steps in Visual Studio.\n Configure the symbol server location:  Navigate to Tools -\u0026gt; Options -\u0026gt; Debugging -\u0026gt; Symbols Click New Azure Devops Symbol Server Location Select the account, and a list of symbol servers available to the account will be displayed. Chose the server. (in the screen shot below, none are shown as the always-developing Github account is not linked to Azure Devops) Click Connect     Azure Devops symbol server \n Configure the debugger settings:\n Navigate to Tools -\u0026gt; Options -\u0026gt; Debugging Ensure that Enable Just My Code is unchecked Ensure that Enable source server support is checked   Azure Devops symbol server \n  Configure which symbols to load automatically (optional but recommended):\nBy default symbols will automatically be loaded (after being downloaded) if they are available in any of the symbol servers. If an application references a number of packages where symbols are available, start-up time when running and debugging can be dramatically negatively impacted.\nVisual Studio can be configured to only load the packages specified - or only load packages based on a wildcard (this is incredibly useful if all NuGet packages share a common namespace structure, as might be the case especially in a corporate environment)\n Navigate to Tools -\u0026gt; Options -\u0026gt; Debugging -\u0026gt; Symbols Select Load only specific modules Click Specify included modules Click New Module Add the module name, or wildcard format   Specify which modules to load \n   NuGet symbol package This post focuses on building and hosting the symbols using Azure Devops - but just a small note publishing to NuGet.org if the package is publicly available.\nThe nuget.org symbol server uses the .snupkg file format for symbols, which are optionally generated when the nupkg file is generated. See this this document on the various ways of generating a .snupkg file.\n Final thoughts That\u0026rsquo;s all there is to it! Whether a package author or package consumer, having the option to step into the code will prove invaluable - with practically no additional development effort.\nIf possible (if the source code can be made public), I highly recommend making the symbols available, to everyone\u0026rsquo;s benefit!\n References Symbol files\nPublishing symbols\nNuGet symbols (slightly outdated, but still useful)\n","date":"2022-01-04T03:00:00+02:00","permalink":"https://always-developing.github.io/p/12-2021-devops-symbol-server/","title":"Azure Devops Symbol Server - a how to guide"},{"content":"The problem Entity Framework Core is a great go-to ORM for .NET, for any type of application provides almost all the functionality required to do successful database access out the box.\nHowever, there are two use cases, specifically with regards to retrieval of data, it doesn\u0026rsquo;t cater for - this post and the accompanying code sample/NuGet package attempts to provides solutions for these use cases.\nFirst, the setup - an EF DbContext which has one DbSet, for storing Blogs (the below is a standard DbContext configuration):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class BlogContext : DbContext { public BlogContext(DbContextOptions\u0026lt;BlogContext\u0026gt; options) : base(options) { } public Action\u0026lt;DbContextOptionsBuilder\u0026gt;? BlogContextOptionsBuilder { get; set; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { base.OnConfiguring(optionsBuilder); } // The DBSet for the Blog entity public DbSet\u0026lt;Blog\u0026gt; Blog { get; set; } } public class Blog { public Guid Id { get; set; } public string Title { get; set; } public string Owner { get; set; } public string Url { get; set; } public List\u0026lt;Post\u0026gt; Posts { get; set; } } public class Post { public Guid Id { get; set; } public string Title { get; set; } public string Content { get; set; } public int WordCount { get; set; } public Guid BlogId { get; set; } public Blog Blog { get; set; } }        The below use cases are fairly niche - in most day-to-day use cases, EF Core will do what is required out the box. The below solutions are intended to be used to enhance and work in conjunction with the normal DbContext.\nIf you find you are ONLY using the DbContext for the below use cases, it might make sense to investigate using another more suited ORM (such as Dapper).\nHowever if you are using EF Core and adding another ORM into your application doesn\u0026rsquo;t make sense, hopefully this post along with the source code + samples and NuGet package can assist you in resolving any issues.\n    DbSet is required To get a list of all Blogs, one of the following two lines of code can be used: 1 2 3  var blogs1 = context.Blog.AsNoTracking().ToList(); // OR var blogs2 = context.Set\u0026lt;Blog\u0026gt;().AsNoTracking().ToList();  \nSuppose only the Blog id and the url was required - any one of the below methods would achieve this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // Define a new type, called BlogUrl, which contains just BlogId and Url properties // Project into the new type var blogs1 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // Project into the new type using raw SQL var blogs2 = context.Set\u0026lt;Blog\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id, Url FROM Blog\u0026#34;) .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // Project into an anonymous type var blogs3 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // Project into an anonymous type using raw SQL  var blogs4 = context.Set\u0026lt;Blog\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id, Url FROM Blog\u0026#34;) .Select(x =\u0026gt; new { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList();    The issue here is that EF Core requires the retrieval to be executed off a DbSet. This means an entity and matching SQL statement cannot dynamically be thrown at EF Core at runtime, and have data successfully returned.\nFor example, the following code would not work unless the BlogUrl type has been added as a DbSet to the DbContext. 1 2 3  // Does not work unless a DbSet of type BlogUrl has been added var blogs = context.Set\u0026lt;BlogUrl\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList();  \nThis problem also extends to anonymous types - as their definition is only known at runtime, a DbSet cannot be created for them before runtime.\n Support for simple types Suppose now only a list of Blog ids is required to be returned - either one of the following would work:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // Define a new type, called BlogId, which contains just Id // Project into the new type var ids1 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new BlogId { Id = x.Id }) .AsNoTracking().ToList(); // Project into a list of Ids var ids2 = context.Set\u0026lt;Blog\u0026gt;() .AsNoTracking() .Select(x =\u0026gt; x.Id).ToList(); // Project into a list of Ids using raw sql var ids3 = context.Set\u0026lt;Blog\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id FROM Blog\u0026#34;) .AsNoTracking() .Select(x =\u0026gt; x.Id).ToList();   The issue here is that the DbSet type is required to be a reference type: This means a list of simple/value types (and other identifier types such as Guid) cannot be returned directly.\nThis is related to the first issue mentioned above - a simple/value type and matching SQL statement cannot dynamically be thrown at EF Core at runtime and have data returned.\nFor example, the following code would not work. 1 2 3  // This DOES NOT WORK (yet) var ids = context.Set\u0026lt;Guid\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id FROM Blog\u0026#34;) .AsNoTracking().ToList();  \n     Both issues this post addresses involves the retrieval data - EF Core change tracking functionality will not work, and is not intended to work with the proposed solutions.\nIf change tracking is required, then the dynamic route outlines in this post should not be used. This is the reason why all example use AsNoTracking() when retrieving the data.\n    Dynamic entity results Projected entity The first issue to resolve, is the ability to populate an entity without having a Dbset added to the DbContext for the entity.\nWe cannot really get around this requirement - EF Core always need the entity be added as a DbSet, however what if it was added dynamically at runtime?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class RuntimeContext\u0026lt;T\u0026gt; : DbContext where T : class { public RuntimeContext() { } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseSqlite($\u0026#34;Data Source={Environment .GetFolderPath(Environment.SpecialFolder.MyDocuments)}\\\\BlogDatabase.db\u0026#34;); base.OnConfiguring(optionsBuilder); } protected override void OnModelCreating(ModelBuilder modelBuilder) { var t = modelBuilder.Entity\u0026lt;T\u0026gt;().HasNoKey(); foreach (var prop in typeof(T) .GetProperties(BindingFlags.Instance | BindingFlags.Public)) { if (!prop.CustomAttributes .Any(a =\u0026gt; a.AttributeType == typeof(NotMappedAttribute))) { t.Property(prop.Name); } } base.OnModelCreating(modelBuilder); } }   Here a context has been created (inherits from DbContext):\n Line 1: It takes in a generic type T Line 15-29: The model for the context is created (when the context is initialized)  Line 17: Type T is added as a DbSet to the context, but without a Key. A key is not required as this will be used only for data retrieval and with AsNoTracking. Line 18-26: Using reflection, the relevant properties of type T are added to the DbSet entity.    The following code will now work, without BlogUrl being added as a DbSet beforehand: 1 2 3  using var dynContext = new RuntimeContext\u0026lt;BlogUrl\u0026gt;(); var blogs = dynContext.Set\u0026lt;BlogUrl\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList()  \nAs this is all being setup dynamically, EF will not know how to generate the SQL for the dynamic entity - this is why raw SQL will always need to be supplied for this solution. The solution could be expanded to include this functionality in future, but this is outside the scope of this post.\nThis is now a working dynamic runtime context - however there are still a few broader issues which need to be resolved, which we\u0026rsquo;ll get to later in the post:\n Dependency Injection - There needs to be a way to configure the DI container with the dynamic runtime context when the underlying original context is configured. Dynamic Configuration: In the above, the configuration of the dynamic runtime context is hardcoded. Ideally this context would be initialized with the same configuration as the original context.   Anonymous entity As it stands, the core of the above code will work with anonymous types - just one small issue to resolve, and thats how to convert the anonymous type to T.\nTo convert the anonymous object to T, we have to inter T by example:\n1 2 3 4 5 6 7 8 9  var anon = new { BlogId = 0, Url = \u0026#34;\u0026#34; }; var blog = CallWithAnon(anon); static T CallWithAnon\u0026lt;T\u0026gt;(T example) where T: class { using var dynContext = new RuntimeContext\u0026lt;T\u0026gt;(); return dynContext.Set\u0026lt;T\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().First(); }    Line 1: Declare an example anonymous object with the relevant properties, using default values Line 2: Invoke the method just using the example object, and not specifying T Line 4-9: T is inferred from the example parameter (which is not used in the method - it is only used for the inference) and can successfully call into the dynamic runtime context   Dynamic value type results The next issue to resolve, is the ability to get a simple type or list of simple types from EF Core dynamically. The term simple type is used very loosely to refer to following types:\n Value types: int, bool, float, char etc Common Unique Identifier: Guid Simple value classes: string  As mentioned previously, EF Core requires a query be executed off a DbSet - another requirement is that the DbSet type be a reference type (a class).\nEven with the dynamic runtime context, the following code would not work as a DbSet of type Guid cannot be dynamically created (as its not a reference type): 1 2 3  // This DOES NOT WORK (yet) var blogs = dynContext.Set\u0026lt;Guid\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id FROM Blog\u0026#34;) .AsNoTracking().ToList();  \nWe cannot really get around the requirement that the DbSet be a reference type - however, what can be done is to dynamically converted the simple type to a reference type, run the query and converted the results back to a simple type\nFirst lets create a reference type class, which will act as a wrapper: 1 2 3 4  public class SimpleType\u0026lt;TValue\u0026gt; { public TValue Value { get; set; } }  \nThere are no constraints on TValue, as there are no generic constraints which will work for all the types we require (value types, Guid and string).\nNow we can use this reference wrapper class, and call the dynamic runtime context: 1 2 3 4  using var dynContext = new RuntimeContext\u0026lt;SimpleType\u0026lt;Guid\u0026gt;\u0026gt;(); var id = dynContext.Set\u0026lt;SimpleType\u0026lt;Guid\u0026gt;\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().First().Value;  \nThe above will work, but we no have two more broader issues which need to be resolved:\n Still using reference type: We are still using a reference type for the DbSet and have to manually wrap the simple type and then unwrap it Column called 'Value': The column in the SQL has to be called \u0026lsquo;Value\u0026rsquo; for it to match the field on the wrapper class and successfully retrieve the data   Resolving outstanding issues Code restructure Even though we have a working dynamic runtime context, there are 4 outstanding issues to be resolved, before we have a more complete solution. First lets restructure the code a bit to make these easier to resolve.\n  Create a new class DynamicContext which accepts a generic DbContext. 1 2 3 4 5 6 7 8 9 10 11  public class DynamicContext\u0026lt;TContext\u0026gt; where TContext : DbContext { private readonly DbContext _originalContext; public DbContext Context { get { return _originalContext; } } public DynamicContext(TContext context) { _originalContext = context; } }  \n  Change RuntimeContext to accept a generic TContext of type DbContext, and make it internal instead of public. The reason for this will become more apparent as we start adding more functionality to DynamicContext. 1 2 3 4 5  internal class RuntimeContext\u0026lt;T, TContext\u0026gt; : DbContext where T : class where TContext : DbContext { // Rest of class implementation }  \n  DynamicContext will now become a wrapper and the public face of RuntimeContext and of the original DbContext - as we work through the outstanding issues below, more functionality will be added to DynamicContext to make use of RuntimeContext.\nThe four outstanding issues:\n Dependency Injection: There needs to be a way to configure the DI container with the runtime context as well as the original context Dynamic Configuration: The dynamic runtime context should use the same configuration as the original underlying DbContext Reference type wrapper: A reference type wrapper is still used for simple types, which has to manually be wrapped and unwrapped Column called 'Value': The column in the raw SQL has to be called \u0026lsquo;Value\u0026rsquo; as it has to match the field on the wrapper class   Dependency Injection As DynamicContext now takes a DbContext as a generic parameter, if a DbContext is added to the DI container DynamicContext should be added as well.\nTo do this, we\u0026rsquo;ll use extension methods which correspond to the existing .NET AddDbContext methods. For each overloaded AddDbContext method, an AddDynamicContext method will be added (an example of one of these methods): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public static IServiceCollection AddDynamicContext\u0026lt;TContext\u0026gt;( this IServiceCollection serviceCollection, Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction = null, ServiceLifetime contextLifetime = ServiceLifetime.Scoped, ServiceLifetime optionsLifetime = ServiceLifetime.Scoped) where TContext : DbContext { // Add the dynamic context for the original dbcontext serviceCollection.AddScoped\u0026lt;DynamicContext\u0026lt;TContext\u0026gt;\u0026gt;(); // add the dbcontext using the normal AddDbContext call return serviceCollection.AddDbContext\u0026lt;TContext, TContext\u0026gt;( optionsAction, contextLifetime, optionsLifetime ); }  \nThe method has the same parameters as the invoked AddDbContext method, and acts as a passthrough - on the way adding a record to the DI container for DynamicContext\u0026lt;T\u0026gt;.\nAn extension method is added for each variation of the AddDbContext method.\nWhen setting up the DI container, instead of calling AddDbContext, AddDynamicContext is now called. 1 2 3 4 5 6 7 8 9  // OLD .AddDbContext\u0026lt;BlogContext\u0026gt;(x =\u0026gt; x .UseSqlite($\u0026#34;Data Source={Environment .GetFolderPath(Environment.SpecialFolder.MyDocuments)}\\\\BlogDatabase.db\u0026#34;)) // NEW .AddDynamicContext\u0026lt;BlogContext\u0026gt;(x =\u0026gt; x .UseSqlite($\u0026#34;Data Source={Environment .GetFolderPath(Environment.SpecialFolder.MyDocuments)}\\\\BlogDatabase.db\u0026#34;))   \nWe can now inject DynamicContext\u0026lt;T\u0026gt; (where T is the DbContext) into the relevant constructor, and have access to the dynamic functionality provided by DynamicContext as well as access to the underlying DbContext, via the Context property.\nDependency injection taken care of!\n Dynamic Configuration Currently, the configuration of the RuntimeContext is hardcoded in the OnConfiguring method. Next let\u0026rsquo;s make it dynamic and have the same configuration as the underlying original DbContext.\nFirst, lets define a new type to store the DbContext initialization Action:\n1 2 3 4 5 6 7  public class DynamicContextInitOptions\u0026lt;TContext\u0026gt; where TContext : DbContext { Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction { get; set; } Action\u0026lt;IServiceProvider, DbContextOptionsBuilder\u0026gt; optionsActionDependencyInjection { get; set; } }   When initializing a DbContext, one of the two Actions could be used. The class can cater for both, but only one of the two will be used at any one time.\nNext, when a DbContext is added to the container (via the AddDynamicContext extension method) we\u0026rsquo;ll record how the original DbContext was initialized, and add the initialization Action to the DI container as well. A private helper method AddDynamicContent is used to configure the DI container based on the Action passed in: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  public static IServiceCollection AddDynamicContext\u0026lt;TContext\u0026gt;( this IServiceCollection serviceCollection, Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction = null, ServiceLifetime contextLifetime = ServiceLifetime.Scoped, ServiceLifetime optionsLifetime = ServiceLifetime.Scoped) where TContext : DbContext { AddDynamicContent\u0026lt;TContext\u0026gt;(serviceCollection, optionsAction); return serviceCollection.AddDbContext\u0026lt;TContext, TContext\u0026gt;( optionsAction, contextLifetime, optionsLifetime ); } private static void AddDynamicContent\u0026lt;TContext\u0026gt;( IServiceCollection serviceCollection, Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction = null, Action\u0026lt;IServiceProvider, DbContextOptionsBuilder\u0026gt; optionsActionDependencyInjection = null) where TContext : DbContext { serviceCollection.AddScoped\u0026lt;DynamicContext\u0026lt;TContext\u0026gt;\u0026gt;(); // If no action, then it would need to be added manually if(optionsAction == null \u0026amp;\u0026amp; optionsActionDependencyInjection == null) { return; } // Create an options instance with the Action populated.  // One of the two will always be null var options = new DynamicContextInitOptions\u0026lt;TContext\u0026gt; { optionsAction = optionsAction, optionsActionDependencyInjection = optionsActionDependencyInjection }; // add the type to the DI container serviceCollection.AddSingleton(typeof(options); }  \nFor a specific DbContext, we now know how it was initialized. So if we inject DynamicContextInitOptions\u0026lt;TContext\u0026gt; into DynamicContext and then into RuntimeContext, it can be used to initialized dynamically.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  internal class RuntimeContext\u0026lt;T\u0026gt; : DbContext where T : class { private readonly DynamicContextInitOptions\u0026lt;DbContext\u0026gt; _contextInitAction; private readonly IServiceProvider _serviceProvider; public RuntimeContext( DynamicContextInitOptions\u0026lt;DbContext\u0026gt; contextInitAction, IServiceProvider serviceProvider) { _contextInitAction = contextInitAction; _serviceProvider = serviceProvider; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { // init the context based on how the initial TContext was initially initialized if (_contextInitAction.optionsAction != null) { _contextInitAction.optionsAction.Invoke(optionsBuilder); } else { _contextInitAction .optionsActionDependencyInjection .Invoke(_serviceProvider, optionsBuilder); } base.OnConfiguring(optionsBuilder); } // Class continues... }   We can now inject a DynamicContext into a relevant constructor, have access to dynamic functionality as well as the underlying original DbContext, and we can dynamically initialized the dynamic context based on how the underlying original context was initialized.\nDynamic configuration taken care of!\n DynamicContext wrapper Next we\u0026rsquo;ll add a few methods to the wrapper DynamicContext to provide access to the internal RuntimeContext, as well as making using the reference type wrapper, SimpleType\u0026lt;T\u0026gt; easier.\n  First a method to add a DbSet dynamically based on the generic entity TEntity: 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public DbSet\u0026lt;TEntity\u0026gt; Set\u0026lt;TEntity\u0026gt;() where TEntity : class { // if the type is on the original context,  // then don\u0026#39;t initialize the dynamic context if (_originalContext.Model.FindEntityType(typeof(TEntity)) != null) { return _originalContext.Set\u0026lt;TEntity\u0026gt;(); } var runtimeContext = new RuntimeContext\u0026lt;TEntity\u0026gt;( _runtimeInitAction, _serviceProvider); return runtimeContext.Set\u0026lt;TEntity\u0026gt;(); }  \nTo invoke this method: 1 2 3  var blogs = dynamicContext.Set\u0026lt;BlogUrl\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList()  \n  Next, a method to add DbSet dynamically based on an anonymous object: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public DbSet\u0026lt;TEntity\u0026gt; Set\u0026lt;TEntity\u0026gt;(TEntity example) where TEntity : class { _ = example; // if the type is on the original context,  // then don\u0026#39;t initialize the dynamic context if (_originalContext.Model.FindEntityType(typeof(TEntity)) != null) { return _originalContext.Set\u0026lt;TEntity\u0026gt;(); } var runtimeContext = new RuntimeContext\u0026lt;TEntity\u0026gt;( _runtimeInitAction, _serviceProvider); return runtimeContext.Set\u0026lt;TEntity\u0026gt;(); }  \nTo invoke this method: 1 2 3 4  var anonBlogUrl = new { BlogId = 0, Url = \u0026#34;\u0026#34; }; var blogs = dynamicContext.Set(anonBlogUrl) .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList();  \n  Next, a method to wrap the explicit SimpleType\u0026lt;T\u0026gt; usage. With this method SimpleType\u0026lt;T\u0026gt; does not need to be used explicitly: 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public DbSet\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt; ValueSet\u0026lt;TEntity\u0026gt;() where TEntity : struct { // as the constraint is on struct, we have this additional check  // just to make sure its a struct of a relevant type  // (int, long, float, bool etc) if(!IsValidType(typeof(TEntity))) { throw new InvalidOperationException( $\u0026#34;Type \u0026#39;{typeof(TEntity).Name}\u0026#39; is not supported\u0026#34;); } var runtimeContext = GetInternalRuntimeContext(new SimpleType\u0026lt;TEntity\u0026gt;()); return runtimeContext.Set\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt;(); }  \nTo invoke this method: 1 2 3  var blogIds = dynamicContext.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList();  \n  Lastly, as string is not a struct, it has to be handled separately: 1 2 3 4 5 6 7  public DbSet\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt; StringSet\u0026lt;TEntity\u0026gt;() where TEntity : IEnumerable\u0026lt;char\u0026gt;, IEnumerable, ICloneable, IComparable, IComparable\u0026lt;string\u0026gt;, IConvertible, IEquatable\u0026lt;string\u0026gt; { var runtimeContext = GetInternalRuntimeContext(new SimpleType\u0026lt;TEntity\u0026gt;()); return runtimeContext.Set\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt;(); }  \nTo invoke this method: 1 2 3  var urls = context.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList();  \n  We can have user friendly methods which are similar to the DbContext Set methods, and which wrap some of the annoyance of having to use SimpleType\u0026lt;T\u0026gt; explicitly.\nSimple value usage taken care of!\n Value column The last issue to resolve is the fact that the Set\u0026lt;\u0026gt; methods for simple types (struct and string) return a DbSet of SimpleType object and not the simple type value itself.\nOne option, is to explicitly select the value out the IQueryable, as seen in line 4 below: 1 2 3 4 5  var urls = context.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking() .Select(x =\u0026gt; x.Value) .ToList();  \nThe other option is to add some extension methods to easily unpack the SimpleType\u0026lt;T\u0026gt; into the T: 1 2 3 4 5 6 7 8 9 10 11 12  public static IQueryable\u0026lt;TEntity\u0026gt; ToSimple\u0026lt;TEntity\u0026gt;( this IQueryable\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt; query) where TEntity : struct, IComparable, IFormattable, IComparable\u0026lt;TEntity\u0026gt;, IEquatable\u0026lt;TEntity\u0026gt; { return query.Select(entity =\u0026gt; entity.Value).AsQueryable(); } public static IQueryable\u0026lt;string\u0026gt; ToSimple(this IQueryable\u0026lt;SimpleType\u0026lt;string\u0026gt;\u0026gt; query) { return query.Select(entity =\u0026gt; entity.Value).AsQueryable(); }  \nTo invoke this method: 1 2 3 4 5  var blogIds = context.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking() .ToSimple() .ToList();  \n     The solution still requires that the SQL command have a column returned with the name of \u0026lsquo;Value\u0026rsquo;. With some additional effort, this constraint could be resolved , but this is outside the scope of this post.\n   Value column partially taken care of!\n Nuget Package All the above functionality has been packed into a NuGet package which is ready to use, and is available here.\nFull source code is also available on GitHub here\n Performance benchmarks Some performance benchmarks of using the DynamicContext vs DbContext directly and projecting the values out (using .NET 6, EF Core 6 and Sqlite)\nThe first set of results benchmark retrieving a list of ids and urls from a database of 500 records, then 100 000 records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // DirectDbSet var blogs = context.Blog.AsNoTracking().ToList(); // GenericDbSet var blogs1 = context.Set\u0026lt;Blog\u0026gt;().AsNoTracking().ToList(); // GenericDbSetRaw var blogs2 = context.Set\u0026lt;Blog\u0026gt;() .FromSqlRaw(\u0026#34;SELECT * FROM Blog\u0026#34;).AsNoTracking().ToList(); // GenericDbSetProj var blogs3 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // GenericDbSetRawProj var blogs4 = context.Set\u0026lt;Blog\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id, Url FROM Blog\u0026#34;) .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // DynamicDbSet var blogs5 = dynamicContext.Set\u0026lt;BlogUrl\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList(); // DynamicDbSetAnon var anonBlogUrl = new { BlogId = 0, Url = \u0026#34;\u0026#34; }; var blogs6 = dynamicContext.Set(anonBlogUrl) .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList();  \n500 records:\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Allocated     DirectDbSet 1,049.3 us 10.66 us 9.97 us 1.00 76.1719 25.3906 477 KB   GenericDbSet 1,054.4 us 12.71 us 11.89 us 1.00 76.1719 25.3906 477 KB   GenericDbSetRaw 1,070.9 us 18.19 us 16.12 us 1.02 78.1250 25.3906 481 KB   GenericDbSetProj 638.2 us 9.48 us 8.87 us 0.61 47.8516 12.6953 296 KB   GenericDbSetRawProj 661.1 us 3.98 us 3.53 us 0.63 48.8281 14.6484 302 KB   DynamicDbSet 696.8 us 3.22 us 2.69 us 0.66 54.6875 14.6484 338 KB   DynamicDbSetAnon 605.2 us 5.51 us 5.15 us 0.58 45.8984 13.6719 287 KB    100 000 records (Gen 0, 1 and 2 decimals truncated for space reasons):\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Gen 2 Allocated     DirectDbSet 268.5 ms 2.02 ms 1.89 ms 1.00 15000.00 5000.00 2000.00 81 MB   GenericDbSet 268.6 ms 2.47 ms 2.19 ms 1.00 15000.00 5000.00 2000.00 81 MB   GenericDbSetRaw 267.9 ms 3.11 ms 2.91 ms 1.00 15000.00 5000.00 2000.00 81 MB   GenericDbSetProj 143.8 ms 2.60 ms 3.09 ms 0.54 8250.00 3000.00 1000.00 46 MB   GenericDbSetRawProj 140.8 ms 2.76 ms 3.06 ms 0.52 8250.00 3000.00 1000.00 46 MB   DynamicDbSet 143.9 ms 2.11 ms 1.97 ms 0.54 8250.00 3000.00 1000.00 46 MB   DynamicDbSetAnon 118.1 ms 2.28 ms 2.02 ms 0.44 6400.00 2400.00 1000.00 36 MB    As expected, projecting the required fields out, is faster and requires less memory than retrieving all the data. Using the DynamicContext is comparable to projecting the specific values out - the overhead of dynamically creating the DynamicContext is negligible.\n The next set of results benchmark retrieving a list of simple types (Guid) from a database of 500 records, then 100 000 records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // DirectDbSet var blogIds = context.Set\u0026lt;Blog\u0026gt;() .AsNoTracking().Select(x =\u0026gt; x.Id).ToList(); // ValueSetSelect var blogIds1 = dynamicContext.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList(); // ValueSetToSimple var blogIds2 = dynamicContext.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().ToSimple().ToList(); // DirectDbSetString var urls = context.Set\u0026lt;Blog\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Url).ToList(); // StringSetSelect var urls1 = dynamicContext.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList(); // StringSetToSimple var urls2 = dynamicContext.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking().ToSimple().ToList();  \n500 records:\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Allocated     DirectDbSet 864.1 us 38.04 us 111.55 us 1.00 - - 226 KB   ValueSetSelect 439.1 us 8.32 us 14.12 us 0.52 37.1094 8.7891 233 KB   ValueSetToSimple 435.7 us 7.98 us 8.20 us 0.51 37.1094 6.8359 232 KB   DirectDbSetString 610.5 us 12.65 us 14.06 us 0.71 38.0859 1.9531 233 KB   StringSetSelect 437.9 us 8.53 us 11.67 us 0.50 39.0625 10.7422 240 KB   StringSetToSimple 439.3 us 8.56 us 12.28 us 0.51 39.0625 9.7656 240 KB    100 000 records (Gen 0, 1 and 2 decimals truncated for space reasons):\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Gen 2 Allocated     DirectDbSet 58.67 ms 1.167 ms 2.276 ms 1.00 4000.00 1000.00 1000.00 32 MB   ValueSetSelect 54.48 ms 1.058 ms 1.132 ms 0.91 5500.00 1100.00 1000.00 32 MB   ValueSetToSimple 51.66 ms 0.399 ms 0.354 ms 0.86 5444.44 1111.11 1000.00 32 MB   DirectDbSetString 81.04 ms 1.153 ms 0.963 ms 1.00 6000.00 2000.00 1000.00 33 MB   StringSetSelect 92.20 ms 1.359 ms 1.271 ms 1.14 5666.67 2000.00 833.33 33 MB   StringSetToSimple 92.26 ms 1.789 ms 1.915 ms 1.14 5666.67 2000.00 833.33 33 MB    For the non-string values, using DynamicContext is faster, while using roughly the same memory, especially with more records. For string values DynamicContext is slower - but with the tradeoff of it being more dynamic.\n Closing The post outlines solutions to be able to:\n Retrieve data into an entity (or collection of entities) without a DbSet, using raw SQL Retrieve data into an entity or collection of entities) based on an anonymous object, using raw SQL Retrieve data into a simple type without having to define a reference type to use as a DbSet  The performance of the library is either faster or comparable to using a DbContext, but as always, test and benchmark and make an informed decision in your specific use case.\nFull source code available on Github and fully functionality package available on NuGet.\n","date":"2021-12-11T03:00:00+02:00","permalink":"https://always-developing.github.io/p/11-2020-dynamic-context/","title":"Dynamic Context (for Entity Framework Core)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks (this post)\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nTips and tricks This post contains a list of tips and tricks, work-around\u0026rsquo;s and other bits of (what I find) useful information to aid in developing analyzers.\n Analyzer tips and tricks Compatibility If an analyzer is created in Visual Studio 2019 using the Analyzer with Code Fix project - it will not be initially compatible with Visual Stdio 2022 (or visa versa).\nThe actual analyzer and code fix code itself is compatible (as its .NET Standard 2.0), however the VSIX project is not compatible\n Default Microsoft.VSSDK.BuildTools reference \nTo have the VSIX project work in Visual Studio 2022, the Microsoft.VSSDK.BuildTools reference needs to be updated to version 17. However doing so will mean it will no longer be supported in Visual Studio 2019.\nTo have the analyzer work in both Visual Studio 2019 and Visual Studio 2022, two VSIX projects need to be created in the solution. One will be for Visual Studio 2019 and have a Microsoft.VSSDK.BuildTools reference of version 15 or 16, and the other for Visual Studio 2022 with a Microsoft.VSSDK.BuildTools reference of 17.\n Visual Studio support \n Syntax tree Sometimes when using the Syntax Visualizer, detailed in the section Writing an analyzer - interrogate the syntax tree, the tree in the Syntax Visualizer windows stops refreshing when selecting items in the code, and will appear blank.\nTo force a refresh of the window, make a small code change - for example, add a remove a semi-colon in code. This will force the window to refresh and the syntax tree will appear and refresh correctly (until the next time it stops working).\n Additional files While an analyzer can inspect non-code files (such as the appsettings.json in the sample), these \u0026ldquo;additional files\u0026rdquo; are not included as part of the Roslyn checks by default. A file has to specifically be marked as an additional file for Roslyn to be able to work with it.\nThis is done by specifying the files Build Action to be C# analyzer additional file on the file\u0026rsquo;s Properties window in Visual Studio.\n Appsettings.json build action \nWhen an analyzer is dependent on the additional file being present, as is the case in the sample analyzer, then a diagnostic can be raised if the additional file cannot be found.\nIn the below example, the ADEF002 diagnostic is raised if the appsettings.json hasn\u0026rsquo;t been included as an additional file - if it doesn\u0026rsquo;t have a build action of C# analyzer additional file.\n1 2 3 4 5 6 7 8 9 10  // if there is no file to query, then report a diagnostic if (context.Options.AdditionalFiles == null || !context.Options.AdditionalFiles.Any(x =\u0026gt; x.Path .EndsWith(\u0026#34;appsettings.json\u0026#34;, StringComparison.OrdinalIgnoreCase))) { var diagnostic002 = Diagnostic.Create(rule002, Location.None); context.ReportDiagnostic(diagnostic002); return; }    Code fix tips and tricks Modify non-code While it is possible to have an analyzer inspect non-code files (such as the appsettings.json in the sample), it is not possible to have the code fix modify these files. The code fix is only able to modify the syntax tree, which a non-code file will obviously not have.\nA solution to this is the demonstrated in the sample analyzer. Diagnostic ADEF003 ensures that the connection string name specified in code exists in the appsettings.json file. As an analyzer can inspect the json file, it is successfully able to trigger the diagnostic, however the associated code fix is unable to modify the json.\nInstead, a comment snippet is inserted above the offending code block, with the correct json, and a message informing the developer what to do with it.\nIn the below example, no connection string called SampleDatabase was present in the appsettings.json, so a diagnostic was triggered.\nBefore code fix has been applied: 1 2 3 4  .ConfigureServices((context, services) =\u0026gt; services .AddDbContext\u0026lt;SampleContext\u0026gt;(x =\u0026gt; x .UseSqlite(context.Configuration.GetConnectionString(\u0026#34;SampleDatabase\u0026#34;))) ).Build();  \nAfter code fix has been applied: 1 2 3 4 5 6 7 8 9 10 11  .ConfigureServices((context, services) =\u0026gt; services /* Ensure the below JSON snippet exists in appsettings.json. { \u0026#34;ConnectionStrings\u0026#34;: { \u0026#34;SampleDatabase\u0026#34;: \u0026#34;Data Source=LocalDatabase.db\u0026#34; } } */ .AddDbContext\u0026lt;SampleContext\u0026gt;(x =\u0026gt; x .UseSqlite(context.Configuration.GetConnectionString(\u0026#34;SampleDatabase\u0026#34;))) ).Build();  \nThis code fix however does not fully resolve the diagnostic. Only once the json snippet has been manually copied in the appsettings.json file by the developer will the analyzer stop reporting the diagnostic.\n Unit test tips and tricks VSIX debugging Using the VSIX project, which is part of the analyzer template, is a critical tool to test and debug an analyzer, and see how it performs in an Visual Studio instance (vs running units tests to ensure the functionality is correct). However occasionally when running the VSIX project, the updated version of the analyzer does get installed/loaded into the debugging Visual Studio instance.\nPerforming one of these two options usually resolves the issue:\n  Explicitly build/rebuild each project in the analyzer solution before running the analyzer VSIX project.\n  Delete the cache for the debug Visual Studio instance. The cache is stored in the user folder: C:\\Users\\username\\AppData\\Local\\Microsoft\\VisualStudio\\xxxxRoslyn.\nDeleting this cache will removing any settings, cache for the debug Visual Studio instance, and the next time its opened it will be as if it was the first time, and the updated version of the extension will be installed for the \u0026ldquo;first time\u0026rdquo;.\n   Series Finale The series of posts have hopefully given enough base information to give a basic understand of what an analyzer and code fix are, what the various components are and how they fit together, and how they can successfully be tested using a number of methods.\nThe source code for full working analyzer and code fix, as well as the sample application is all available on Github.\n","date":"2021-11-28T05:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-extra/","title":"Roslyn Analyzer - tips and tricks (Part 5)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix (this post)\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nAnalyzer unit test introduction The previous posts in the series detail how to write an analyzer and code fix.\nThis post details writing unit tests to help ensure the stability of the code, but also aid in the development process by providing a quick and easy way to debug and test the analyzer and code fix.\n Why write unit tests? Analyzers are not simple to test - to \u0026ldquo;run\u0026rdquo; an analyzer, a new instance of Visual Studio starts up with the analyzer installed as an extension. An application (which has the code needed to test the analyzer) then needs to be opened to cause the analyzer trigger.\nWhile this definitely has a place when testing (hence the suggestion of creating a sample application for the analyzer), this process to often be inconsistent, with the updated analyzer not always being installed in the new instance of Visual Studio, or the breakpoints in the analyzer not being hit.\nUnit tests provide a convenient and comparatively quick way to debug and iterate while coding the analyzer and code fix.\nLuckily, writing unit tests are fairly straight forward. In addition a test framework is available for the testing of analyzers and code fixes.\n Default unit tests Wrapper classes As part of the analyzer template, a unit test project is automatically created.\nThis template has:\n A sample analyzer test, using the a VerifyCS.VerifyAnalyzerAsync method A sample verify code fix test, using a VerifyCS.VerifyCodeFixAsync method  The VerifyCS class is an auto-generated class, which wraps a lot of the complexity of the underlying testing framework classes - while this is great when first working with analyzers and is easy to use for simple use cases, more complex use cases require more configuration and its generally easier to just use the underlying wrapped classes directly.\nUsing the VerifyCS class to test an analyzer is straightforward though:\n Define a block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Call VerifyCS.VerifyAnalyzerAsync()  1 2 3 4 5 6 7 8 9  //No diagnostics expected to show up [TestMethod] public async Task TestMethod1() { var test = @\u0026#34;\u0026#34;; // No code, so no diagnostic will be triggered await VerifyCS.VerifyAnalyzerAsync(test); }   Using the VerifyCS class to test a code fix:\n Define a initial state block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Define a final state block of code as a string (what the code would look like after the code fix has been applied) Call VerifyCS.VerifyCodeFixAsync()  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  //Diagnostic and CodeFix both triggered and checked for [TestMethod] public async Task TestMethod2() { // define the initial code block var test = @\u0026#34; using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using System.Diagnostics; namespace ConsoleApplication1 { class {|#0:TypeName|} { } }\u0026#34;; // define the final state code block var fixtest = @\u0026#34; using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using System.Diagnostics; namespace ConsoleApplication1 { class TYPENAME { } }\u0026#34;; // Expected diagnostics to be triggered var expected = VerifyCS.Diagnostic(\u0026#34;Analyzer1\u0026#34;) .WithLocation(0).WithArguments(\u0026#34;TypeName\u0026#34;); // Verify the diagnostic will be triggered,  // and that the code fix applies successfully await VerifyCS.VerifyCodeFixAsync(test, expected, fixtest); }    Complex use cases There are a few use cases where I\u0026rsquo;ve found NOT using VerifyCS easier (although it is still possible to use it):\n If the code block requires external dependencies to compile (such as a NuGet package) If the code block is using some of the .NET 6 features (such as the minimal startup with the implicit main method) If the analyzer requires additional files, such as an appsettings.json file. If the build config (or any preprocessor symbol) makes a different to the analyzer  For these reasons, I generally do not use VerifyCS, but use the underlying framework classes directly instead.\n Enhanced unit tests The steps for using the framework classes directly (CSharpAnalyzerTest) are similar to using the wrapper class:\nUsing the CSharpAnalyzerTest class to test an analyzer:\n Define a block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Define any additional configuration Call RunAsync()  To test a code fix using CSharpCodeFixTest:\n Define a initial state block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Define a final state block of code as a string (what the code would look like after the code fix has been applied) Define any additional configuration for both the initial and final state Call RunAsync()  Lets go through these steps in details in the next sections.\n Defining the code Analyzer test code Although the analyzer and code fix test use different test classes, the setup is very similar.\nWith the configuration for an analyzer, the TestState is set - the sourceCode variable is a string with C# code as text. 1 2 3 4 5 6 7  var analyzerTest = new CSharpAnalyzerTest\u0026lt;DevOnlyMigrateAnalyzer, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode } } };  \nCode fix test code With the configuration for a code fix, the TestState is set, as well as the source code for the expected FinalState. The final state is the expected code after the code fix has been applied. Again, both sourceCode and fixedCode are C# code as text. 1 2 3 4 5 6 7 8 9 10 11 12  var analyzerFix = new CSharpCodeFixTest\u0026lt;DevOnlyMigrateAnalyzer, DevOnlyMigrateCodeFixProvider, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode } }, FixedState = { Sources = { fixCode } } };  \n Defining the diagnostics Next up is to define the diagnostics we expect the code to trigger.\nAnalyzer diagnostics With an analyzer test, the diagnostic id, severity and location of the expected diagnostics is specified: 1 2 3 4 5  analyzerTest.ExpectedDiagnostics.Add( new DiagnosticResult( \u0026#34;ADEF001\u0026#34;, Microsoft.CodeAnalysis.DiagnosticSeverity.Warning ).WithLocation(18, 27));  \nCode fix diagnostics With a code fix, if the expectation is that there will still be diagnostics after the code fix has been applied, the ExpectedDiagnostics is set on the FixedState: 1 2 3 4 5  analyzerFix.FixedState.ExpectedDiagnostics.Add( new DiagnosticResult( \u0026#34;ADEF001\u0026#34;, Microsoft.CodeAnalysis.DiagnosticSeverity.Warning ).WithLocation(18, 27));  \nNo or multiple expected diagnostics can be specified.\n Additional configuration .NET6.0 support If the sourceCode (a string representation of C# code) contains any features specific to .NET6.0 (such as the no longer required Main method), the setup below needs to be done.\nThis specifies to the testing framework to include the additional package as part of the code when executing the analyzer: 1 2 3 4 5 6 7 8 9 10 11 12 13  var analyzerTest = new CSharpAnalyzerTest\u0026lt;ConfigConnectionStringAnalyzer, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode }, ReferenceAssemblies = new ReferenceAssemblies( \u0026#34;net6.0\u0026#34;, new PackageIdentity( \u0026#34;Microsoft.NETCore.App.Ref\u0026#34;, \u0026#34;6.0.0\u0026#34;), Path.Combine(\u0026#34;ref\u0026#34;, \u0026#34;net6.0\u0026#34;)) } };  \nFor a code fix test, the same needs to be applied to the FinalState if it makes use of the same .NET6.0 specific functionality.\nNuget Packages Sometimes additional packages are required for the sourceCode to successfully compile. In the sample code, for example, the EntityFramework Core references.\nThe required package names and version are specified and then added to the TestState. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // include any nuget packages to reduce the number of errors var packages = new[] { new PackageIdentity(\u0026#34;Microsoft.Extensions.Hosting\u0026#34;, \u0026#34;6.0.0\u0026#34;), new PackageIdentity(\u0026#34;Microsoft.Extensions.Configuration\u0026#34;, \u0026#34;6.0.0\u0026#34;), new PackageIdentity(\u0026#34;Microsoft.EntityFrameworkCore\u0026#34;, \u0026#34;6.0.0\u0026#34;), new PackageIdentity(\u0026#34;Microsoft.EntityFrameworkCore.Sqlite\u0026#34;, \u0026#34;6.0.0\u0026#34;) } .ToImmutableArray(); var analyzerTest = new CSharpAnalyzerTest\u0026lt;DevOnlyMigrateAnalyzer, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode }, ReferenceAssemblies = new ReferenceAssemblies( \u0026#34;net6.0\u0026#34;, new PackageIdentity( \u0026#34;Microsoft.NETCore.App.Ref\u0026#34;, \u0026#34;6.0.0\u0026#34;), Path.Combine(\u0026#34;ref\u0026#34;, \u0026#34;net6.0\u0026#34;)) .AddPackages(packages) } };  \n     Adding the packages to the tests is NOT required - if not added, the code simply wont compile, with the error: The type or namespace name \u0026lsquo;XXX\u0026rsquo; does not exist in the namespace \u0026hellip;\nThese errors could be added to the ExpectedDiagnostics collection and as the test now expects these to occur, the test will pass.\nHowever the easier and more complete solution, is to rather just add the required packages instead of trying to cater for diagnostics not related to the analyzer or code fix being tested.\n   Additional files Sometimes an analyzer will require additional files to successfully perform its function - such as checking the contents of the appsettings.json. To successfully be able to test this, additional files (names, and content) can be configured as part of the test.\nThis is done on the TestState or FixedState:\nIn the below sample, an additional file called appsettings.json, with empty json contents, is added to the test state.\n1 2  analyzerTest.TestState .AdditionalFiles.Add((\u0026#34;appsettings.json\u0026#34;, \u0026#34;{}\u0026#34;));   Build configuration In some use cases, such as one in the sample, the build configuration of the project makes a difference to how the analyzer performs.\nTo specify the build configuration, or any preprocessor symbols, the following is used:\n1 2 3 4 5 6  analyzerTest.SolutionTransforms.Add((s, p) =\u0026gt; { return s.WithProjectParseOptions(p, new CSharpParseOptions() .WithPreprocessorSymbols(\u0026#34;DEBUG\u0026#34;)); });    Next steps: Tips and tricks The next and final part in the series will provider some collection of tips and tricks collected while working with analyzers.\nUseful links Roslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-27T04:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-test/","title":"Roslyn Analyzer - testing an analyzer and code fix (Part 4)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix (this post)\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nCode fix introduction As detailed in the previous post in the series, now that there is a working analyzer which accurately reports diagnostic information to Roslyn, the next step is to write the code fix to resolve the diagnostic.\nNot all analyzers will have a code fix - the resolution might be out of the scope of Roslyn to resolve, in which case the diagnostic should info the developer how to resolve the report.\n Coding the code fix Code fix setup First step is to configure the code fix so it applies to a specific diagnostic (or multiple diagnostics)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [ExportCodeFixProvider(LanguageNames.CSharp, Name = nameof(DevOnlyMigrateCodeFixProvider)), Shared] public class DevOnlyMigrateCodeFixProvider : CodeFixProvider { public sealed override ImmutableArray\u0026lt;string\u0026gt; FixableDiagnosticIds { get { return ImmutableArray.Create(DevOnlyMigrateAnalyzer.DiagnosticId); } } public sealed override FixAllProvider GetFixAllProvider() { return WellKnownFixAllProviders.BatchFixer; } . . . }    Line 3: The class must inherit from CodeFixProvider Line 5-8: The overridden FixableDiagnosticIds returns a list of the diagnostic ids this code fix will resolve   Register the code fix The next step is to register the code fix with Roslyn - this is done by overriding the RegisterCodeFixesAsync method.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public sealed override async Task RegisterCodeFixesAsync(CodeFixContext context) { var root = await context.Document.GetSyntaxRootAsync(context.CancellationToken) .ConfigureAwait(false); var diagnostic = context.Diagnostics.First(); var diagnosticSpan = diagnostic.Location.SourceSpan; var declaration = root.FindToken(diagnosticSpan.Start).Parent. AncestorsAndSelf().OfType\u0026lt;InvocationExpressionSyntax\u0026gt;().First(); // Register a code action that will invoke the fix. context.RegisterCodeFix( CodeAction.Create( equivalenceKey: DevOnlyMigrateAnalyzer.DiagnosticId, title: \u0026#34;Surround with correct #if directive\u0026#34;, createChangedDocument: c =\u0026gt; InsertIfDirectiveAsync(context.Document, declaration, c)), diagnostic); }    Lines 3-4: Gets the entire syntax tree from the context Lines 6-7: Get the first diagnostic reported, and get its Span (the location within the root syntax tree) Lines 9-10: Find the syntax node at the location of the diagnostic Lines 13-19: Register the code fix:  Line 15: Register the specific diagnostic id Line 16: The text which appears in the quick action menu Lines 17-19: The method to call which will handle altering the document     Alter the syntax tree A code fix consists of taking the original document (which contains the full context tree), modifying various nodes in the tree to reflect how the fixed code should look, and then returning the updated document.\nFor the sample analyzer, this is done in InsertIfDirectiveAsync, the method registered in the previous step:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  private async Task\u0026lt;Document\u0026gt; InsertIfDirectiveAsync(Document document, InvocationExpressionSyntax invocationExpr, CancellationToken cancellationToken) { var memberAccessExpr = invocationExpr.Expression as MemberAccessExpressionSyntax; var originalRoot = await document.GetSyntaxRootAsync(cancellationToken); var statement = GetStatement(invocationExpr); // get the closest If directive var closestIfDirective = CodeAnalysisHelper.GetClosestIfDirective(memberAccessExpr, originalRoot); // if there was one if (closestIfDirective != null) { // work out the replacement directive and replace  var replacementIfDirective = SyntaxFactory.IfDirectiveTrivia( SyntaxFactory.ParseExpression($\u0026#34; DEBUG{Environment.NewLine}\u0026#34;), true, true, true); var replacementIfDirectiveList = SyntaxFactory.TriviaList(new SyntaxTrivia[] { SyntaxFactory.Trivia(replacementIfDirective) }); var ifDirectiveNode = statement.FindNode(closestIfDirective.Value.Span); if(ifDirectiveNode != null \u0026amp;\u0026amp; ifDirectiveNode.HasLeadingTrivia) { var newIfDirectiveNode = ifDirectiveNode .WithLeadingTrivia(replacementIfDirectiveList); var newReplacementStatement = statement .ReplaceNode(ifDirectiveNode, newIfDirectiveNode); var newReplacementRoot = originalRoot .ReplaceNode(statement, newReplacementStatement); return document.WithSyntaxRoot(newReplacementRoot); } return document; } // this branch is if there is no directive var statementWithDirective = InsertNewIfDirective(statement); var newRootWithEndDirective = originalRoot .ReplaceNode(statement, statementWithDirective); return document.WithSyntaxRoot(newRootWithEndDirective); }    Lines 1-2: The parameters to the method are the full Document, as well as the specific syntax which triggered the diagnostic Line 6: A helper method is called to get the code statement which invocationExpr (Migrate method call) is part of.\nThe statement is the larger code block containing the invocationExpr : _context?.Database.Migrate() Lines 9-10: A helper method is called to get the closest #if directive which occurs before the invocationExpr location Lines 13-39: This handles replacing the existing #if directive with a version which has the correct condition  Lines 16-23: Builds the replacement trivia: #if DEBUG Line 25: Find the existing trivia in the statement node Lines 29-34: Replaces the text in the #if directive, then replaced the directive in the statement with the new directive, then replaced the statement in the root with the new statement Lines 36: Return the document with the new syntax root   Lines 43-47: This handles inserting a new #if directive into the statement (InsertNewIfDirective method), and then returns the document with the newly inserted directive.   Applying the code fix Nothing more is required - Visual Studio and Roslyn will automatically call the code fix method to:\n Give a preview of the fix being applied when the cursor is held over the quick action menu item. Apply the fix when the quick action menu item is clicked.   The code fix preview \n Next steps: Testing the analyzer and code fix Next up, part 4 in the series will detail how to test the custom analyzer and associated code fix. This includes information on using the analyzer unit tests infrastructure to assist with development, as well as using the VSIX project.\nUseful links Roslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-26T03:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-code-fix/","title":"Roslyn Analyzer - writing the code fix (Part 3)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer (this post)\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nAnalyzer introduction To recap from the previous post in the series, an analyzer is a piece of code which inspects code (C# or Visual Basic) during design and compile time, and based on the results of the inspection, can trigger a diagnostic as an Error, Warning or as Information.\nThis post will detail the various parts of the analyzer, how they fit together, and then explore creating a custom analyzer.\n     While the samples used in these posts and in the associated Github repository are working and practical, the code is NOT optimized, and also does not cater for all use cases scenarios and edge cases.\nThe code should be used as a guide for writing a custom analyzer and code fix and not as-is for production use.\n    Analyzer solution Creating an analyzer project Creating the initial analyzer project is very simple - Visual Studio has a template for it!\nWhen creating a new project in Visual Studio, search for analyzer and select the C# Analyzer with Code Fix (.NET Standard) template.\n C# Analyzer with Code Fix (.NET Standard) project \nIf the project doesn\u0026rsquo;t appear in the list, the .NET Compiler Platform SDK workload is most likely not installed. Modify the Visual Studio installation to confirm and install if required.\n .NET Compiler Platform SDK selection \n     The various analyzer projects will be created with the target framework of .NET Standard 2.0 for the analyzer specific projects, and .NET Framework 4.7.2 for the VSIX project.\nThese should remain as is - as Visual Studio was written using .NET Framework, extensions are required to target .NET Standard 2.0 and currently cannot target any later framework.\n    Structure of the solution The default analyzer template will create 5 projects as part of the solution (in the order as they appear in the screenshot below):\n A project which contains the analyzer code A project which contains the code fix code A project used to create a NuGet package for the analyzer A test project containing unit test (which is also invaluable for debugging while developing) A VSIX project which creates the Visual Studio extension (also invaluable for testing while developing)   Structure of an analyzer solution (sample folder added manually) \n The analyzer A sample application Before starting to code the analyzer, a very strong suggestion is to create a small sample application which contains the scenario to trigger the analyzer. This will be very useful when testing, as well as crucial when working out the syntax tree of the code (more on this below).\nThis sample project does not have to be at all complicated - the sample project (available on Github) just creates a connection to a Sqlite database, and applies a database migration. No other logic.\nPersonally I prefer to add the sample to my analyzer solution (useful when using the Syntax Visualizer), but then also create a separate solution which just contains just the sample project (useful when testing the analyzer as an extension).\nSee part 1 for a more in depth breakdown of the the scenarios the custom analyzers are reporting on.\n Coding the analyzer Analyzer structure An analyzer class inherits from the DiagnosticAnalyzer class, and can be broken down into four parts:\n The diagnostic setup: Configure the diagnostic information which appear when the analyzer reports feedback back to the developer Register the action: An Action (a method) is registered, along with a specific syntax kind (e.g. MethodInvocations or NamedTypes). The action/method will then be invoked whenever Roslyn encounters a syntax of that kind while running analysis. Interrogate the syntax tree: Once Roslyn calls the action/method setup in step 2, the syntax tree/code structure is interrogated to determine if the code is relevant for the analyzer and does a diagnostic need to be trigger Trigger the diagnostic result: The final step is to trigger a diagnostic with Roslyn so the results can be reported back   Diagnostic setup The first step is to setup the diagnostic information, the information which is reported back.\nThe template makes use of a resx file to allow for localization, however in the sample code on Github as well as in the example below, the resx has been removed and the messages put directly in code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public const string DiagnosticId = \u0026#34;ADEF001\u0026#34;; private static readonly string Title = \u0026#34;Release build auto-migration\u0026#34;; private static readonly string MessageFormat = \u0026#34;It is recommended to only \u0026#34; + \u0026#34;run auto-migrations in development environments\u0026#34;; private static readonly string Description = \u0026#34;Best practice is to only run \u0026#34;+ \u0026#34;auto-migrations in development environments and not \u0026#34; + \u0026#34;in test or production environments - this should be done by a CI/CD pipeline.\u0026#34;; private const string Category = \u0026#34;Usage\u0026#34;; private static readonly DiagnosticDescriptor rule001 = new DiagnosticDescriptor(DiagnosticId, Title, MessageFormat, Category, DiagnosticSeverity.Warning, isEnabledByDefault: true, description: Description); public override ImmutableArray\u0026lt;DiagnosticDescriptor\u0026gt; SupportedDiagnostics { get { return ImmutableArray.Create(rule001); } }    Line 1: The unique identifier for the diagnostic being triggered Line 3: The title for the diagnostic Line 4: The message for the diagnostic Line 11: The category for the diagnostic (the type of analyzer - for example the default template analyzer has a category of Naming, while the above uses Usage) Line 13: Creates the actual rule using the information defined above Line 14: Exposes the rules the analyzer could potentially report (a single analyzer could trigger multiple types of diagnostic)   The diagnostic result information displayed in Visual Studio \n Register the action The next step is to register an action to be called when Roslyn finds a the type of code (syntax kind) the analyzer is interested in.\nThis is done in the overridden Initialize method.\n1 2 3 4 5 6 7  public override void Initialize(AnalysisContext context) { context.ConfigureGeneratedCodeAnalysis(GeneratedCodeAnalysisFlags.None); context.EnableConcurrentExecution(); context.RegisterSyntaxNodeAction(AnalyzeExpression, SyntaxKind.InvocationExpression); }    Line 3-4: Default configuration. For most analyzers this does not need to be changed Line 6:. This is the important line, which registers the AnalyzeExpression method to be called when Roslyn finds a piece of code which is of type InvocationExpression (a method call).  There are a large number of SyntaxKinds which can be used to trigger a call to the action method.\nThe analyzer is starting to take form, with the details of the rule defined, as well as an action registered, to be called when the syntax kind in question is found by Roslyn.\n Interrogate the syntax tree See the \u0026ldquo;Working Sample Analyzer\u0026rdquo; section in the previous post for more information regarding what this customer analyzer is doing. In short though, the analyser is looking for a very specific method called Migrate on a parent called Database (so Database.Migrate()), which should only be called in debug configuration.\nThis is where most of the analyzer work happens - the syntax node and syntax tree are interrogated to determine if the diagnostic should be triggered or not.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  private static void AnalyzeExpression(SyntaxNodeAnalysisContext context) { // We know the node is of type InvocationExpressionSyntax as the callback // registration was only for SyntaxKind.InvocationExpression var invocationExpr = (InvocationExpressionSyntax)context.Node; // InvocationExpr.Expression is the method name, the expression before \u0026#34;(\u0026#34;.  // In our case Database.Migrate var memberAccessExpr = invocationExpr.Expression as MemberAccessExpressionSyntax; if (memberAccessExpr == null) return; // Get the expression. In our case, Database var bindingExpression = memberAccessExpr.Expression as MemberBindingExpressionSyntax; if (bindingExpression == null) return; // Get the memberAccessExpr name of the expression. // In our case, Migrate var expressionName = bindingExpression.Name as IdentifierNameSyntax; if (expressionName == null) return; // If we reach this far, make sure its the Database property if (expressionName.Identifier.ToString().ToLower() != \u0026#34;Database\u0026#34;.ToLower()) return; // Get the memberAccessExpr name of the expression. // In our case, Migrate var identifierName = memberAccessExpr.Name as IdentifierNameSyntax; if (identifierName == null) return; // check if its the specific method we want to analyze if (identifierName.Identifier.ToString().ToLower() == \u0026#34;Migrate\u0026#34;.ToLower()) { var closestIfDirective = CodeAnalysisHelper.GetClosestIfDirective( memberAccessExpr, context.SemanticModel.SyntaxTree.GetRoot()); if (closestIfDirective != null) { if(CodeAnalysisHelper.IsValidIfDirective(closestIfDirective)) { return; } } // report the error if we found the method and it didn\u0026#39;t have the  // directives expected var diagnostic001 = Diagnostic.Create(rule001, identifierName.GetLocation()); context.ReportDiagnostic(diagnostic001); } }   As the AnalyzeExpression method is called every time the syntax kind registered (InvocationExpression in this case) is found in code, the analyzer needs to ignore any InvocationExpression\u0026rsquo;s which are not relevant to it.\n Lines 5-35: These lines interrogate the syntax tree to make sure the InvocationExpression is the one relevant to it - Database.Migrate() Line 37-38: A helper method is called to find the closest #if directive which occurs before the Database.Migrate() call Line 41: A helper method is called to check if the #if directive contains a valid condition Line 49-50: All necessary checks are complete and the diagnostic is triggered with Roslyn  These step can be very tricky to get right, and sometimes requires a lot of trial and error and debugging to get right. Working with the syntax tree can be complex depending on what the analyzer is looking for.\nHowever the Syntax Visualizer does make it easier.\nThis is an iterative process, using the below three methods to debug, inspect the code and syntax tree, and making tweaks to the various analyzer checks:\n Use of the Syntax Visualizer Use of the unit test infrastructure for analyzers Executing the VSIX project (which starts up a new instance of Visual Studio with the analyzer installed as an extension)   The Syntax Visualizer Visual Studio comes with a built in tool window called the Syntax Visualizer, which can be found under the View -\u0026gt; Other Windows -\u0026gt; Syntax Visualizer.\nThis window will track the current active code window, and display the syntax tree of the active code, in a hierarchical structure.\nSelecting various pieces of the code will cause the highlighted item in the Syntax Visualizer to change and track the active item in code.\nThis is invaluable in determining which SyntaxKind to register (as described in the \u0026ldquo;register the action\u0026rdquo; section ), as well as how to traverse the tree to find the relevant syntax nodes to trigger the diagnostic being registered.\nThe Syntax Visualizer + the sample project created in the \u0026ldquo;creating an analyzer project\u0026rdquo; section, are key in correctly determining the logic of the analyzer. The below screen shot show the Syntax Visualizer reflecting the part of the syntax tree for the Migrate() method.\nNotice how the tree matches the checks done in the code in the above section::\nInvocationExpression -\u0026gt; MemberAccessExpression -\u0026gt; MemberBindingExpression -\u0026gt; IdentifierName\n The Syntax Visualizer used in the sample project \n Trigger the diagnostics Once the code has been interrogated and it has been determined feedback needs to be given, the final step is to trigger and register the diagnostic with Roslyn.\nThe diagnostic information and rule created in \u0026ldquo;diagnostic setup\u0026rdquo;, is reported at a specific location.\n1 2 3 4  // report the error if we found the method and it didn\u0026#39;t have the  // directives expected var diagnostic001 = Diagnostic.Create(rule001, identifierName.GetLocation()); context.ReportDiagnostic(diagnostic001);    Line 3: The diagnostic is created, with a specific rule and a specific location. This location will be where the squiggle appears in code when the diagnostic is triggered. Line 4: The diagnostic is finally triggered with Roslyn.  Next steps: Coding the code fix Next up, part 3 in the series will go into detail and expand on coding the code fix for our analyzer, which will fix the code the analyzer has determined to be incorrect.\n Useful links Roslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-25T02:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-write/","title":"Roslyn Analyzer - writing the analyzer (Part 2)"},{"content":"Series introduction This is a a five part series exploring the Roslyn analyzer and code fix functionality, how to successfully write and test a custom analyzer, as well as some useful tips and tricks for writing analyzers.\nAll posts in the series:\nPart 1: Roslyn Analyzer - explained (this post)\nPart 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nWhat is Roslyn? In short, Roslyn is the .NET compiler - it consists of the compilers for C# and Visual Basic, as well as an api layer which can be leveraged to gather information about the code (analyse), and then perform actions based on this information (code fix).\n What is a Roslyn analyzer? An analyzer is a piece of code which inspects code (C# or Visual Basic) during design and compile time, and based on the results of the inspection, can raise a diagnostic result as an Error, Warning or as Information.\nAll installed and built-in analyzer(s) are run at design time (and compile time) automatically, with the diagnostic results reflecting:\n As coloured \u0026ldquo;squiggles\u0026rdquo; in code In the Error List (Ctrl+W, E) in Visual Studio In the build output   Warning highlighted in code by the green squiggle, and also appearing in the Error List \n Warning also reflecting during a build \nAn analyzer can be leveraged to inspect code for a number of issues related to (but not limited to):\n Style Quality Design Maintainability  As Roslyn exposes an API layer on top of the compiler, this layer can be used to write a custom analyzer.\nSee part 2 for more in depth details regarding writing a custom analyzer.\n What is a Roslyn analyzer code fix? Once an analyzer has inspected the code and returned an diagnostic result, the next step is apply a code change to resolve the source of the alert - a code fix.\nAn analyzer does not require a code fix, but if no code fix is provided then it is up to the developer to resolve the issue manually based on the error, warning or information message.\nIf the analyzer does have an associated code fix, it can be accessed using these steps:\n Hover or place the cursor over the squiggle, a light bulb will appear Select the small arrow next to the light bulb, or (Ctrl+.) to see available fix suggestions Hover the cursor over one of the suggestions in the list A preview of how the code will be changed when the code fix is applied is displayed Select one of the suggestions to apply the code fix   Code fix for the analyzer \nSee part 3 for more in depth details regarding writing a code fix for a custom analyzer.\n Why write an analyzer? A few reasons or use cases for writing a custom analyzer:\n To monitor and diagnose more niche coding patterns you, as a developer, constantly gets wrong or have to look up (analyzers already exist for most common best practices) As a library author (publishing a library to NuGet, for example) an analyzer can be packaged with the library (see the section below) to ensure that it is used correctly by the developer. To ensure common coding practices and styles are shared across all development teams in an organization.   Sharing a custom analyzer There are two ways to share a custom analyzer once it has been written:\n VSIX: The analyzer can be packaged as a vsix, a Visual Studio Extension. This is an executable file which can be either be shared and manually installed by the developer, or can be downloaded Visual Studio Marketplace.. NuGet package: An analyzer can be package into a NuGet package and installed into a project via a NuGet store (such as nuget.org or an internal NuGet store in the case of a company specific analyzer)   Analyzers are tricky! It can be very tricky getting the analyzer to accurately detect the relevant scenarios in code, and just as hard to fix it accurately with a code fix - syntax trees are complex. (more on this later in the series: part 2, part 3 and part 4)\nOn top of that, the developer experience for analyzers are not as slick and friendly as with other tooling. The debugging experience for analyzers are inconsistent and not always responsive, while the apis exposed to assist with testing an analyzer can be complicated and difficult to configure.\nBut all is not lost - it is possible to work with and around the above constraints (with tips from this series of posts) and still successfully create your own custom analyzer.\n A working sample analyzer The guides in part 2 and part 3 will detail how to write an analyzer package which inspects the code, and applies a code fix for the following two scenarios related to Entity Framework Core (an understanding of Entity Framework Core is not required to understand the analyzers):\n Ensure code migrations are not automatically applied in the Test or Production environment Ensure the correct appsettings.json section has been added an Entity Framework Core database connection is configured in code  Scenario 1: auto-migrations Entity Framework Core (EF) is an ORM which provides build in data-access functionality to perform operations on a database. What is important for these posts, is to know that EF provides functionality to scaffold and update the schema of the database (the tables etc) at runtime, usually at startup.\nHowever it is recommended to only run this migration on development environments, and not in test or production environments. Usually CI/CD pipeline executes the database migration in these environments (which also allows for review of the migration script before it being applied to the database)\nThe custom analyzer will look for the presence of the migration code (a .Database.Migrate method call), and ensure it is only executed when the code is run in DEBUG configuration.\nScenario 2: connection string When configuring EF, a database connection name is specified, with the actual connection string stored in the appsettings.json settings file.\n1 2  .AddDbContext\u0026lt;SampleContext\u0026gt;(x =\u0026gt; x .UseSqlite(context.Configuration.GetConnectionString(\u0026#34;SampleDatabase\u0026#34;)))   This code relies on the connection string being present in the appsettings.json file:\n1 2 3 4 5  { \u0026#34;ConnectionStrings\u0026#34;: { \u0026#34;SamplesDatabase\u0026#34;: \u0026#34;Data Source=LocalDatabase.db\u0026#34; } }   The custom analyzer will inspect the appsettings.json file and ensure the connection string is present and correct.\n Next steps: Writing the analyzer Next up, part 2 in the series will go into detail and expand on coding a custom analyzer.\n Useful links Entity Framework Core\nRoslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-24T01:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-explained/","title":"Roslyn Analyzer - explained (Part 1)"},{"content":"The challenge Consider a scenario where the requirement is to upload a file to an online provider (AWS S3, Azure Blob or a FTP site in the examples below), where the provider can be easily changed (either dynamically at runtime, or easily with minimal code changes), with the possibility additional providers being added in future.\nTo make use of dependency injection, a generic interface is created, IFileUploader, along with three implementations AWSUploader, AzureUploader and FTPUploader. The interface prescribes that the implementations provide a method to upload a file (UploadFile) and a method to get the implementation name (GetName).\nThe built in .NET dependency injection (DI) container is all one will need for almost all situations (including this situation): however this scenario can be a bit more challenging to get right - with multiple implementations of the same interface, how do you get the right implementation from the DI container?\nThe problem with .NET dependency injection container One piece of functionality the .NET DI container does not have (which is available in some other 3rd party DI/IoC containers) is the ability to add and retrieve service implementations by name.\nShort of actually implementing one of these other 3rd party containers, below are a number of different options and techniques one can use to get the correct implementation from the DI container when there are multiple implementations registered.\n     The benchmarks on the below techniques were all executed at the same time under the same conditions using BenchmarkDotNet\nEven though some some techniques performed poorly when compared to others, bear in mind that the time frame in question here is nanoseconds (a nanosecond is one billionth of a second).\nIn most scenarios, the DI technique used (if used correctly) is not going to make a massive material different to the performance of the application/service (of course there are exceptions, depending on how complicated the dependency tree is)\n   The different techniques IEnumerable   Configuration:\nThis is the simplest \u0026lsquo;out of the box\u0026rsquo; technique, with the various implementations just all added to the DI container using the same interface (lines 7-9): 1 2 3 4 5 6 7 8 9 10 11  private readonly IHost host; public EnumerableBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;EnumerableHandler\u0026gt;() .AddTransient\u0026lt;IFileUploader, AWSUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, AzureUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, FTPUploader\u0026gt;() ).Build(); }  \n  Usage:\nInject IEnumerableinto the relevant class (line 4), and then retrieve the required implementation from the IEnumerable collection (lines 11-13) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class EnumerableHandler { private readonly IEnumerable\u0026lt;IFileUploader\u0026gt; _uploaders; public EnumerableHandler(IEnumerable\u0026lt;IFileUploader\u0026gt; uploaders) { _uploaders = uploaders; } public void Execute() { var providerName = \u0026#34;aws\u0026#34;; var uploader = _uploaders.FirstOrDefault(up =\u0026gt; up .GetName().Equals(providerName)); if (uploader == null) { throw new ArgumentException($\u0026#34;No uploader with name \u0026#34; + $\u0026#34;{providerName} could be found\u0026#34;); } uploader.UploadFile(); } }  \n  Pros:\n Easy to implement Implementation can be selected/changed at runtime    Cons:\n Every implementation is instantiated (as part of IEnumerable) even if not required or used. This could be especially problematic if the implementations themselves have a number of dependencies which then need to be instantiated (this was NOT the case with the benchmarks) which could result in a negative performance impact. The logic to retrieve the implementation from IEnumerable is contained in multiple places (each class which has it injected)    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B       Factory One of the negative aspects of the IEnumerable approach, is that the logic to retrieve the correct implementation could be present in multiple places (if IEnumberable is injected into multiple classes). The Factory approach moves the logic into a separate actory class, which is then injected and is responsible for retrieving the required implementation.\n  Configuration:\nConfiguration is the same as IEnumerable, the various implementations all added to the DI container using the same interface, with one additional class added, the factory class (line 7) 1 2 3 4 5 6 7 8 9 10 11 12  private readonly IHost host; public FactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;FactoryHandler\u0026gt;() .AddTransient\u0026lt;FileUploaderFactory\u0026gt;() .AddTransient\u0026lt;IFileUploader, AWSUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, AzureUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, FTPUploader\u0026gt;() ).Build(); }  \nThe factory looks very similar to the handler from the IEnumerable approach: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class FileUploaderFactory { private readonly IEnumerable\u0026lt;IFileUploader\u0026gt; _uploaders; public FileUploaderFactory(IEnumerable\u0026lt;IFileUploader\u0026gt; uploaders) { _uploaders = uploaders; } public IFileUploader Resolve(string providerName) { var uploader = _uploaders.FirstOrDefault(up =\u0026gt; up .GetName().Equals(providerName)); if (uploader == null) { throw new ArgumentException($\u0026#34;No uploader with name \u0026#34; + $\u0026#34;{providerName} could be found\u0026#34;); } return uploader; } }  \n  Usage:\nThe factory is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class FactoryHandler { private readonly FileUploaderFactory _factory; public FactoryHandler(FileUploaderFactory factory) { _factory = factory; } public void Execute() { var providerName = \u0026#34;azure\u0026#34;; var uploader = _factory.Resolve(providerName); uploader.UploadFile(); } }  \n  Pros:\n Easy to implement Implementation can be selected/changed at runtime Retrieval logic is contained in a single place    Cons:\n Every implementation is instantiated (as part of IEnumerable) even if not required or used. This could have an impact on performance and memory usage. Slightly slower, and slightly more memory usage than the IEnumerable approach (due to the extra layer between the handler and the IEnumerable collection)    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B       Type Factory A big negative aspect of the IEnumerable and Factory approach, is that all the implementations are instantiated every time, even if not used or required. This could have big impact on performance and memory if the implementations them themselves have many dependencies (and those dependencies have dependencies and so on).\nThe next approach is extends on the Factory technique, but only instantiates the requested implementation based on naming conventions.\n  Configuration:\nSetup is the same as with the Factory method. 1 2 3 4 5 6 7 8 9 10 11 12  private readonly IHost host; public FactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;TypeFactoryHandler\u0026gt;() .AddTransient\u0026lt;FileUploaderTypeFactory\u0026gt;() .AddTransient\u0026lt;IFileUploader, AWSUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, AzureUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, FTPUploader\u0026gt;() ).Build(); }  \nThe factory in this approach, takes the requested name, finds the type based on the name (lines 11-12) and gets it from the DI container (line 20) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class FileUploaderTypeFactory { private readonly IServiceProvider _provider; public FileUploaderTypeFactory(IServiceProvider provider) { _provider = provider; } public IFileUploader Resolve(string providerName) { var type = Assembly.GetAssembly(typeof(FileUploaderTypeFactory)).GetType( $\u0026#34;{typeof(FileUploaderTypeFactory).Namespace}.{providerName}Uploader\u0026#34;); if (type == null) { throw new ArgumentException($\u0026#34;No uploader with name \u0026#34; + $\u0026#34;{providerName} could be found\u0026#34;); } var uploader = _provider.GetService(type); return uploader as IFileUploader; } }  \n  Usage:\nThe factory is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class TypeFactoryHandler { private readonly FileUploaderTypeFactory _factory; public TypeFactoryHandler(FileUploaderTypeFactory factory) { _factory = factory; } public void Execute() { var providerName = \u0026#34;Azure\u0026#34;; var uploader = _factory.Resolve(providerName); uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Better memory usage compared to other two approaches so far Implementation can be selected/changed at runtime Retrieval logic is contained in a single place    Cons:\n Use of reflection to convert the name to a Type does have an big impact on performance Strict naming convention has to be followed in order for the reflection logic to work correctly    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B       Delegate The next approach tries to achieve the same as the Type Factory approach - not instantiating every implementation, but using a different technique.\nIn short, a delegate is called at runtime when an implementation is requested, and using a switch statement the correct one is determined and returned.\n  Configuration:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  private readonly IHost host; public DelegateBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;DelegateHandler\u0026gt;() .AddTransient\u0026lt;DelegateResolver\u0026gt;(serviceProvider =\u0026gt; providerName =\u0026gt; { switch (providerName) { case \u0026#34;aws\u0026#34;: return serviceProvider.GetService\u0026lt;AWSUploader\u0026gt;(); case \u0026#34;azure\u0026#34;: return serviceProvider.GetService\u0026lt;AzureUploader\u0026gt;(); case \u0026#34;ftp\u0026#34;: return serviceProvider.GetService\u0026lt;FTPUploader\u0026gt;(); default: throw new ArgumentException($\u0026#34;No uploader with \u0026#34; + $\u0026#34;name {providerName} could be found\u0026#34;); } })).Build(); }  \nThe DelegateResolver is as follows 1  public delegate IFileUploader DelegateResolver(string providerName);  \n  Usage:\nThe delegate is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class DelegateHandler { private readonly DelegateResolver _resolver; public DelegateHandler(DelegateResolver resovler) { _resolver = resovler; } public void Execute() { var uploader = _resolver(\u0026#34;ftp\u0026#34;); uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Best memory usage compared to other approaches so far Implementation can be selected/changed at runtime Retrieval logic is contained in a single place    Cons:\n Slightly more complicated setup with the delegate and switch statement compared to other approaches Switch statement is hardcoded and needs to be manually maintained every time a new provider is added    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B       Type Delegate The next approach extends the Delegate technique, and uses reflection and naming conventions to get the Type dynamically.\n  Configuration:\nSetup is as follows, very similar to the Delegate approach, but instead of the switch statement, reflection is used to get the Type based on naming conventions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  private readonly IHost host; public TypeDelegateBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;TypeDelegateHandler\u0026gt;() .AddTransient\u0026lt;TypeDelegateResolver\u0026gt;(serviceProvider =\u0026gt; providerName =\u0026gt; { var type = Assembly.GetAssembly(typeof(FileUploaderTypeFactory)) .GetType($\u0026#34;{typeof(FileUploaderTypeFactory).Namespace} .{providerName}Uploader\u0026#34;, false, true); if (type == null) { throw new ArgumentException($\u0026#34;No uploader with \u0026#34; + $\u0026#34;name {providerName} could be found\u0026#34;); } var uploader = serviceProvider.GetService(type); return uploader as IFileUploader; })).Build(); }  \nThe DelegateResolver is the same as before. 1  public delegate IFileUploader DelegateResolver(string providerName);  \n  Usage:\nThe delegate is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class TypeDelegateHandler { private readonly DelegateResolver _resolver; public TypeDelegateHandler(DelegateResolver resovler) { _resolver = resovler; } public void Execute() { var uploader = _resolver(\u0026#34;ftp\u0026#34;); uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Retrieval logic is contained in a single place No switch statement to maintain when a new provider is added    Cons:\n Use of reflection to convert the name to a Type does have a large impact on performance Strict naming convention has to be followed in order for the reflection logic to work correctly    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B       Distinct The next technique uses a wrapper to make each implementation added to the DI container unique, and hence can be retrieved uniquely.\n  Configuration:\nAdditional types are also now required to be defined and added to the DI container, IGenericUploader and GenericUploader 1 2 3 4 5 6 7 8 9 10 11 12 13 14  private readonly IHost host; public DistinctBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;DistinctHandler\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AWSUploader\u0026gt;, GenericUploader\u0026lt;AWSUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AzureUploader\u0026gt;, GenericUploader\u0026lt;AzureUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;FTPUploader\u0026gt;, GenericUploader\u0026lt;FTPUploader\u0026gt;\u0026gt;() ).Build(); }  \nIGenericUploader is defined as below. 1  public interface IGenericUploader\u0026lt;T\u0026gt; : IFileUploader where T : IFileUploader { }  \nGenericUploader is defined as below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class GenericUploader\u0026lt;T\u0026gt; : IGenericUploader\u0026lt;T\u0026gt; where T : IFileUploader { private readonly T _implementation; public GenericUploader(T implementation) { _implementation = implementation; } public string GetName() { return _implementation.GetName(); } public void UploadFile() { _implementation.UploadFile(); } }  \n  A new generic provider is defined (implementing the relevant interface) and the generic provider wraps the \u0026ldquo;true provider\u0026rdquo; implementation. As the generic implementation takes a T argument, this can be used to uniquely distinguish them and retrieve the correct implementation.\n  Usage:\nThe generic interface with the required implementation is now injected into the relevant class (line 4) and is then invoked (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13  public class DistinctHandler { private readonly IGenericUploader\u0026lt;AWSUploader\u0026gt; _uploader; public DistinctHandler(IGenericUploader\u0026lt;AWSUploader\u0026gt; uploader) { _uploader = uploader; } public void Execute() { _uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated The default DI container is doing all the retrieval work (as a unique item is being asked for), so is very efficient By far the best performing (in both time and memory usage) technique so far    Cons:\n Implementation can NOT be selected/changed at runtime Bit of a convoluted process having a wrapper interface    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B       Distinct Factory This technique extends the Distinct approach, resolving the limitation of not being able to select or change the implementation at runtime.\n  Configuration:\nSetup very similar to the Distinct setup, with the addition of the DistinctFactory (line 9) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  private readonly IHost host; public DistinctFactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;DistinctFactory\u0026gt;() .AddTransient\u0026lt;DistinctFactoryHandler\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AWSUploader\u0026gt;, GenericUploader\u0026lt;AWSUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AzureUploader\u0026gt;, GenericUploader\u0026lt;AzureUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;FTPUploader\u0026gt;, GenericUploader\u0026lt;FTPUploader\u0026gt;\u0026gt;() ).Build(); }  \nIGenericUploader and GenericUploader are exactly as defined in the Distinct technique.\nDistinctFactoryHandler is defined as below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class DistinctFactory { private readonly IServiceProvider _provider; public DistinctFactory(IServiceProvider provider) { _provider = provider; } public IFileUploader Resolve(string providerName) { switch (providerName) { case \u0026#34;aws\u0026#34;: return _provider.GetService(typeof( IGenericUploader\u0026lt;AWSUploader\u0026gt;)) as IFileUploader; case \u0026#34;azure\u0026#34;: return _provider.GetService(typeof( IGenericUploader\u0026lt;AzureUploader\u0026gt;)) as IFileUploader; case \u0026#34;ftp\u0026#34;: return _provider.GetService(typeof( IGenericUploader\u0026lt;FTPUploader\u0026gt;)) as IFileUploader; default: throw new ArgumentException($\u0026#34;No uploader with \u0026#34; + $\u0026#34;name {providerName} could be found\u0026#34;); } } }  \n  Usage:\nThe factory is now injected into the relevant class (line 4) and is then invoked to get the requested implementation by name (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class DistinctFactoryHandler { private readonly DistinctFactory _distinctFactory; public DistinctFactoryHandler(DistinctFactory distinctFactory) { _distinctFactory = distinctFactory; } public void Execute() { _distinctFactory.Resolve(\u0026#34;ftp\u0026#34;).UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance    Cons:\n Switch statement is hardcoded and needs to be manually maintained every time a new provider is added Bit of a convoluted process    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B       Distinct Lookup Factory This approach gives implementations names as they are added to the DI container, keeps track of the name-implementation link, and facilitates lookup and retrieval of the correct implementation.\n  Configuration:\nThis setup is different, in that implementations of the same interface are grouped together by the AddNamedUploader extension method (line 6), and as implementations are added, they are given a name. 1 2 3 4 5 6 7 8 9 10 11 12 13  private readonly IHost host; public DistinctLookupFactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddNamedUploader\u0026lt;IFileUploader\u0026gt;(builder =\u0026gt; builder .AddTransient(\u0026#34;aws\u0026#34;, typeof(AWSUploader)) .AddTransient(\u0026#34;azure\u0026#34;, typeof(AzureUploader)) .AddTransient(\u0026#34;ftp\u0026#34;, typeof(FTPUploader)) ) .AddTransient\u0026lt;DistinctLookupFactoryHandler\u0026gt;() ).Build(); }  \nThere are a number of new components here:\n AddNamedUploader extension method (line 6): this will setup base functionality required as expose the UploaderBuilder as a parameter builder, of type UploaderBuilder (line 6): this is an Action which handles keeping track of the name-implementation link. AddTransient extension method (lines 7-9): this is not the same as the normal AddTransient method on IServiceCollection, but an extension method on the builder (UploaderBuilder) which wraps the usual .NET AddTransient method.  The full definition of the classes (along with all other code) can be found on Github, here\nIn summary though, it works as follows:\n  AddNamedUploader creates an instance of UploaderTypes, which keeps track of the name and the implementation Type. UploaderTypes is added to the DI container as a singleton. 1 2 3 4 5 6 7 8 9 10 11 12  public static IServiceCollection AddNamedUploader\u0026lt;T\u0026gt;( this IServiceCollection services, Action\u0026lt;UploaderBuilder\u0026lt;T\u0026gt;\u0026gt; builder) where T : class { var uploaderType = new UploaderTypes\u0026lt;T\u0026gt;(); services.AddSingleton(uploaderType); services.AddTransient(typeof(DistinctLookupFactory\u0026lt;T\u0026gt;)); builder.Invoke(new UploaderBuilder\u0026lt;T\u0026gt;(services, uploaderType)); return services; }  \n  The AddTransient method will add records to the UploaderTypes class, as well as add the implementation to the DI container. 1 2 3 4 5 6 7 8 9 10  public static UploaderBuilder\u0026lt;T\u0026gt; AddTransient\u0026lt;T\u0026gt;( this UploaderBuilder\u0026lt;T\u0026gt; builder, string name, Type implementation) where T : class { builder.Types.Add(name, implementation); builder.Services.AddTransient(implementation); return builder; }  \n    Usage:\nThe factory is now injected into the relevant class (line 4) for a specific interface, and is then invoked to get the requested implementation by name (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class DistinctLookupFactoryHandler { private readonly DistinctLookupFactory\u0026lt;IFileUploader\u0026gt; _distinctFactory; public DistinctLookupFactoryHandler( DistinctLookupFactory\u0026lt;IFileUploader\u0026gt; distinctFactory) { _distinctFactory = distinctFactory; } public void Execute() { _distinctFactory.Resolve(\u0026#34;ftp\u0026#34;).UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance No hard coded switch statement which needs to be maintained    Cons:\n The most complicated to setup, with the most moving parts    Performance:\n     Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B   DistinctLookupFactory Execute 92.96 ns 0.764 ns 0.714 ns 1.07 0.01 0.0126 80 B     Rollcall Rollcall is a library (written by me) which extends the DistinctLookupFactory approach and makes it generic so that it will function with any interface and implementation. Rollcall is available on Nuget\n  Configuration:\nThe setup is almost identical to the DistinctLookupFactory, but without the need for the factory, as this is built into the Rollcall library. 1 2 3 4 5 6 7 8 9 10 11 12 13  private readonly IHost host; public RollcallBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;RollcallHandler\u0026gt;() .AddNamedService\u0026lt;IFileUploader\u0026gt;(builder =\u0026gt; builder .AddTransient(\u0026#34;aws\u0026#34;, typeof(AWSUploader)) .AddTransient(\u0026#34;azure\u0026#34;, typeof(AzureUploader)) .AddTransient(\u0026#34;ftp\u0026#34;, typeof(FTPUploader)) ) ).Build(); }  \n  Usage:\nThe Rollcall provider/factory is now injected into the relevant class (line 4) for a specific interface, and is then invoked to get the requested implementation by name (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class RollcallHandler { private readonly IRollcallProvider\u0026lt;IFileUploader\u0026gt; _provider; public RollcallHandler(IRollcallProvider\u0026lt;IFileUploader\u0026gt; provider) { _provider = provider; } public void Execute() { var providerName = \u0026#34;aws\u0026#34;; var uploader = _provider.GetService(providerName); uploader.UploadFile(); } }   Not shown above, but one could also inject IServiceProvider and used the provided GetService extension method to get the service by name.\n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance No hard coded switch statement which needs to be maintained Works with any interface + implementation, and provides all functionality out the box    Cons:\n Slight performance overhead when compared to the non-generic method    Performance:\n     Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B   DistinctLookupFactory Execute 92.96 ns 0.764 ns 0.714 ns 1.07 0.01 0.0126 80 B   Rollcall Execute 124.52 ns 1.485 ns 1.389 ns 1.43 0.02 0.0076 48 B     Rollcall with Func Rollcall can also be used with a implementation factory, a Func\u0026lt;IServiceProvider,object\u0026gt; method. This method is called when requesting the implementation by name from the DI container. Available on NuGet.\n  Configuration:\nThe setup is a little more complicated than before, as some of the configuration needs to be done manually (instead of by the Rollcall package) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  private readonly IHost host; public RollcallFuncBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;RollcallFuncHandler\u0026gt;() .AddTransient\u0026lt;AWSUploader\u0026gt;() .AddTransient\u0026lt;AzureUploader\u0026gt;() .AddTransient\u0026lt;FTPUploader\u0026gt;() .AddNamedService\u0026lt;IFileUploader\u0026gt;(builder =\u0026gt; builder .AddTransient(\u0026#34;aws\u0026#34;, sp =\u0026gt; sp.GetService(typeof(AWSUploader))) .AddTransient(\u0026#34;azure\u0026#34;, sp =\u0026gt; sp.GetService(typeof(AzureUploader))) .AddTransient(\u0026#34;ftp\u0026#34;, sp =\u0026gt; sp.GetService(typeof(FTPUploader))) )).Build(); }  \n  Usage:\nThe usage is exactly the same with the Func\u0026lt;\u0026gt; as with the normal interface + implementation (as shown above) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class RollcallFuncHandler { private readonly IRollcallProvider\u0026lt;IFileUploader\u0026gt; _provider; public RollcallFuncHandler(IRollcallProvider\u0026lt;IFileUploader\u0026gt; provider) { _provider = provider; } public void Execute() { var providerName = \u0026#34;aws\u0026#34;; var uploader = _provider.GetService(providerName); uploader.UploadFile(); } }   Not shown above, but one could also inject IServiceProvider and used the provided GetService extension method to get the service by name.\n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance No hard coded switch statement which needs to be maintained Works with any interface + func\u0026lt;\u0026gt;, and provides all functionality out the box    Cons:\n Slight performance overhead when compared to the non-generic method, and when compared to the interface + implementation method.    Performance:\n     Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B   DistinctLookupFactory Execute 92.96 ns 0.764 ns 0.714 ns 1.07 0.01 0.0126 80 B   Rollcall Execute 124.52 ns 1.485 ns 1.389 ns 1.43 0.02 0.0076 48 B   RollcallFunc Execute 134.68 ns 1.224 ns 1.085 ns 1.55 0.02 0.0076 48 B     Conclusion There are a variety of ways to handle multiple implementations of the same interface, none of which are wrong. However, not all are suitable for every situation and using the incorrect one for the situation could result in a performance impact.\nThere are trade-offs and pros and cons to using each technique - the most performant might be the most difficult to maintain for your situation.\nTest the various methods and find which works best and is most optimal for your particular situation.\nReferences and links Rollcall Github repo\nRollcall Nuget package\n ","date":"2021-11-06T01:00:00+02:00","permalink":"https://always-developing.github.io/p/multiple-implementations/","title":"Multiple implementations of same interface - the options"},{"content":"Why learn keyboard shortcuts? So I confess I have no empirical evidence to backup the up to 20% more productive claim. That number is just made up, but with years of experience on my side, it honestly feels fairly accurate to me!\nHaving often been involved in assisting, troubleshooting and debugging code with fellow developers, it is apparent that the developers which are familiar with their IDE, and make use of the shortcuts, generally (but not always!) resolve tasks quicker and more efficiently than those that don\u0026rsquo;t.\nEvery hand reach for the mouse, every unnecessary cursor movement, every menu click is potentially a waste of time. It\u0026rsquo;s time two hands are not on the keyboard writing code. The more shortcuts a person is familiar with, the more the unnecessary time wasting can be minimized. Thus, more programming time and more productivity!\n Is there anything wrong with not making use of keyboard shortcuts? Definitely not. Does not using keyboard shortcuts make a person any less of a developer? Definitely not. Could using keyboard shortcuts make a person more productive? Definitely yes.  Visual Studio shortcuts to learn Below is a list of useful Visual Studio shortcuts I use the most often and find the more useful in my day to day development. This is by no means an exhaustive list - however I have no doubt a massive benefit can be gained by learning just a few of these.\nSome of these shortcuts are not just Visual Studio shortcuts, and also be leveraged in other applications (such as VS Code).\n       + indicates a combination of keys is to be pressed to perform the action.\nIn some cases (like the example below), the final key can be tapped to perform the action multiple times (while still holding down the initial two keys)\nE.g. Ctrl + Shift + -: Ctrl and Shift can be held down at the same time while the - key is pressed multiple times.\n  , is used to indicate a sequence of keys is to be pressed.\nE.g. Ctrl + M, O: Ctrl is held down, while M is pressed and then O is pressed.\n     View shortcuts   Ctrl + - and Ctrl + Shift + -: Navigate backwards and forwards 🧭\nMoves the cursor, backwards and forwards through the history of visited cursor locations in file(s). This is incredibly useful especially when used in conjunction with the Go to Definition / Ctrl + F12 function.\n  Ctrl + .: Quick actions and refactoring 💡\nWhen the cursor is over a block of code, this shortcut will bring up the quick actions and refactoring (Lightbulb or screwdriver icon) menu\n  Ctrl + Spacebar: Trigger Intellisense\n  Editor shortcuts   Ctrl + ← and Ctrl + →: Moves cursor one word to the left or right ⬅️➡️\nGreat when used in combination with the Shift key (e.g. Ctrl + Shift + →) to highlight/select entire word(s).\n  Ctrl + Del: Delete an entire line 🚫\nWhen you dislike your code and you want it gone quickly.\n  Ctrl + M, O: Collapse to definitions 📄\nCollapse all methods, regions, comment blocks etc in the current document.\n  Ctrl + F: Find in current file 🔍\nDefaults to search in only the current document, but this can be changed to include more documents (e.g. entire solution)\n  Ctrl + Shift + F: Find in all files 🔍🔍\nOpens the Find in files dialog. Defaults to search the entire solution, but this can be changed to include less documents (e.g. current document)\n  Ctrl + H: Replace in current file 📑\nDefaults to search in only the current document, but this can be changed to include more documents (e.g. entire solution)\n  Ctrl + Shift + H: Replace in all files 📑📑\nOpens the Replace in files_ dialog. Defaults to replace in the entire solution, but this can be changed to include less documents (e.g. current document)\n  Ctrl + K, C and Ctrl + K, U: Comments and uncomment code selection 📜\nComment and uncomment code selection. If no selection is made, the line of code the cursor is current on will be commented/un-commented.\n  Refactor shortcuts   'ctor', Tab, Tab: Constructor creation 🏗️\nThis is a prebuilt code snippet and not really a keyboard shortcut. This will create a default parameter-less constructor for the current class\n  Ctrl + R, R: Rename 💬\nAllows for the rename of a class, method, variable etc. as well as all usages of said code. Place the cursor on a method name, for example, press Ctrl + R, R, type in the new name and hit enter. The method name and all usages of the name have now been renamed.\n  Ctrl + R, M: Extract to method 📤\nCreate a new method containing the selected code, and invoke the new method from the current code location. Great for code clean up.\n  Ctrl + R, G: Remove and sort usings ⛔ Performing this shortcut anywhere in a document will remove any unused usings in the file, as well as sort the remaining ones alphabetically.\n  Build shortcuts   F5: Build and start application with the debugger attached. 🐛\nBreakpoints will pause code execution, code can be stepped through, etc.\n  Ctrl + F5: Build and start application without the debugger attached. 🏃‍♂️\nNo debug symbols will be loaded, so breakpoints will not be hit. Most often used when:\n Running multiple dependent services/applications in the same solution (without the need for debugging all the projects) Running benchmarking (using BenchmarkDotNet)    Code quality shortcuts  ///: Adds comments 🧾\nUsed above a method or class to create and partially auto populate the comments.\nThese comments can be used to generate an XML document file (especially useful for library authors)  Conclusion It does take a conscious effort when starting to actually slow down, lookup the shortcut to be used and force yourself to use it. But adaption happens quickly, and before you know it you\u0026rsquo;ll be using the keyboard shortcuts without even realising it.\nIt is an on-going learning process - if you find yourself performing the same time consuming action over and over in the IDE, consider investigating and learning the shortcut.\nThe list of VS2019 Keyboard shortcuts. (this mostly apply to VS2017 and VS2022 as well)\nUse shortcuts. Be more productive.\n","date":"2021-10-25T01:00:00+02:00","permalink":"https://always-developing.github.io/p/vs-keyboard-shortcuts/","title":"Useful Visual Studio keyboard shortcuts"},{"content":"What\u0026rsquo;s the issue? When working with strings in C# one can either use String (uppercase) or string (lowercase) and in both cases the code will compile and execute.\nExplicitly typed string variables can be done in either of the following ways:\nstring variable = \u0026#34;Always Developing\u0026#34;; String variable = \u0026#34;Always Developing\u0026#34;; Or when invoking string related methods, both of the following examples are valid:\nstring variable = string.Format(\u0026#34;Always Developing using {0}\u0026#34;, \u0026#34;C#\u0026#34;); String variable = String.Format(\u0026#34;Always Developing using {0}\u0026#34;, \u0026#34;Typescript\u0026#34;); Whats the difference between using String and using string? Is there a difference? Does it really matter?\nIs there a difference?   System.String is a .NET CLR (Common Runtime Library) class. This means it\u0026rsquo;s part of the core .NET environment, which sits one level below the specific language implementation.\n  string is a C# specific keyword, which is an alias for the CLR System.String type.\n  What this means is that string is just another name for System.String and they are effectively equivalent.\n     The same way int is an alias and maps to the CLR type System.Int32 and long is an alias and map to CLR type System.Int64, string is an alias and maps to the CLR type System.String\n   Deeper comparisons Variable declaration We can further confirm String and string are equivalent by comparing the IL (Intermediate Language) code generated when declaring variables using both of the types.\n     This post is primarily to compare the C# String and string types, but VB.NET examples have also been included in the comparison for completeness.\n   Take these three methods, all functionally equivalent, but declaring the variable using the different types:\npublic string GetString() { String variable = \u0026#34;string value\u0026#34;; return variable; } public string GetString() { string variable = \u0026#34;string value\u0026#34;; return variable; } Public Function GetString() As String Dim variable As String = \u0026#34;string value\u0026#34; Return variable End Function The IL code generated by all three examples is all effectively identical:\n// Methods .method public hidebysig instance string GetString () cil managed { // Method begins at RVA 0x2050 // Code size 6 (0x6) .maxstack 8 IL_0000: ldstr \u0026#34;string value\u0026#34; IL_0005: ret } // end of method CClass::GetString String method invocation So it\u0026rsquo;s confirmed that String and string are equivalent when declaring variables, but what about with method invocation?\nAgain, three functionally equivalent methods, but invoking the Format method differently:\npublic string StringFormat() { var insertString = \u0026#34;C#\u0026#34;; var variable = String.Format(\u0026#34;Always Developing using {0}\u0026#34;, insertString); return variable; } public string StringFormat() { var insertString = \u0026#34;C#\u0026#34;; var variable = string.Format(\u0026#34;Always Developing using {0}\u0026#34;, insertString); return variable; } Public Function StringFormat() As String Dim insertString = \u0026#34;C#\u0026#34; Dim variable = String.Format(\u0026#34;Always Developing using {0}\u0026#34;, insertString) Return variable End Function When the generated IL code is compared, in all three cases, it is equivalent:\n// Methods .method public hidebysig instance string StringFormat () cil managed { // Method begins at RVA 0x2050 // Code size 18 (0x12) .maxstack 2 .locals init ( [0] string insertString ) IL_0000: ldstr \u0026#34;C#\u0026#34; IL_0005: stloc.0 IL_0006: ldstr \u0026#34;Always Developing using {0}\u0026#34; IL_000b: ldloc.0 IL_000c: call string [System.Private.CoreLib]System.String::Format(string, object) IL_0011: ret } // end of method CClass::StringFormat Conclusion Use either String or string, they are effectively equivalent.\nHowever, the recommended approach is to use the C# language specific keyword string, as it works without having to include using System;\n     The recommendation method of using string comes from the official Microsoft documentation, and is included as a default style rule in Visual Studio\n        It is recommended to use implicitly type local variables (where appropriate) by using the var keyword (instead of string, in the above examples), and having the type inferred by the compiled.\nThe use of var versus explicate declaration is a personal preference, and will not effect the execution or performance of the code.\nPersonally I use var in my code: I find the code cleaner and easier to read. One can see the type being inferred by the compiler by hovering the mouse cursor over the var keyword in Visual Studio.\n   References and links Microsoft string guidance\nMicrosoft style rule\nImplicitly typed variables\nSharp lab - IL generator\n","date":"2021-10-21T01:00:00+02:00","permalink":"https://always-developing.github.io/p/string-vs-string/","title":"C# String vs string"}]