[{"content":"Symbol server explained What are symbols? When building a .NET project, symbol files (generally files with the extension of .pdb) are automatically created by the compiler. These symbol files contain metadata information about the source code (indexes, function names, line numbers, etc) and are used when debugging and stepping through code, by linking the debugger (e.g. Visual Studio) to the source code.\nGenerally, these symbol files are only available when developing locally, and building a project in debug configuration - that is, unless they are uploaded to a symbol server.\nWhat is a symbol server? A symbol server is a central location to store symbols - having the symbols available allow for the stepping into a referenced NuGet package code without having the source code available locally.\nThe source code doesn\u0026rsquo;t need to be part of the solution being built, or even on the local machine - the symbol file, made available by the symbol server will allow for full \u0026lsquo;step into\u0026rsquo; debugging experience.\n Why use a symbol server As mentioned above, having the symbols available via the server, allows for stepping into a referenced package\u0026rsquo;s source code without having the source directly available locally. Why would one need or want this to be possible?\n Help the package author debug and assist when issues are experienced using the package. This is especially useful in the corporate environment where the author of a package is potentially closer to the developers and applications using the package, and is required to assist with the usage and functioning of the package. Help users of the package understand in more depth what the package does and how. Especially useful in an Open Source environment where the author of the package is most likely further removed from the user of the package. With the user of the package having the option of stepping into the package source code, it facilitates more easily understanding the package and allows for the user more easily help themselves if any issues arise.  Even though each point above highlights the use case in a specific environment (corporate vs Open Source), both points can apply to either environment.\n     This post will focus on using Azure Devops as a build and symbol server, but other build and symbol servers can also be used and will mostly follow a similar processes to the one described in this post.\n    Producing symbols Configuring code The first step in the process, is to configure the project to produce symbols with the required metadata to allow for the debugging experience.\nTo do this, the required Source Link NuGet package must be added to the project. There are a number of different options available, based on where the repository is hosted.\nFor a repository hosted in a Git repository in Azure Devops, a reference to Microsoft.SourceLink.AzureRepos.Git is added.\n1 2 3 4  \u0026lt;PackageReference Include=\u0026#34;Microsoft.SourceLink.AzureRepos.Git\u0026#34; Version=\u0026#34;1.1.1\u0026#34;\u0026gt; \u0026lt;PrivateAssets\u0026gt;all\u0026lt;/PrivateAssets\u0026gt; \u0026lt;IncludeAssets\u0026gt;runtime; build; native; contentfiles; analyzers; buildtransitive\u0026lt;/IncludeAssets\u0026gt; \u0026lt;/PackageReference\u0026gt;        The Source Link reference added is required only as a development dependency and is only used during the build process. This is the reason the PrivateAssets property is set to All - this prevents the package consuming applications from also needing to install Source Link as a dependency.\n    Configuring CI/CD pipeline The next step is to have the CI/CD process produce the symbols, and then upload them to the symbol server.\n  Producing the symbols\nUsually when developing locally, .pdb files are only generated when running in debug configuration, when the code is un-optimized. However, When releasing a package, it should be built in release configuration with optimized code.\nWith the relevant Source Link package reference added (Microsoft.SourceLink.AzureRepos.Git), the code can be built in release configuration and have the symbols produced. The build can either be done using:\n dotnet build:\nExecute the dotnet build command with a build configuration of Release  Azure Devops dotnet task \n Azure Devops dotnet task detail  Visual Studio build:\nExecute the Visual Studio build task with build configuration of Release, and with the MSBuild Argument of /p:SourceLinkCreate=true  Azure Devops VS build task \n Azure Devops VS build task detail     Publishing the symbols:\nThe Index sources and publish symbols task is then used to publish the symbols to either a file share, or the Azure Devops symbol server  Azure Devops publish symbol task \n Azure Devops publish symbol detail \nGenerally the publishing of artifacts would be part of the release pipeline, and not the build. However the Index sources and publish symbols task is only available in the build pipeline.\n   Consuming symbols Configuring Visual Studio The final step is to configure Visual Studio with the details on how and when to download and use the symbols. Perform the following steps in Visual Studio.\n Configure the symbol server location:  Navigate to Tools -\u0026gt; Options -\u0026gt; Debugging -\u0026gt; Symbols Click New Azure Devops Symbol Server Location Select the account, and a list of symbol servers available to the account will be displayed. Chose the server. (in the screen shot below, none are shown as the always-developing Github account is not linked to Azure Devops) Click Connect     Azure Devops symbol server \n Configure the debugger settings:\n Navigate to Tools -\u0026gt; Options -\u0026gt; Debugging Ensure that Enable Just My Code is unchecked Ensure that Enable source server support is checked   Azure Devops symbol server \n  Configure which symbols to load automatically (optional but recommended):\nBy default symbols will automatically be loaded (after being downloaded) if they are available in any of the symbol servers. If an application references a number of packages where symbols are available, start-up time when running and debugging can be dramatically negatively impacted.\nVisual Studio can be configured to only load the packages specified - or only load packages based on a wildcard (this is incredibly useful if all NuGet packages share a common namespace structure, as might be the case especially in a corporate environment)\n Navigate to Tools -\u0026gt; Options -\u0026gt; Debugging -\u0026gt; Symbols Select Load only specific modules Click Specify included modules Click New Module Add the module name, or wildcard format   Specify which modules to load \n   NuGet symbol package This post focuses on building and hosting the symbols using Azure Devops - but just a small note publishing to NuGet.org if the package is publicly available.\nThe nuget.org symbol server uses the .snupkg file format for symbols, which are optionally generated when the nupkg file is generated. See this this document on the various ways of generating a .snupkg file.\n Final thoughts That\u0026rsquo;s all there is to it! Whether a package author or package consumer, having the option to step into the code will prove invaluable - with practically no additional development effort.\nIf possible (if the source code can be made public), I highly recommend making the symbols available, to everyone\u0026rsquo;s benefit!\n References Symbol files\nPublishing symbols\nNuGet symbols (slightly outdated, but still useful)\n","date":"2022-01-04T03:00:00+02:00","permalink":"https://always-developing.github.io/p/12-2021-devops-symbol-server/","title":"Azure Devops Symbol Server - a how to guide"},{"content":"The problem Entity Framework Core is a great go-to ORM for .NET, for any type of application provides almost all the functionality required to do successful database access out the box.\nHowever, there are two use cases, specifically with regards to retrieval of data, it doesn\u0026rsquo;t cater for - this post and the accompanying code sample/NuGet package attempts to provides solutions for these use cases.\nFirst, the setup - an EF DbContext which has one DbSet, for storing Blogs (the below is a standard DbContext configuration):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class BlogContext : DbContext { public BlogContext(DbContextOptions\u0026lt;BlogContext\u0026gt; options) : base(options) { } public Action\u0026lt;DbContextOptionsBuilder\u0026gt;? BlogContextOptionsBuilder { get; set; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { base.OnConfiguring(optionsBuilder); } // The DBSet for the Blog entity  public DbSet\u0026lt;Blog\u0026gt; Blog { get; set; } } public class Blog { public Guid Id { get; set; } public string Title { get; set; } public string Owner { get; set; } public string Url { get; set; } public List\u0026lt;Post\u0026gt; Posts { get; set; } } public class Post { public Guid Id { get; set; } public string Title { get; set; } public string Content { get; set; } public int WordCount { get; set; } public Guid BlogId { get; set; } public Blog Blog { get; set; } }        The below use cases are fairly niche - in most day-to-day use cases, EF Core will do what is required out the box. The below solutions are intended to be used to enhance and work in conjunction with the normal DbContext.\nIf you find you are ONLY using the DbContext for the below use cases, it might make sense to investigate using another more suited ORM (such as Dapper).\nHowever if you are using EF Core and adding another ORM into your application doesn\u0026rsquo;t make sense, hopefully this post along with the source code + samples and NuGet package can assist you in resolving any issues.\n    DbSet is required To get a list of all Blogs, one of the following two lines of code can be used: 1 2 3  var blogs1 = context.Blog.AsNoTracking().ToList(); // OR var blogs2 = context.Set\u0026lt;Blog\u0026gt;().AsNoTracking().ToList();  \nSuppose only the Blog id and the url was required - any one of the below methods would achieve this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // Define a new type, called BlogUrl, which contains just BlogId and Url properties // Project into the new type var blogs1 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // Project into the new type using raw SQL var blogs2 = context.Set\u0026lt;Blog\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id, Url FROM Blog\u0026#34;) .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // Project into an anonymous type var blogs3 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // Project into an anonymous type using raw SQL var blogs4 = context.Set\u0026lt;Blog\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id, Url FROM Blog\u0026#34;) .Select(x =\u0026gt; new { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList();    The issue here is that EF Core requires the retrieval to be executed off a DbSet. This means an entity and matching SQL statement cannot dynamically be thrown at EF Core at runtime, and have data successfully returned.\nFor example, the following code would not work unless the BlogUrl type has been added as a DbSet to the DbContext. 1 2 3  // Does not work unless a DbSet of type BlogUrl has been added var blogs = context.Set\u0026lt;BlogUrl\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList();  \nThis problem also extends to anonymous types - as their definition is only known at runtime, a DbSet cannot be created for them before runtime.\n Support for simple types Suppose now only a list of Blog ids is required to be returned - either one of the following would work:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // Define a new type, called BlogId, which contains just Id // Project into the new type var ids1 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new BlogId { Id = x.Id }) .AsNoTracking().ToList(); // Project into a list of Ids var ids2 = context.Set\u0026lt;Blog\u0026gt;() .AsNoTracking() .Select(x =\u0026gt; x.Id).ToList(); // Project into a list of Ids using raw sql var ids3 = context.Set\u0026lt;Blog\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id FROM Blog\u0026#34;) .AsNoTracking() .Select(x =\u0026gt; x.Id).ToList();   The issue here is that the DbSet type is required to be a reference type: This means a list of simple/value types (and other identifier types such as Guid) cannot be returned directly.\nThis is related to the first issue mentioned above - a simple/value type and matching SQL statement cannot dynamically be thrown at EF Core at runtime and have data returned.\nFor example, the following code would not work. 1 2 3  // This DOES NOT WORK (yet) var ids = context.Set\u0026lt;Guid\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id FROM Blog\u0026#34;) .AsNoTracking().ToList();  \n     Both issues this post addresses involves the retrieval data - EF Core change tracking functionality will not work, and is not intended to work with the proposed solutions.\nIf change tracking is required, then the dynamic route outlines in this post should not be used. This is the reason why all example use AsNoTracking() when retrieving the data.\n    Dynamic entity results Projected entity The first issue to resolve, is the ability to populate an entity without having a Dbset added to the DbContext for the entity.\nWe cannot really get around this requirement - EF Core always need the entity be added as a DbSet, however what if it was added dynamically at runtime?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class RuntimeContext\u0026lt;T\u0026gt; : DbContext where T : class { public RuntimeContext() { } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseSqlite($\u0026#34;Data Source={Environment .GetFolderPath(Environment.SpecialFolder.MyDocuments)}\\\\BlogDatabase.db\u0026#34;); base.OnConfiguring(optionsBuilder); } protected override void OnModelCreating(ModelBuilder modelBuilder) { var t = modelBuilder.Entity\u0026lt;T\u0026gt;().HasNoKey(); foreach (var prop in typeof(T) .GetProperties(BindingFlags.Instance | BindingFlags.Public)) { if (!prop.CustomAttributes .Any(a =\u0026gt; a.AttributeType == typeof(NotMappedAttribute))) { t.Property(prop.Name); } } base.OnModelCreating(modelBuilder); } }   Here a context has been created (inherits from DbContext):\n Line 1: It takes in a generic type T Line 15-29: The model for the context is created (when the context is initialized)  Line 17: Type T is added as a DbSet to the context, but without a Key. A key is not required as this will be used only for data retrieval and with AsNoTracking. Line 18-26: Using reflection, the relevant properties of type T are added to the DbSet entity.    The following code will now work, without BlogUrl being added as a DbSet beforehand: 1 2 3  using var dynContext = new RuntimeContext\u0026lt;BlogUrl\u0026gt;(); var blogs = dynContext.Set\u0026lt;BlogUrl\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList()  \nAs this is all being setup dynamically, EF will not know how to generate the SQL for the dynamic entity - this is why raw SQL will always need to be supplied for this solution. The solution could be expanded to include this functionality in future, but this is outside the scope of this post.\nThis is now a working dynamic runtime context - however there are still a few broader issues which need to be resolved, which we\u0026rsquo;ll get to later in the post:\n Dependency Injection - There needs to be a way to configure the DI container with the dynamic runtime context when the underlying original context is configured. Dynamic Configuration: In the above, the configuration of the dynamic runtime context is hardcoded. Ideally this context would be initialized with the same configuration as the original context.   Anonymous entity As it stands, the core of the above code will work with anonymous types - just one small issue to resolve, and thats how to convert the anonymous type to T.\nTo convert the anonymous object to T, we have to inter T by example:\n1 2 3 4 5 6 7 8 9  var anon = new { BlogId = 0, Url = \u0026#34;\u0026#34; }; var blog = CallWithAnon(anon); static T CallWithAnon\u0026lt;T\u0026gt;(T example) where T: class { using var dynContext = new RuntimeContext\u0026lt;T\u0026gt;(); return dynContext.Set\u0026lt;T\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().First(); }    Line 1: Declare an example anonymous object with the relevant properties, using default values Line 2: Invoke the method just using the example object, and not specifying T Line 4-9: T is inferred from the example parameter (which is not used in the method - it is only used for the inference) and can successfully call into the dynamic runtime context   Dynamic value type results The next issue to resolve, is the ability to get a simple type or list of simple types from EF Core dynamically. The term simple type is used very loosely to refer to following types:\n Value types: int, bool, float, char etc Common Unique Identifier: Guid Simple value classes: string  As mentioned previously, EF Core requires a query be executed off a DbSet - another requirement is that the DbSet type be a reference type (a class).\nEven with the dynamic runtime context, the following code would not work as a DbSet of type Guid cannot be dynamically created (as its not a reference type): 1 2 3  // This DOES NOT WORK (yet) var blogs = dynContext.Set\u0026lt;Guid\u0026gt;().FromSqlRaw(\u0026#34;SELECT Id FROM Blog\u0026#34;) .AsNoTracking().ToList();  \nWe cannot really get around the requirement that the DbSet be a reference type - however, what can be done is to dynamically converted the simple type to a reference type, run the query and converted the results back to a simple type\nFirst lets create a reference type class, which will act as a wrapper: 1 2 3 4  public class SimpleType\u0026lt;TValue\u0026gt; { public TValue Value { get; set; } }  \nThere are no constraints on TValue, as there are no generic constraints which will work for all the types we require (value types, Guid and string).\nNow we can use this reference wrapper class, and call the dynamic runtime context: 1 2 3 4  using var dynContext = new RuntimeContext\u0026lt;SimpleType\u0026lt;Guid\u0026gt;\u0026gt;(); var id = dynContext.Set\u0026lt;SimpleType\u0026lt;Guid\u0026gt;\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().First().Value;  \nThe above will work, but we no have two more broader issues which need to be resolved:\n Still using reference type: We are still using a reference type for the DbSet and have to manually wrap the simple type and then unwrap it Column called 'Value': The column in the SQL has to be called \u0026lsquo;Value\u0026rsquo; for it to match the field on the wrapper class and successfully retrieve the data   Resolving outstanding issues Code restructure Even though we have a working dynamic runtime context, there are 4 outstanding issues to be resolved, before we have a more complete solution. First lets restructure the code a bit to make these easier to resolve.\n  Create a new class DynamicContext which accepts a generic DbContext. 1 2 3 4 5 6 7 8 9 10 11  public class DynamicContext\u0026lt;TContext\u0026gt; where TContext : DbContext { private readonly DbContext _originalContext; public DbContext Context { get { return _originalContext; } } public DynamicContext(TContext context) { _originalContext = context; } }  \n  Change RuntimeContext to accept a generic TContext of type DbContext, and make it internal instead of public. The reason for this will become more apparent as we start adding more functionality to DynamicContext. 1 2 3 4 5  internal class RuntimeContext\u0026lt;T, TContext\u0026gt; : DbContext where T : class where TContext : DbContext { // Rest of class implementation }  \n  DynamicContext will now become a wrapper and the public face of RuntimeContext and of the original DbContext - as we work through the outstanding issues below, more functionality will be added to DynamicContext to make use of RuntimeContext.\nThe four outstanding issues:\n Dependency Injection: There needs to be a way to configure the DI container with the runtime context as well as the original context Dynamic Configuration: The dynamic runtime context should use the same configuration as the original underlying DbContext Reference type wrapper: A reference type wrapper is still used for simple types, which has to manually be wrapped and unwrapped Column called 'Value': The column in the raw SQL has to be called \u0026lsquo;Value\u0026rsquo; as it has to match the field on the wrapper class   Dependency Injection As DynamicContext now takes a DbContext as a generic parameter, if a DbContext is added to the DI container DynamicContext should be added as well.\nTo do this, we\u0026rsquo;ll use extension methods which correspond to the existing .NET AddDbContext methods. For each overloaded AddDbContext method, an AddDynamicContext method will be added (an example of one of these methods): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public static IServiceCollection AddDynamicContext\u0026lt;TContext\u0026gt;( this IServiceCollection serviceCollection, Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction = null, ServiceLifetime contextLifetime = ServiceLifetime.Scoped, ServiceLifetime optionsLifetime = ServiceLifetime.Scoped) where TContext : DbContext { // Add the dynamic context for the original dbcontext  serviceCollection.AddScoped\u0026lt;DynamicContext\u0026lt;TContext\u0026gt;\u0026gt;(); // add the dbcontext using the normal AddDbContext call  return serviceCollection.AddDbContext\u0026lt;TContext, TContext\u0026gt;( optionsAction, contextLifetime, optionsLifetime ); }  \nThe method has the same parameters as the invoked AddDbContext method, and acts as a passthrough - on the way adding a record to the DI container for DynamicContext\u0026lt;T\u0026gt;.\nAn extension method is added for each variation of the AddDbContext method.\nWhen setting up the DI container, instead of calling AddDbContext, AddDynamicContext is now called. 1 2 3 4 5 6 7 8 9  // OLD .AddDbContext\u0026lt;BlogContext\u0026gt;(x =\u0026gt; x .UseSqlite($\u0026#34;Data Source={Environment .GetFolderPath(Environment.SpecialFolder.MyDocuments)}\\\\BlogDatabase.db\u0026#34;)) // NEW .AddDynamicContext\u0026lt;BlogContext\u0026gt;(x =\u0026gt; x .UseSqlite($\u0026#34;Data Source={Environment .GetFolderPath(Environment.SpecialFolder.MyDocuments)}\\\\BlogDatabase.db\u0026#34;))   \nWe can now inject DynamicContext\u0026lt;T\u0026gt; (where T is the DbContext) into the relevant constructor, and have access to the dynamic functionality provided by DynamicContext as well as access to the underlying DbContext, via the Context property.\nDependency injection taken care of!\n Dynamic Configuration Currently, the configuration of the RuntimeContext is hardcoded in the OnConfiguring method. Next let\u0026rsquo;s make it dynamic and have the same configuration as the underlying original DbContext.\nFirst, lets define a new type to store the DbContext initialization Action:\n1 2 3 4 5 6 7  public class DynamicContextInitOptions\u0026lt;TContext\u0026gt; where TContext : DbContext { Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction { get; set; } Action\u0026lt;IServiceProvider, DbContextOptionsBuilder\u0026gt; optionsActionDependencyInjection { get; set; } }   When initializing a DbContext, one of the two Actions could be used. The class can cater for both, but only one of the two will be used at any one time.\nNext, when a DbContext is added to the container (via the AddDynamicContext extension method) we\u0026rsquo;ll record how the original DbContext was initialized, and add the initialization Action to the DI container as well. A private helper method AddDynamicContent is used to configure the DI container based on the Action passed in: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  public static IServiceCollection AddDynamicContext\u0026lt;TContext\u0026gt;( this IServiceCollection serviceCollection, Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction = null, ServiceLifetime contextLifetime = ServiceLifetime.Scoped, ServiceLifetime optionsLifetime = ServiceLifetime.Scoped) where TContext : DbContext { AddDynamicContent\u0026lt;TContext\u0026gt;(serviceCollection, optionsAction); return serviceCollection.AddDbContext\u0026lt;TContext, TContext\u0026gt;( optionsAction, contextLifetime, optionsLifetime ); } private static void AddDynamicContent\u0026lt;TContext\u0026gt;( IServiceCollection serviceCollection, Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction = null, Action\u0026lt;IServiceProvider, DbContextOptionsBuilder\u0026gt; optionsActionDependencyInjection = null) where TContext : DbContext { serviceCollection.AddScoped\u0026lt;DynamicContext\u0026lt;TContext\u0026gt;\u0026gt;(); // If no action, then it would need to be added manually  if(optionsAction == null \u0026amp;\u0026amp; optionsActionDependencyInjection == null) { return; } // Create an options instance with the Action populated.  // One of the two will always be null  var options = new DynamicContextInitOptions\u0026lt;TContext\u0026gt; { optionsAction = optionsAction, optionsActionDependencyInjection = optionsActionDependencyInjection }; // add the type to the DI container  serviceCollection.AddSingleton(typeof(options); }  \nFor a specific DbContext, we now know how it was initialized. So if we inject DynamicContextInitOptions\u0026lt;TContext\u0026gt; into DynamicContext and then into RuntimeContext, it can be used to initialized dynamically.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  internal class RuntimeContext\u0026lt;T\u0026gt; : DbContext where T : class { private readonly DynamicContextInitOptions\u0026lt;DbContext\u0026gt; _contextInitAction; private readonly IServiceProvider _serviceProvider; public RuntimeContext( DynamicContextInitOptions\u0026lt;DbContext\u0026gt; contextInitAction, IServiceProvider serviceProvider) { _contextInitAction = contextInitAction; _serviceProvider = serviceProvider; } protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { // init the context based on how the initial TContext was initially initialized  if (_contextInitAction.optionsAction != null) { _contextInitAction.optionsAction.Invoke(optionsBuilder); } else { _contextInitAction .optionsActionDependencyInjection .Invoke(_serviceProvider, optionsBuilder); } base.OnConfiguring(optionsBuilder); } // Class continues... }   We can now inject a DynamicContext into a relevant constructor, have access to dynamic functionality as well as the underlying original DbContext, and we can dynamically initialized the dynamic context based on how the underlying original context was initialized.\nDynamic configuration taken care of!\n DynamicContext wrapper Next we\u0026rsquo;ll add a few methods to the wrapper DynamicContext to provide access to the internal RuntimeContext, as well as making using the reference type wrapper, SimpleType\u0026lt;T\u0026gt; easier.\n  First a method to add a DbSet dynamically based on the generic entity TEntity: 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public DbSet\u0026lt;TEntity\u0026gt; Set\u0026lt;TEntity\u0026gt;() where TEntity : class { // if the type is on the original context,  // then don\u0026#39;t initialize the dynamic context  if (_originalContext.Model.FindEntityType(typeof(TEntity)) != null) { return _originalContext.Set\u0026lt;TEntity\u0026gt;(); } var runtimeContext = new RuntimeContext\u0026lt;TEntity\u0026gt;( _runtimeInitAction, _serviceProvider); return runtimeContext.Set\u0026lt;TEntity\u0026gt;(); }  \nTo invoke this method: 1 2 3  var blogs = dynamicContext.Set\u0026lt;BlogUrl\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList()  \n  Next, a method to add DbSet dynamically based on an anonymous object: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public DbSet\u0026lt;TEntity\u0026gt; Set\u0026lt;TEntity\u0026gt;(TEntity example) where TEntity : class { _ = example; // if the type is on the original context,  // then don\u0026#39;t initialize the dynamic context  if (_originalContext.Model.FindEntityType(typeof(TEntity)) != null) { return _originalContext.Set\u0026lt;TEntity\u0026gt;(); } var runtimeContext = new RuntimeContext\u0026lt;TEntity\u0026gt;( _runtimeInitAction, _serviceProvider); return runtimeContext.Set\u0026lt;TEntity\u0026gt;(); }  \nTo invoke this method: 1 2 3 4  var anonBlogUrl = new { BlogId = 0, Url = \u0026#34;\u0026#34; }; var blogs = dynamicContext.Set(anonBlogUrl) .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList();  \n  Next, a method to wrap the explicit SimpleType\u0026lt;T\u0026gt; usage. With this method SimpleType\u0026lt;T\u0026gt; does not need to be used explicitly: 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public DbSet\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt; ValueSet\u0026lt;TEntity\u0026gt;() where TEntity : struct { // as the constraint is on struct, we have this additional check  // just to make sure its a struct of a relevant type  // (int, long, float, bool etc)  if(!IsValidType(typeof(TEntity))) { throw new InvalidOperationException( $\u0026#34;Type \u0026#39;{typeof(TEntity).Name}\u0026#39; is not supported\u0026#34;); } var runtimeContext = GetInternalRuntimeContext(new SimpleType\u0026lt;TEntity\u0026gt;()); return runtimeContext.Set\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt;(); }  \nTo invoke this method: 1 2 3  var blogIds = dynamicContext.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList();  \n  Lastly, as string is not a struct, it has to be handled separately: 1 2 3 4 5 6 7  public DbSet\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt; StringSet\u0026lt;TEntity\u0026gt;() where TEntity : IEnumerable\u0026lt;char\u0026gt;, IEnumerable, ICloneable, IComparable, IComparable\u0026lt;string\u0026gt;, IConvertible, IEquatable\u0026lt;string\u0026gt; { var runtimeContext = GetInternalRuntimeContext(new SimpleType\u0026lt;TEntity\u0026gt;()); return runtimeContext.Set\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt;(); }  \nTo invoke this method: 1 2 3  var urls = context.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList();  \n  We can have user friendly methods which are similar to the DbContext Set methods, and which wrap some of the annoyance of having to use SimpleType\u0026lt;T\u0026gt; explicitly.\nSimple value usage taken care of!\n Value column The last issue to resolve is the fact that the Set\u0026lt;\u0026gt; methods for simple types (struct and string) return a DbSet of SimpleType object and not the simple type value itself.\nOne option, is to explicitly select the value out the IQueryable, as seen in line 4 below: 1 2 3 4 5  var urls = context.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking() .Select(x =\u0026gt; x.Value) .ToList();  \nThe other option is to add some extension methods to easily unpack the SimpleType\u0026lt;T\u0026gt; into the T: 1 2 3 4 5 6 7 8 9 10 11 12  public static IQueryable\u0026lt;TEntity\u0026gt; ToSimple\u0026lt;TEntity\u0026gt;( this IQueryable\u0026lt;SimpleType\u0026lt;TEntity\u0026gt;\u0026gt; query) where TEntity : struct, IComparable, IFormattable, IComparable\u0026lt;TEntity\u0026gt;, IEquatable\u0026lt;TEntity\u0026gt; { return query.Select(entity =\u0026gt; entity.Value).AsQueryable(); } public static IQueryable\u0026lt;string\u0026gt; ToSimple(this IQueryable\u0026lt;SimpleType\u0026lt;string\u0026gt;\u0026gt; query) { return query.Select(entity =\u0026gt; entity.Value).AsQueryable(); }  \nTo invoke this method: 1 2 3 4 5  var blogIds = context.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking() .ToSimple() .ToList();  \n     The solution still requires that the SQL command have a column returned with the name of \u0026lsquo;Value\u0026rsquo;. With some additional effort, this constraint could be resolved , but this is outside the scope of this post.\n   Value column partially taken care of!\n Nuget Package All the above functionality has been packed into a NuGet package which is ready to use, and is available here.\nFull source code is also available on GitHub here\n Performance benchmarks Some performance benchmarks of using the DynamicContext vs DbContext directly and projecting the values out (using .NET 6, EF Core 6 and Sqlite)\nThe first set of results benchmark retrieving a list of ids and urls from a database of 500 records, then 100 000 records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  // DirectDbSet var blogs = context.Blog.AsNoTracking().ToList(); // GenericDbSet var blogs1 = context.Set\u0026lt;Blog\u0026gt;().AsNoTracking().ToList(); // GenericDbSetRaw var blogs2 = context.Set\u0026lt;Blog\u0026gt;() .FromSqlRaw(\u0026#34;SELECT * FROM Blog\u0026#34;).AsNoTracking().ToList(); // GenericDbSetProj var blogs3 = context.Set\u0026lt;Blog\u0026gt;() .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // GenericDbSetRawProj var blogs4 = context.Set\u0026lt;Blog\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id, Url FROM Blog\u0026#34;) .Select(x =\u0026gt; new BlogUrl { BlogId = x.Id, Url = x.Url }) .AsNoTracking().ToList(); // DynamicDbSet var blogs5 = dynamicContext.Set\u0026lt;BlogUrl\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList(); // DynamicDbSetAnon var anonBlogUrl = new { BlogId = 0, Url = \u0026#34;\u0026#34; }; var blogs6 = dynamicContext.Set(anonBlogUrl) .FromSqlRaw(\u0026#34;SELECT Id as BlogId, Url FROM Blog\u0026#34;) .AsNoTracking().ToList();  \n500 records:\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Allocated     DirectDbSet 1,049.3 us 10.66 us 9.97 us 1.00 76.1719 25.3906 477 KB   GenericDbSet 1,054.4 us 12.71 us 11.89 us 1.00 76.1719 25.3906 477 KB   GenericDbSetRaw 1,070.9 us 18.19 us 16.12 us 1.02 78.1250 25.3906 481 KB   GenericDbSetProj 638.2 us 9.48 us 8.87 us 0.61 47.8516 12.6953 296 KB   GenericDbSetRawProj 661.1 us 3.98 us 3.53 us 0.63 48.8281 14.6484 302 KB   DynamicDbSet 696.8 us 3.22 us 2.69 us 0.66 54.6875 14.6484 338 KB   DynamicDbSetAnon 605.2 us 5.51 us 5.15 us 0.58 45.8984 13.6719 287 KB    100 000 records (Gen 0, 1 and 2 decimals truncated for space reasons):\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Gen 2 Allocated     DirectDbSet 268.5 ms 2.02 ms 1.89 ms 1.00 15000.00 5000.00 2000.00 81 MB   GenericDbSet 268.6 ms 2.47 ms 2.19 ms 1.00 15000.00 5000.00 2000.00 81 MB   GenericDbSetRaw 267.9 ms 3.11 ms 2.91 ms 1.00 15000.00 5000.00 2000.00 81 MB   GenericDbSetProj 143.8 ms 2.60 ms 3.09 ms 0.54 8250.00 3000.00 1000.00 46 MB   GenericDbSetRawProj 140.8 ms 2.76 ms 3.06 ms 0.52 8250.00 3000.00 1000.00 46 MB   DynamicDbSet 143.9 ms 2.11 ms 1.97 ms 0.54 8250.00 3000.00 1000.00 46 MB   DynamicDbSetAnon 118.1 ms 2.28 ms 2.02 ms 0.44 6400.00 2400.00 1000.00 36 MB    As expected, projecting the required fields out, is faster and requires less memory than retrieving all the data. Using the DynamicContext is comparable to projecting the specific values out - the overhead of dynamically creating the DynamicContext is negligible.\n The next set of results benchmark retrieving a list of simple types (Guid) from a database of 500 records, then 100 000 records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  // DirectDbSet var blogIds = context.Set\u0026lt;Blog\u0026gt;() .AsNoTracking().Select(x =\u0026gt; x.Id).ToList(); // ValueSetSelect var blogIds1 = dynamicContext.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList(); // ValueSetToSimple var blogIds2 = dynamicContext.ValueSet\u0026lt;Guid\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Id as Value FROM Blog\u0026#34;) .AsNoTracking().ToSimple().ToList(); // DirectDbSetString var urls = context.Set\u0026lt;Blog\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Url).ToList(); // StringSetSelect var urls1 = dynamicContext.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking().Select(x =\u0026gt; x.Value).ToList(); // StringSetToSimple var urls2 = dynamicContext.StringSet\u0026lt;string\u0026gt;() .FromSqlRaw(\u0026#34;SELECT Url as Value FROM Blog\u0026#34;) .AsNoTracking().ToSimple().ToList();  \n500 records:\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Allocated     DirectDbSet 864.1 us 38.04 us 111.55 us 1.00 - - 226 KB   ValueSetSelect 439.1 us 8.32 us 14.12 us 0.52 37.1094 8.7891 233 KB   ValueSetToSimple 435.7 us 7.98 us 8.20 us 0.51 37.1094 6.8359 232 KB   DirectDbSetString 610.5 us 12.65 us 14.06 us 0.71 38.0859 1.9531 233 KB   StringSetSelect 437.9 us 8.53 us 11.67 us 0.50 39.0625 10.7422 240 KB   StringSetToSimple 439.3 us 8.56 us 12.28 us 0.51 39.0625 9.7656 240 KB    100 000 records (Gen 0, 1 and 2 decimals truncated for space reasons):\n   Method Mean Error StdDev Ratio Gen 0 Gen 1 Gen 2 Allocated     DirectDbSet 58.67 ms 1.167 ms 2.276 ms 1.00 4000.00 1000.00 1000.00 32 MB   ValueSetSelect 54.48 ms 1.058 ms 1.132 ms 0.91 5500.00 1100.00 1000.00 32 MB   ValueSetToSimple 51.66 ms 0.399 ms 0.354 ms 0.86 5444.44 1111.11 1000.00 32 MB   DirectDbSetString 81.04 ms 1.153 ms 0.963 ms 1.00 6000.00 2000.00 1000.00 33 MB   StringSetSelect 92.20 ms 1.359 ms 1.271 ms 1.14 5666.67 2000.00 833.33 33 MB   StringSetToSimple 92.26 ms 1.789 ms 1.915 ms 1.14 5666.67 2000.00 833.33 33 MB    For the non-string values, using DynamicContext is faster, while using roughly the same memory, especially with more records. For string values DynamicContext is slower - but with the tradeoff of it being more dynamic.\n Closing The post outlines solutions to be able to:\n Retrieve data into an entity (or collection of entities) without a DbSet, using raw SQL Retrieve data into an entity or collection of entities) based on an anonymous object, using raw SQL Retrieve data into a simple type without having to define a reference type to use as a DbSet  The performance of the library is either faster or comparable to using a DbContext, but as always, test and benchmark and make an informed decision in your specific use case.\nFull source code available on Github and fully functionality package available on NuGet.\n","date":"2021-12-11T03:00:00+02:00","permalink":"https://always-developing.github.io/p/11-2020-dynamic-context/","title":"Dynamic Context (for Entity Framework Core)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks (this post)\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nTips and tricks This post contains a list of tips and tricks, work-around\u0026rsquo;s and other bits of (what I find) useful information to aid in developing analyzers.\n Analyzer tips and tricks Compatibility If an analyzer is created in Visual Studio 2019 using the Analyzer with Code Fix project - it will not be initially compatible with Visual Stdio 2022 (or visa versa).\nThe actual analyzer and code fix code itself is compatible (as its .NET Standard 2.0), however the VSIX project is not compatible\n Default Microsoft.VSSDK.BuildTools reference \nTo have the VSIX project work in Visual Studio 2022, the Microsoft.VSSDK.BuildTools reference needs to be updated to version 17. However doing so will mean it will no longer be supported in Visual Studio 2019.\nTo have the analyzer work in both Visual Studio 2019 and Visual Studio 2022, two VSIX projects need to be created in the solution. One will be for Visual Studio 2019 and have a Microsoft.VSSDK.BuildTools reference of version 15 or 16, and the other for Visual Studio 2022 with a Microsoft.VSSDK.BuildTools reference of 17.\n Visual Studio support \n Syntax tree Sometimes when using the Syntax Visualizer, detailed in the section Writing an analyzer - interrogate the syntax tree, the tree in the Syntax Visualizer windows stops refreshing when selecting items in the code, and will appear blank.\nTo force a refresh of the window, make a small code change - for example, add a remove a semi-colon in code. This will force the window to refresh and the syntax tree will appear and refresh correctly (until the next time it stops working).\n Additional files While an analyzer can inspect non-code files (such as the appsettings.json in the sample), these \u0026ldquo;additional files\u0026rdquo; are not included as part of the Roslyn checks by default. A file has to specifically be marked as an additional file for Roslyn to be able to work with it.\nThis is done by specifying the files Build Action to be C# analyzer additional file on the file\u0026rsquo;s Properties window in Visual Studio.\n Appsettings.json build action \nWhen an analyzer is dependent on the additional file being present, as is the case in the sample analyzer, then a diagnostic can be raised if the additional file cannot be found.\nIn the below example, the ADEF002 diagnostic is raised if the appsettings.json hasn\u0026rsquo;t been included as an additional file - if it doesn\u0026rsquo;t have a build action of C# analyzer additional file.\n1 2 3 4 5 6 7 8 9 10  // if there is no file to query, then report a diagnostic if (context.Options.AdditionalFiles == null || !context.Options.AdditionalFiles.Any(x =\u0026gt; x.Path .EndsWith(\u0026#34;appsettings.json\u0026#34;, StringComparison.OrdinalIgnoreCase))) { var diagnostic002 = Diagnostic.Create(rule002, Location.None); context.ReportDiagnostic(diagnostic002); return; }    Code fix tips and tricks Modify non-code While it is possible to have an analyzer inspect non-code files (such as the appsettings.json in the sample), it is not possible to have the code fix modify these files. The code fix is only able to modify the syntax tree, which a non-code file will obviously not have.\nA solution to this is the demonstrated in the sample analyzer. Diagnostic ADEF003 ensures that the connection string name specified in code exists in the appsettings.json file. As an analyzer can inspect the json file, it is successfully able to trigger the diagnostic, however the associated code fix is unable to modify the json.\nInstead, a comment snippet is inserted above the offending code block, with the correct json, and a message informing the developer what to do with it.\nIn the below example, no connection string called SampleDatabase was present in the appsettings.json, so a diagnostic was triggered.\nBefore code fix has been applied: 1 2 3 4  .ConfigureServices((context, services) =\u0026gt; services .AddDbContext\u0026lt;SampleContext\u0026gt;(x =\u0026gt; x .UseSqlite(context.Configuration.GetConnectionString(\u0026#34;SampleDatabase\u0026#34;))) ).Build();  \nAfter code fix has been applied: 1 2 3 4 5 6 7 8 9 10 11  .ConfigureServices((context, services) =\u0026gt; services /* Ensure the below JSON snippet exists in appsettings.json. { \u0026#34;ConnectionStrings\u0026#34;: { \u0026#34;SampleDatabase\u0026#34;: \u0026#34;Data Source=LocalDatabase.db\u0026#34; } } */ .AddDbContext\u0026lt;SampleContext\u0026gt;(x =\u0026gt; x .UseSqlite(context.Configuration.GetConnectionString(\u0026#34;SampleDatabase\u0026#34;))) ).Build();  \nThis code fix however does not fully resolve the diagnostic. Only once the json snippet has been manually copied in the appsettings.json file by the developer will the analyzer stop reporting the diagnostic.\n Unit test tips and tricks VSIX debugging Using the VSIX project, which is part of the analyzer template, is a critical tool to test and debug an analyzer, and see how it performs in an Visual Studio instance (vs running units tests to ensure the functionality is correct). However occasionally when running the VSIX project, the updated version of the analyzer does get installed/loaded into the debugging Visual Studio instance.\nPerforming one of these two options usually resolves the issue:\n  Explicitly build/rebuild each project in the analyzer solution before running the analyzer VSIX project.\n  Delete the cache for the debug Visual Studio instance. The cache is stored in the user folder: C:\\Users\\username\\AppData\\Local\\Microsoft\\VisualStudio\\xxxxRoslyn.\nDeleting this cache will removing any settings, cache for the debug Visual Studio instance, and the next time its opened it will be as if it was the first time, and the updated version of the extension will be installed for the \u0026ldquo;first time\u0026rdquo;.\n   Series Finale The series of posts have hopefully given enough base information to give a basic understand of what an analyzer and code fix are, what the various components are and how they fit together, and how they can successfully be tested using a number of methods.\nThe source code for full working analyzer and code fix, as well as the sample application is all available on Github.\n","date":"2021-11-28T05:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-extra/","title":"Roslyn Analyzer - tips and tricks (Part 5)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix (this post)\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nAnalyzer unit test introduction The previous posts in the series detail how to write an analyzer and code fix.\nThis post details writing unit tests to help ensure the stability of the code, but also aid in the development process by providing a quick and easy way to debug and test the analyzer and code fix.\n Why write unit tests? Analyzers are not simple to test - to \u0026ldquo;run\u0026rdquo; an analyzer, a new instance of Visual Studio starts up with the analyzer installed as an extension. An application (which has the code needed to test the analyzer) then needs to be opened to cause the analyzer trigger.\nWhile this definitely has a place when testing (hence the suggestion of creating a sample application for the analyzer), this process to often be inconsistent, with the updated analyzer not always being installed in the new instance of Visual Studio, or the breakpoints in the analyzer not being hit.\nUnit tests provide a convenient and comparatively quick way to debug and iterate while coding the analyzer and code fix.\nLuckily, writing unit tests are fairly straight forward. In addition a test framework is available for the testing of analyzers and code fixes.\n Default unit tests Wrapper classes As part of the analyzer template, a unit test project is automatically created.\nThis template has:\n A sample analyzer test, using the a VerifyCS.VerifyAnalyzerAsync method A sample verify code fix test, using a VerifyCS.VerifyCodeFixAsync method  The VerifyCS class is an auto-generated class, which wraps a lot of the complexity of the underlying testing framework classes - while this is great when first working with analyzers and is easy to use for simple use cases, more complex use cases require more configuration and its generally easier to just use the underlying wrapped classes directly.\nUsing the VerifyCS class to test an analyzer is straightforward though:\n Define a block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Call VerifyCS.VerifyAnalyzerAsync()  1 2 3 4 5 6 7 8 9  //No diagnostics expected to show up [TestMethod] public async Task TestMethod1() { var test = @\u0026#34;\u0026#34;; // No code, so no diagnostic will be triggered  await VerifyCS.VerifyAnalyzerAsync(test); }   Using the VerifyCS class to test a code fix:\n Define a initial state block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Define a final state block of code as a string (what the code would look like after the code fix has been applied) Call VerifyCS.VerifyCodeFixAsync()  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  //Diagnostic and CodeFix both triggered and checked for [TestMethod] public async Task TestMethod2() { // define the initial code block  var test = @\u0026#34; using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using System.Diagnostics; namespace ConsoleApplication1 { class {|#0:TypeName|} { } }\u0026#34;; // define the final state code block  var fixtest = @\u0026#34; using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using System.Diagnostics; namespace ConsoleApplication1 { class TYPENAME { } }\u0026#34;; // Expected diagnostics to be triggered  var expected = VerifyCS.Diagnostic(\u0026#34;Analyzer1\u0026#34;) .WithLocation(0).WithArguments(\u0026#34;TypeName\u0026#34;); // Verify the diagnostic will be triggered,  // and that the code fix applies successfully  await VerifyCS.VerifyCodeFixAsync(test, expected, fixtest); }    Complex use cases There are a few use cases where I\u0026rsquo;ve found NOT using VerifyCS easier (although it is still possible to use it):\n If the code block requires external dependencies to compile (such as a NuGet package) If the code block is using some of the .NET 6 features (such as the minimal startup with the implicit main method) If the analyzer requires additional files, such as an appsettings.json file. If the build config (or any preprocessor symbol) makes a different to the analyzer  For these reasons, I generally do not use VerifyCS, but use the underlying framework classes directly instead.\n Enhanced unit tests The steps for using the framework classes directly (CSharpAnalyzerTest) are similar to using the wrapper class:\nUsing the CSharpAnalyzerTest class to test an analyzer:\n Define a block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Define any additional configuration Call RunAsync()  To test a code fix using CSharpCodeFixTest:\n Define a initial state block of code as a string Define the list of diagnostic result the code should produce (and the location in the code) Define a final state block of code as a string (what the code would look like after the code fix has been applied) Define any additional configuration for both the initial and final state Call RunAsync()  Lets go through these steps in details in the next sections.\n Defining the code Analyzer test code Although the analyzer and code fix test use different test classes, the setup is very similar.\nWith the configuration for an analyzer, the TestState is set - the sourceCode variable is a string with C# code as text. 1 2 3 4 5 6 7  var analyzerTest = new CSharpAnalyzerTest\u0026lt;DevOnlyMigrateAnalyzer, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode } } };  \nCode fix test code With the configuration for a code fix, the TestState is set, as well as the source code for the expected FinalState. The final state is the expected code after the code fix has been applied. Again, both sourceCode and fixedCode are C# code as text. 1 2 3 4 5 6 7 8 9 10 11 12  var analyzerFix = new CSharpCodeFixTest\u0026lt;DevOnlyMigrateAnalyzer, DevOnlyMigrateCodeFixProvider, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode } }, FixedState = { Sources = { fixCode } } };  \n Defining the diagnostics Next up is to define the diagnostics we expect the code to trigger.\nAnalyzer diagnostics With an analyzer test, the diagnostic id, severity and location of the expected diagnostics is specified: 1 2 3 4 5  analyzerTest.ExpectedDiagnostics.Add( new DiagnosticResult( \u0026#34;ADEF001\u0026#34;, Microsoft.CodeAnalysis.DiagnosticSeverity.Warning ).WithLocation(18, 27));  \nCode fix diagnostics With a code fix, if the expectation is that there will still be diagnostics after the code fix has been applied, the ExpectedDiagnostics is set on the FixedState: 1 2 3 4 5  analyzerFix.FixedState.ExpectedDiagnostics.Add( new DiagnosticResult( \u0026#34;ADEF001\u0026#34;, Microsoft.CodeAnalysis.DiagnosticSeverity.Warning ).WithLocation(18, 27));  \nNo or multiple expected diagnostics can be specified.\n Additional configuration .NET6.0 support If the sourceCode (a string representation of C# code) contains any features specific to .NET6.0 (such as the no longer required Main method), the setup below needs to be done.\nThis specifies to the testing framework to include the additional package as part of the code when executing the analyzer: 1 2 3 4 5 6 7 8 9 10 11 12 13  var analyzerTest = new CSharpAnalyzerTest\u0026lt;ConfigConnectionStringAnalyzer, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode }, ReferenceAssemblies = new ReferenceAssemblies( \u0026#34;net6.0\u0026#34;, new PackageIdentity( \u0026#34;Microsoft.NETCore.App.Ref\u0026#34;, \u0026#34;6.0.0\u0026#34;), Path.Combine(\u0026#34;ref\u0026#34;, \u0026#34;net6.0\u0026#34;)) } };  \nFor a code fix test, the same needs to be applied to the FinalState if it makes use of the same .NET6.0 specific functionality.\nNuget Packages Sometimes additional packages are required for the sourceCode to successfully compile. In the sample code, for example, the EntityFramework Core references.\nThe required package names and version are specified and then added to the TestState. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // include any nuget packages to reduce the number of errors var packages = new[] { new PackageIdentity(\u0026#34;Microsoft.Extensions.Hosting\u0026#34;, \u0026#34;6.0.0\u0026#34;), new PackageIdentity(\u0026#34;Microsoft.Extensions.Configuration\u0026#34;, \u0026#34;6.0.0\u0026#34;), new PackageIdentity(\u0026#34;Microsoft.EntityFrameworkCore\u0026#34;, \u0026#34;6.0.0\u0026#34;), new PackageIdentity(\u0026#34;Microsoft.EntityFrameworkCore.Sqlite\u0026#34;, \u0026#34;6.0.0\u0026#34;) } .ToImmutableArray(); var analyzerTest = new CSharpAnalyzerTest\u0026lt;DevOnlyMigrateAnalyzer, MSTestVerifier\u0026gt; { TestState = { Sources = { sourceCode }, ReferenceAssemblies = new ReferenceAssemblies( \u0026#34;net6.0\u0026#34;, new PackageIdentity( \u0026#34;Microsoft.NETCore.App.Ref\u0026#34;, \u0026#34;6.0.0\u0026#34;), Path.Combine(\u0026#34;ref\u0026#34;, \u0026#34;net6.0\u0026#34;)) .AddPackages(packages) } };  \n     Adding the packages to the tests is NOT required - if not added, the code simply wont compile, with the error: The type or namespace name \u0026lsquo;XXX\u0026rsquo; does not exist in the namespace \u0026hellip;\nThese errors could be added to the ExpectedDiagnostics collection and as the test now expects these to occur, the test will pass.\nHowever the easier and more complete solution, is to rather just add the required packages instead of trying to cater for diagnostics not related to the analyzer or code fix being tested.\n   Additional files Sometimes an analyzer will require additional files to successfully perform its function - such as checking the contents of the appsettings.json. To successfully be able to test this, additional files (names, and content) can be configured as part of the test.\nThis is done on the TestState or FixedState:\nIn the below sample, an additional file called appsettings.json, with empty json contents, is added to the test state.\n1 2  analyzerTest.TestState .AdditionalFiles.Add((\u0026#34;appsettings.json\u0026#34;, \u0026#34;{}\u0026#34;));   Build configuration In some use cases, such as one in the sample, the build configuration of the project makes a difference to how the analyzer performs.\nTo specify the build configuration, or any preprocessor symbols, the following is used:\n1 2 3 4 5 6  analyzerTest.SolutionTransforms.Add((s, p) =\u0026gt; { return s.WithProjectParseOptions(p, new CSharpParseOptions() .WithPreprocessorSymbols(\u0026#34;DEBUG\u0026#34;)); });    Next steps: Tips and tricks The next and final part in the series will provider some collection of tips and tricks collected while working with analyzers.\nUseful links Roslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-27T04:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-test/","title":"Roslyn Analyzer - testing an analyzer and code fix (Part 4)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix (this post)\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nCode fix introduction As detailed in the previous post in the series, now that there is a working analyzer which accurately reports diagnostic information to Roslyn, the next step is to write the code fix to resolve the diagnostic.\nNot all analyzers will have a code fix - the resolution might be out of the scope of Roslyn to resolve, in which case the diagnostic should info the developer how to resolve the report.\n Coding the code fix Code fix setup First step is to configure the code fix so it applies to a specific diagnostic (or multiple diagnostics)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [ExportCodeFixProvider(LanguageNames.CSharp, Name = nameof(DevOnlyMigrateCodeFixProvider)), Shared] public class DevOnlyMigrateCodeFixProvider : CodeFixProvider { public sealed override ImmutableArray\u0026lt;string\u0026gt; FixableDiagnosticIds { get { return ImmutableArray.Create(DevOnlyMigrateAnalyzer.DiagnosticId); } } public sealed override FixAllProvider GetFixAllProvider() { return WellKnownFixAllProviders.BatchFixer; } . . . }    Line 3: The class must inherit from CodeFixProvider Line 5-8: The overridden FixableDiagnosticIds returns a list of the diagnostic ids this code fix will resolve   Register the code fix The next step is to register the code fix with Roslyn - this is done by overriding the RegisterCodeFixesAsync method.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public sealed override async Task RegisterCodeFixesAsync(CodeFixContext context) { var root = await context.Document.GetSyntaxRootAsync(context.CancellationToken) .ConfigureAwait(false); var diagnostic = context.Diagnostics.First(); var diagnosticSpan = diagnostic.Location.SourceSpan; var declaration = root.FindToken(diagnosticSpan.Start).Parent. AncestorsAndSelf().OfType\u0026lt;InvocationExpressionSyntax\u0026gt;().First(); // Register a code action that will invoke the fix.  context.RegisterCodeFix( CodeAction.Create( equivalenceKey: DevOnlyMigrateAnalyzer.DiagnosticId, title: \u0026#34;Surround with correct #if directive\u0026#34;, createChangedDocument: c =\u0026gt; InsertIfDirectiveAsync(context.Document, declaration, c)), diagnostic); }    Lines 3-4: Gets the entire syntax tree from the context Lines 6-7: Get the first diagnostic reported, and get its Span (the location within the root syntax tree) Lines 9-10: Find the syntax node at the location of the diagnostic Lines 13-19: Register the code fix:  Line 15: Register the specific diagnostic id Line 16: The text which appears in the quick action menu Lines 17-19: The method to call which will handle altering the document     Alter the syntax tree A code fix consists of taking the original document (which contains the full context tree), modifying various nodes in the tree to reflect how the fixed code should look, and then returning the updated document.\nFor the sample analyzer, this is done in InsertIfDirectiveAsync, the method registered in the previous step:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  private async Task\u0026lt;Document\u0026gt; InsertIfDirectiveAsync(Document document, InvocationExpressionSyntax invocationExpr, CancellationToken cancellationToken) { var memberAccessExpr = invocationExpr.Expression as MemberAccessExpressionSyntax; var originalRoot = await document.GetSyntaxRootAsync(cancellationToken); var statement = GetStatement(invocationExpr); // get the closest If directive  var closestIfDirective = CodeAnalysisHelper.GetClosestIfDirective(memberAccessExpr, originalRoot); // if there was one  if (closestIfDirective != null) { // work out the replacement directive and replace  var replacementIfDirective = SyntaxFactory.IfDirectiveTrivia( SyntaxFactory.ParseExpression($\u0026#34; DEBUG{Environment.NewLine}\u0026#34;), true, true, true); var replacementIfDirectiveList = SyntaxFactory.TriviaList(new SyntaxTrivia[] { SyntaxFactory.Trivia(replacementIfDirective) }); var ifDirectiveNode = statement.FindNode(closestIfDirective.Value.Span); if(ifDirectiveNode != null \u0026amp;\u0026amp; ifDirectiveNode.HasLeadingTrivia) { var newIfDirectiveNode = ifDirectiveNode .WithLeadingTrivia(replacementIfDirectiveList); var newReplacementStatement = statement .ReplaceNode(ifDirectiveNode, newIfDirectiveNode); var newReplacementRoot = originalRoot .ReplaceNode(statement, newReplacementStatement); return document.WithSyntaxRoot(newReplacementRoot); } return document; } // this branch is if there is no directive  var statementWithDirective = InsertNewIfDirective(statement); var newRootWithEndDirective = originalRoot .ReplaceNode(statement, statementWithDirective); return document.WithSyntaxRoot(newRootWithEndDirective); }    Lines 1-2: The parameters to the method are the full Document, as well as the specific syntax which triggered the diagnostic Line 6: A helper method is called to get the code statement which invocationExpr (Migrate method call) is part of.\nThe statement is the larger code block containing the invocationExpr : _context?.Database.Migrate() Lines 9-10: A helper method is called to get the closest #if directive which occurs before the invocationExpr location Lines 13-39: This handles replacing the existing #if directive with a version which has the correct condition  Lines 16-23: Builds the replacement trivia: #if DEBUG Line 25: Find the existing trivia in the statement node Lines 29-34: Replaces the text in the #if directive, then replaced the directive in the statement with the new directive, then replaced the statement in the root with the new statement Lines 36: Return the document with the new syntax root   Lines 43-47: This handles inserting a new #if directive into the statement (InsertNewIfDirective method), and then returns the document with the newly inserted directive.   Applying the code fix Nothing more is required - Visual Studio and Roslyn will automatically call the code fix method to:\n Give a preview of the fix being applied when the cursor is held over the quick action menu item. Apply the fix when the quick action menu item is clicked.   The code fix preview \n Next steps: Testing the analyzer and code fix Next up, part 4 in the series will detail how to test the custom analyzer and associated code fix. This includes information on using the analyzer unit tests infrastructure to assist with development, as well as using the VSIX project.\nUseful links Roslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-26T03:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-code-fix/","title":"Roslyn Analyzer - writing the code fix (Part 3)"},{"content":"All posts in the series:\nPart 1: Roslyn Analyzer - explained Part 2: Roslyn Analyzer - writing an analyzer (this post)\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nAnalyzer introduction To recap from the previous post in the series, an analyzer is a piece of code which inspects code (C# or Visual Basic) during design and compile time, and based on the results of the inspection, can trigger a diagnostic as an Error, Warning or as Information.\nThis post will detail the various parts of the analyzer, how they fit together, and then explore creating a custom analyzer.\n     While the samples used in these posts and in the associated Github repository are working and practical, the code is NOT optimized, and also does not cater for all use cases scenarios and edge cases.\nThe code should be used as a guide for writing a custom analyzer and code fix and not as-is for production use.\n    Analyzer solution Creating an analyzer project Creating the initial analyzer project is very simple - Visual Studio has a template for it!\nWhen creating a new project in Visual Studio, search for analyzer and select the C# Analyzer with Code Fix (.NET Standard) template.\n C# Analyzer with Code Fix (.NET Standard) project \nIf the project doesn\u0026rsquo;t appear in the list, the .NET Compiler Platform SDK workload is most likely not installed. Modify the Visual Studio installation to confirm and install if required.\n .NET Compiler Platform SDK selection \n     The various analyzer projects will be created with the target framework of .NET Standard 2.0 for the analyzer specific projects, and .NET Framework 4.7.2 for the VSIX project.\nThese should remain as is - as Visual Studio was written using .NET Framework, extensions are required to target .NET Standard 2.0 and currently cannot target any later framework.\n    Structure of the solution The default analyzer template will create 5 projects as part of the solution (in the order as they appear in the screenshot below):\n A project which contains the analyzer code A project which contains the code fix code A project used to create a NuGet package for the analyzer A test project containing unit test (which is also invaluable for debugging while developing) A VSIX project which creates the Visual Studio extension (also invaluable for testing while developing)   Structure of an analyzer solution (sample folder added manually) \n The analyzer A sample application Before starting to code the analyzer, a very strong suggestion is to create a small sample application which contains the scenario to trigger the analyzer. This will be very useful when testing, as well as crucial when working out the syntax tree of the code (more on this below).\nThis sample project does not have to be at all complicated - the sample project (available on Github) just creates a connection to a Sqlite database, and applies a database migration. No other logic.\nPersonally I prefer to add the sample to my analyzer solution (useful when using the Syntax Visualizer), but then also create a separate solution which just contains just the sample project (useful when testing the analyzer as an extension).\nSee part 1 for a more in depth breakdown of the the scenarios the custom analyzers are reporting on.\n Coding the analyzer Analyzer structure An analyzer class inherits from the DiagnosticAnalyzer class, and can be broken down into four parts:\n The diagnostic setup: Configure the diagnostic information which appear when the analyzer reports feedback back to the developer Register the action: An Action (a method) is registered, along with a specific syntax kind (e.g. MethodInvocations or NamedTypes). The action/method will then be invoked whenever Roslyn encounters a syntax of that kind while running analysis. Interrogate the syntax tree: Once Roslyn calls the action/method setup in step 2, the syntax tree/code structure is interrogated to determine if the code is relevant for the analyzer and does a diagnostic need to be trigger Trigger the diagnostic result: The final step is to trigger a diagnostic with Roslyn so the results can be reported back   Diagnostic setup The first step is to setup the diagnostic information, the information which is reported back.\nThe template makes use of a resx file to allow for localization, however in the sample code on Github as well as in the example below, the resx has been removed and the messages put directly in code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public const string DiagnosticId = \u0026#34;ADEF001\u0026#34;; private static readonly string Title = \u0026#34;Release build auto-migration\u0026#34;; private static readonly string MessageFormat = \u0026#34;It is recommended to only \u0026#34; + \u0026#34;run auto-migrations in development environments\u0026#34;; private static readonly string Description = \u0026#34;Best practice is to only run \u0026#34;+ \u0026#34;auto-migrations in development environments and not \u0026#34; + \u0026#34;in test or production environments - this should be done by a CI/CD pipeline.\u0026#34;; private const string Category = \u0026#34;Usage\u0026#34;; private static readonly DiagnosticDescriptor rule001 = new DiagnosticDescriptor(DiagnosticId, Title, MessageFormat, Category, DiagnosticSeverity.Warning, isEnabledByDefault: true, description: Description); public override ImmutableArray\u0026lt;DiagnosticDescriptor\u0026gt; SupportedDiagnostics { get { return ImmutableArray.Create(rule001); } }    Line 1: The unique identifier for the diagnostic being triggered Line 3: The title for the diagnostic Line 4: The message for the diagnostic Line 11: The category for the diagnostic (the type of analyzer - for example the default template analyzer has a category of Naming, while the above uses Usage) Line 13: Creates the actual rule using the information defined above Line 14: Exposes the rules the analyzer could potentially report (a single analyzer could trigger multiple types of diagnostic)   The diagnostic result information displayed in Visual Studio \n Register the action The next step is to register an action to be called when Roslyn finds a the type of code (syntax kind) the analyzer is interested in.\nThis is done in the overridden Initialize method.\n1 2 3 4 5 6 7  public override void Initialize(AnalysisContext context) { context.ConfigureGeneratedCodeAnalysis(GeneratedCodeAnalysisFlags.None); context.EnableConcurrentExecution(); context.RegisterSyntaxNodeAction(AnalyzeExpression, SyntaxKind.InvocationExpression); }    Line 3-4: Default configuration. For most analyzers this does not need to be changed Line 6:. This is the important line, which registers the AnalyzeExpression method to be called when Roslyn finds a piece of code which is of type InvocationExpression (a method call).  There are a large number of SyntaxKinds which can be used to trigger a call to the action method.\nThe analyzer is starting to take form, with the details of the rule defined, as well as an action registered, to be called when the syntax kind in question is found by Roslyn.\n Interrogate the syntax tree See the \u0026ldquo;Working Sample Analyzer\u0026rdquo; section in the previous post for more information regarding what this customer analyzer is doing. In short though, the analyser is looking for a very specific method called Migrate on a parent called Database (so Database.Migrate()), which should only be called in debug configuration.\nThis is where most of the analyzer work happens - the syntax node and syntax tree are interrogated to determine if the diagnostic should be triggered or not.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  private static void AnalyzeExpression(SyntaxNodeAnalysisContext context) { // We know the node is of type InvocationExpressionSyntax as the callback  // registration was only for SyntaxKind.InvocationExpression  var invocationExpr = (InvocationExpressionSyntax)context.Node; // InvocationExpr.Expression is the method name, the expression before \u0026#34;(\u0026#34;.  // In our case Database.Migrate  var memberAccessExpr = invocationExpr.Expression as MemberAccessExpressionSyntax; if (memberAccessExpr == null) return; // Get the expression. In our case, Database  var bindingExpression = memberAccessExpr.Expression as MemberBindingExpressionSyntax; if (bindingExpression == null) return; // Get the memberAccessExpr name of the expression.  // In our case, Migrate  var expressionName = bindingExpression.Name as IdentifierNameSyntax; if (expressionName == null) return; // If we reach this far, make sure its the Database property  if (expressionName.Identifier.ToString().ToLower() != \u0026#34;Database\u0026#34;.ToLower()) return; // Get the memberAccessExpr name of the expression.  // In our case, Migrate  var identifierName = memberAccessExpr.Name as IdentifierNameSyntax; if (identifierName == null) return; // check if its the specific method we want to analyze  if (identifierName.Identifier.ToString().ToLower() == \u0026#34;Migrate\u0026#34;.ToLower()) { var closestIfDirective = CodeAnalysisHelper.GetClosestIfDirective( memberAccessExpr, context.SemanticModel.SyntaxTree.GetRoot()); if (closestIfDirective != null) { if(CodeAnalysisHelper.IsValidIfDirective(closestIfDirective)) { return; } } // report the error if we found the method and it didn\u0026#39;t have the  // directives expected  var diagnostic001 = Diagnostic.Create(rule001, identifierName.GetLocation()); context.ReportDiagnostic(diagnostic001); } }   As the AnalyzeExpression method is called every time the syntax kind registered (InvocationExpression in this case) is found in code, the analyzer needs to ignore any InvocationExpression\u0026rsquo;s which are not relevant to it.\n Lines 5-35: These lines interrogate the syntax tree to make sure the InvocationExpression is the one relevant to it - Database.Migrate() Line 37-38: A helper method is called to find the closest #if directive which occurs before the Database.Migrate() call Line 41: A helper method is called to check if the #if directive contains a valid condition Line 49-50: All necessary checks are complete and the diagnostic is triggered with Roslyn  These step can be very tricky to get right, and sometimes requires a lot of trial and error and debugging to get right. Working with the syntax tree can be complex depending on what the analyzer is looking for.\nHowever the Syntax Visualizer does make it easier.\nThis is an iterative process, using the below three methods to debug, inspect the code and syntax tree, and making tweaks to the various analyzer checks:\n Use of the Syntax Visualizer Use of the unit test infrastructure for analyzers Executing the VSIX project (which starts up a new instance of Visual Studio with the analyzer installed as an extension)   The Syntax Visualizer Visual Studio comes with a built in tool window called the Syntax Visualizer, which can be found under the View -\u0026gt; Other Windows -\u0026gt; Syntax Visualizer.\nThis window will track the current active code window, and display the syntax tree of the active code, in a hierarchical structure.\nSelecting various pieces of the code will cause the highlighted item in the Syntax Visualizer to change and track the active item in code.\nThis is invaluable in determining which SyntaxKind to register (as described in the \u0026ldquo;register the action\u0026rdquo; section ), as well as how to traverse the tree to find the relevant syntax nodes to trigger the diagnostic being registered.\nThe Syntax Visualizer + the sample project created in the \u0026ldquo;creating an analyzer project\u0026rdquo; section, are key in correctly determining the logic of the analyzer. The below screen shot show the Syntax Visualizer reflecting the part of the syntax tree for the Migrate() method.\nNotice how the tree matches the checks done in the code in the above section::\nInvocationExpression -\u0026gt; MemberAccessExpression -\u0026gt; MemberBindingExpression -\u0026gt; IdentifierName\n The Syntax Visualizer used in the sample project \n Trigger the diagnostics Once the code has been interrogated and it has been determined feedback needs to be given, the final step is to trigger and register the diagnostic with Roslyn.\nThe diagnostic information and rule created in \u0026ldquo;diagnostic setup\u0026rdquo;, is reported at a specific location.\n1 2 3 4  // report the error if we found the method and it didn\u0026#39;t have the // directives expected var diagnostic001 = Diagnostic.Create(rule001, identifierName.GetLocation()); context.ReportDiagnostic(diagnostic001);    Line 3: The diagnostic is created, with a specific rule and a specific location. This location will be where the squiggle appears in code when the diagnostic is triggered. Line 4: The diagnostic is finally triggered with Roslyn.  Next steps: Coding the code fix Next up, part 3 in the series will go into detail and expand on coding the code fix for our analyzer, which will fix the code the analyzer has determined to be incorrect.\n Useful links Roslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-25T02:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-write/","title":"Roslyn Analyzer - writing the analyzer (Part 2)"},{"content":"Series introduction This is a a five part series exploring the Roslyn analyzer and code fix functionality, how to successfully write and test a custom analyzer, as well as some useful tips and tricks for writing analyzers.\nAll posts in the series:\nPart 1: Roslyn Analyzer - explained (this post)\nPart 2: Roslyn Analyzer - writing an analyzer\nPart 3: Roslyn Analyzer - writing a code fix\nPart 4: Roslyn Analyzer - testing an analyzer and code fix\nPart 5: Roslyn Analyzer - tips and tricks\nAll code in the posts, including the sample project and working analyzer and code fix are available on Github.\nWhat is Roslyn? In short, Roslyn is the .NET compiler - it consists of the compilers for C# and Visual Basic, as well as an api layer which can be leveraged to gather information about the code (analyse), and then perform actions based on this information (code fix).\n What is a Roslyn analyzer? An analyzer is a piece of code which inspects code (C# or Visual Basic) during design and compile time, and based on the results of the inspection, can raise a diagnostic result as an Error, Warning or as Information.\nAll installed and built-in analyzer(s) are run at design time (and compile time) automatically, with the diagnostic results reflecting:\n As coloured \u0026ldquo;squiggles\u0026rdquo; in code In the Error List (Ctrl+W, E) in Visual Studio In the build output   Warning highlighted in code by the green squiggle, and also appearing in the Error List \n Warning also reflecting during a build \nAn analyzer can be leveraged to inspect code for a number of issues related to (but not limited to):\n Style Quality Design Maintainability  As Roslyn exposes an API layer on top of the compiler, this layer can be used to write a custom analyzer.\nSee part 2 for more in depth details regarding writing a custom analyzer.\n What is a Roslyn analyzer code fix? Once an analyzer has inspected the code and returned an diagnostic result, the next step is apply a code change to resolve the source of the alert - a code fix.\nAn analyzer does not require a code fix, but if no code fix is provided then it is up to the developer to resolve the issue manually based on the error, warning or information message.\nIf the analyzer does have an associated code fix, it can be accessed using these steps:\n Hover or place the cursor over the squiggle, a light bulb will appear Select the small arrow next to the light bulb, or (Ctrl+.) to see available fix suggestions Hover the cursor over one of the suggestions in the list A preview of how the code will be changed when the code fix is applied is displayed Select one of the suggestions to apply the code fix   Code fix for the analyzer \nSee part 3 for more in depth details regarding writing a code fix for a custom analyzer.\n Why write an analyzer? A few reasons or use cases for writing a custom analyzer:\n To monitor and diagnose more niche coding patterns you, as a developer, constantly gets wrong or have to look up (analyzers already exist for most common best practices) As a library author (publishing a library to NuGet, for example) an analyzer can be packaged with the library (see the section below) to ensure that it is used correctly by the developer. To ensure common coding practices and styles are shared across all development teams in an organization.   Sharing a custom analyzer There are two ways to share a custom analyzer once it has been written:\n VSIX: The analyzer can be packaged as a vsix, a Visual Studio Extension. This is an executable file which can be either be shared and manually installed by the developer, or can be downloaded Visual Studio Marketplace.. NuGet package: An analyzer can be package into a NuGet package and installed into a project via a NuGet store (such as nuget.org or an internal NuGet store in the case of a company specific analyzer)   Analyzers are tricky! It can be very tricky getting the analyzer to accurately detect the relevant scenarios in code, and just as hard to fix it accurately with a code fix - syntax trees are complex. (more on this later in the series: part 2, part 3 and part 4)\nOn top of that, the developer experience for analyzers are not as slick and friendly as with other tooling. The debugging experience for analyzers are inconsistent and not always responsive, while the apis exposed to assist with testing an analyzer can be complicated and difficult to configure.\nBut all is not lost - it is possible to work with and around the above constraints (with tips from this series of posts) and still successfully create your own custom analyzer.\n A working sample analyzer The guides in part 2 and part 3 will detail how to write an analyzer package which inspects the code, and applies a code fix for the following two scenarios related to Entity Framework Core (an understanding of Entity Framework Core is not required to understand the analyzers):\n Ensure code migrations are not automatically applied in the Test or Production environment Ensure the correct appsettings.json section has been added an Entity Framework Core database connection is configured in code  Scenario 1: auto-migrations Entity Framework Core (EF) is an ORM which provides build in data-access functionality to perform operations on a database. What is important for these posts, is to know that EF provides functionality to scaffold and update the schema of the database (the tables etc) at runtime, usually at startup.\nHowever it is recommended to only run this migration on development environments, and not in test or production environments. Usually CI/CD pipeline executes the database migration in these environments (which also allows for review of the migration script before it being applied to the database)\nThe custom analyzer will look for the presence of the migration code (a .Database.Migrate method call), and ensure it is only executed when the code is run in DEBUG configuration.\nScenario 2: connection string When configuring EF, a database connection name is specified, with the actual connection string stored in the appsettings.json settings file.\n1 2  .AddDbContext\u0026lt;SampleContext\u0026gt;(x =\u0026gt; x .UseSqlite(context.Configuration.GetConnectionString(\u0026#34;SampleDatabase\u0026#34;)))   This code relies on the connection string being present in the appsettings.json file:\n1 2 3 4 5  { \u0026#34;ConnectionStrings\u0026#34;: { \u0026#34;SamplesDatabase\u0026#34;: \u0026#34;Data Source=LocalDatabase.db\u0026#34; } }   The custom analyzer will inspect the appsettings.json file and ensure the connection string is present and correct.\n Next steps: Writing the analyzer Next up, part 2 in the series will go into detail and expand on coding a custom analyzer.\n Useful links Entity Framework Core\nRoslyn repository\nSample analyzer and code fix repository\n","date":"2021-11-24T01:00:00+02:00","permalink":"https://always-developing.github.io/p/analyzer-explained/","title":"Roslyn Analyzer - explained (Part 1)"},{"content":"The challenge Consider a scenario where the requirement is to upload a file to an online provider (AWS S3, Azure Blob or a FTP site in the examples below), where the provider can be easily changed (either dynamically at runtime, or easily with minimal code changes), with the possibility additional providers being added in future.\nTo make use of dependency injection, a generic interface is created, IFileUploader, along with three implementations AWSUploader, AzureUploader and FTPUploader. The interface prescribes that the implementations provide a method to upload a file (UploadFile) and a method to get the implementation name (GetName).\nThe built in .NET dependency injection (DI) container is all one will need for almost all situations (including this situation): however this scenario can be a bit more challenging to get right - with multiple implementations of the same interface, how do you get the right implementation from the DI container?\nThe problem with .NET dependency injection container One piece of functionality the .NET DI container does not have (which is available in some other 3rd party DI/IoC containers) is the ability to add and retrieve service implementations by name.\nShort of actually implementing one of these other 3rd party containers, below are a number of different options and techniques one can use to get the correct implementation from the DI container when there are multiple implementations registered.\n     The benchmarks on the below techniques were all executed at the same time under the same conditions using BenchmarkDotNet\nEven though some some techniques performed poorly when compared to others, bear in mind that the time frame in question here is nanoseconds (a nanosecond is one billionth of a second).\nIn most scenarios, the DI technique used (if used correctly) is not going to make a massive material different to the performance of the application/service (of course there are exceptions, depending on how complicated the dependency tree is)\n   The different techniques IEnumerable   Configuration:\nThis is the simplest \u0026lsquo;out of the box\u0026rsquo; technique, with the various implementations just all added to the DI container using the same interface (lines 7-9): 1 2 3 4 5 6 7 8 9 10 11  private readonly IHost host; public EnumerableBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;EnumerableHandler\u0026gt;() .AddTransient\u0026lt;IFileUploader, AWSUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, AzureUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, FTPUploader\u0026gt;() ).Build(); }  \n  Usage:\nInject IEnumerableinto the relevant class (line 4), and then retrieve the required implementation from the IEnumerable collection (lines 11-13) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class EnumerableHandler { private readonly IEnumerable\u0026lt;IFileUploader\u0026gt; _uploaders; public EnumerableHandler(IEnumerable\u0026lt;IFileUploader\u0026gt; uploaders) { _uploaders = uploaders; } public void Execute() { var providerName = \u0026#34;aws\u0026#34;; var uploader = _uploaders.FirstOrDefault(up =\u0026gt; up .GetName().Equals(providerName)); if (uploader == null) { throw new ArgumentException($\u0026#34;No uploader with name \u0026#34; + $\u0026#34;{providerName} could be found\u0026#34;); } uploader.UploadFile(); } }  \n  Pros:\n Easy to implement Implementation can be selected/changed at runtime    Cons:\n Every implementation is instantiated (as part of IEnumerable) even if not required or used. This could be especially problematic if the implementations themselves have a number of dependencies which then need to be instantiated (this was NOT the case with the benchmarks) which could result in a negative performance impact. The logic to retrieve the implementation from IEnumerable is contained in multiple places (each class which has it injected)    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B       Factory One of the negative aspects of the IEnumerable approach, is that the logic to retrieve the correct implementation could be present in multiple places (if IEnumberable is injected into multiple classes). The Factory approach moves the logic into a separate actory class, which is then injected and is responsible for retrieving the required implementation.\n  Configuration:\nConfiguration is the same as IEnumerable, the various implementations all added to the DI container using the same interface, with one additional class added, the factory class (line 7) 1 2 3 4 5 6 7 8 9 10 11 12  private readonly IHost host; public FactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;FactoryHandler\u0026gt;() .AddTransient\u0026lt;FileUploaderFactory\u0026gt;() .AddTransient\u0026lt;IFileUploader, AWSUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, AzureUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, FTPUploader\u0026gt;() ).Build(); }  \nThe factory looks very similar to the handler from the IEnumerable approach: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class FileUploaderFactory { private readonly IEnumerable\u0026lt;IFileUploader\u0026gt; _uploaders; public FileUploaderFactory(IEnumerable\u0026lt;IFileUploader\u0026gt; uploaders) { _uploaders = uploaders; } public IFileUploader Resolve(string providerName) { var uploader = _uploaders.FirstOrDefault(up =\u0026gt; up .GetName().Equals(providerName)); if (uploader == null) { throw new ArgumentException($\u0026#34;No uploader with name \u0026#34; + $\u0026#34;{providerName} could be found\u0026#34;); } return uploader; } }  \n  Usage:\nThe factory is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class FactoryHandler { private readonly FileUploaderFactory _factory; public FactoryHandler(FileUploaderFactory factory) { _factory = factory; } public void Execute() { var providerName = \u0026#34;azure\u0026#34;; var uploader = _factory.Resolve(providerName); uploader.UploadFile(); } }  \n  Pros:\n Easy to implement Implementation can be selected/changed at runtime Retrieval logic is contained in a single place    Cons:\n Every implementation is instantiated (as part of IEnumerable) even if not required or used. This could have an impact on performance and memory usage. Slightly slower, and slightly more memory usage than the IEnumerable approach (due to the extra layer between the handler and the IEnumerable collection)    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B       Type Factory A big negative aspect of the IEnumerable and Factory approach, is that all the implementations are instantiated every time, even if not used or required. This could have big impact on performance and memory if the implementations them themselves have many dependencies (and those dependencies have dependencies and so on).\nThe next approach is extends on the Factory technique, but only instantiates the requested implementation based on naming conventions.\n  Configuration:\nSetup is the same as with the Factory method. 1 2 3 4 5 6 7 8 9 10 11 12  private readonly IHost host; public FactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;TypeFactoryHandler\u0026gt;() .AddTransient\u0026lt;FileUploaderTypeFactory\u0026gt;() .AddTransient\u0026lt;IFileUploader, AWSUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, AzureUploader\u0026gt;() .AddTransient\u0026lt;IFileUploader, FTPUploader\u0026gt;() ).Build(); }  \nThe factory in this approach, takes the requested name, finds the type based on the name (lines 11-12) and gets it from the DI container (line 20) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  public class FileUploaderTypeFactory { private readonly IServiceProvider _provider; public FileUploaderTypeFactory(IServiceProvider provider) { _provider = provider; } public IFileUploader Resolve(string providerName) { var type = Assembly.GetAssembly(typeof(FileUploaderTypeFactory)).GetType( $\u0026#34;{typeof(FileUploaderTypeFactory).Namespace}.{providerName}Uploader\u0026#34;); if (type == null) { throw new ArgumentException($\u0026#34;No uploader with name \u0026#34; + $\u0026#34;{providerName} could be found\u0026#34;); } var uploader = _provider.GetService(type); return uploader as IFileUploader; } }  \n  Usage:\nThe factory is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class TypeFactoryHandler { private readonly FileUploaderTypeFactory _factory; public TypeFactoryHandler(FileUploaderTypeFactory factory) { _factory = factory; } public void Execute() { var providerName = \u0026#34;Azure\u0026#34;; var uploader = _factory.Resolve(providerName); uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Better memory usage compared to other two approaches so far Implementation can be selected/changed at runtime Retrieval logic is contained in a single place    Cons:\n Use of reflection to convert the name to a Type does have an big impact on performance Strict naming convention has to be followed in order for the reflection logic to work correctly    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B       Delegate The next approach tries to achieve the same as the Type Factory approach - not instantiating every implementation, but using a different technique.\nIn short, a delegate is called at runtime when an implementation is requested, and using a switch statement the correct one is determined and returned.\n  Configuration:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  private readonly IHost host; public DelegateBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;DelegateHandler\u0026gt;() .AddTransient\u0026lt;DelegateResolver\u0026gt;(serviceProvider =\u0026gt; providerName =\u0026gt; { switch (providerName) { case \u0026#34;aws\u0026#34;: return serviceProvider.GetService\u0026lt;AWSUploader\u0026gt;(); case \u0026#34;azure\u0026#34;: return serviceProvider.GetService\u0026lt;AzureUploader\u0026gt;(); case \u0026#34;ftp\u0026#34;: return serviceProvider.GetService\u0026lt;FTPUploader\u0026gt;(); default: throw new ArgumentException($\u0026#34;No uploader with \u0026#34; + $\u0026#34;name {providerName} could be found\u0026#34;); } })).Build(); }  \nThe DelegateResolver is as follows 1  public delegate IFileUploader DelegateResolver(string providerName);  \n  Usage:\nThe delegate is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class DelegateHandler { private readonly DelegateResolver _resolver; public DelegateHandler(DelegateResolver resovler) { _resolver = resovler; } public void Execute() { var uploader = _resolver(\u0026#34;ftp\u0026#34;); uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Best memory usage compared to other approaches so far Implementation can be selected/changed at runtime Retrieval logic is contained in a single place    Cons:\n Slightly more complicated setup with the delegate and switch statement compared to other approaches Switch statement is hardcoded and needs to be manually maintained every time a new provider is added    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B       Type Delegate The next approach extends the Delegate technique, and uses reflection and naming conventions to get the Type dynamically.\n  Configuration:\nSetup is as follows, very similar to the Delegate approach, but instead of the switch statement, reflection is used to get the Type based on naming conventions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  private readonly IHost host; public TypeDelegateBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;TypeDelegateHandler\u0026gt;() .AddTransient\u0026lt;TypeDelegateResolver\u0026gt;(serviceProvider =\u0026gt; providerName =\u0026gt; { var type = Assembly.GetAssembly(typeof(FileUploaderTypeFactory)) .GetType($\u0026#34;{typeof(FileUploaderTypeFactory).Namespace} .{providerName}Uploader\u0026#34;, false, true); if (type == null) { throw new ArgumentException($\u0026#34;No uploader with \u0026#34; + $\u0026#34;name {providerName} could be found\u0026#34;); } var uploader = serviceProvider.GetService(type); return uploader as IFileUploader; })).Build(); }  \nThe DelegateResolver is the same as before. 1  public delegate IFileUploader DelegateResolver(string providerName);  \n  Usage:\nThe delegate is now injected into the relevant class (line 4) and is then invoked to get the requested implementation (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class TypeDelegateHandler { private readonly DelegateResolver _resolver; public TypeDelegateHandler(DelegateResolver resovler) { _resolver = resovler; } public void Execute() { var uploader = _resolver(\u0026#34;ftp\u0026#34;); uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Retrieval logic is contained in a single place No switch statement to maintain when a new provider is added    Cons:\n Use of reflection to convert the name to a Type does have a large impact on performance Strict naming convention has to be followed in order for the reflection logic to work correctly    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B       Distinct The next technique uses a wrapper to make each implementation added to the DI container unique, and hence can be retrieved uniquely.\n  Configuration:\nAdditional types are also now required to be defined and added to the DI container, IGenericUploader and GenericUploader 1 2 3 4 5 6 7 8 9 10 11 12 13 14  private readonly IHost host; public DistinctBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;DistinctHandler\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AWSUploader\u0026gt;, GenericUploader\u0026lt;AWSUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AzureUploader\u0026gt;, GenericUploader\u0026lt;AzureUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;FTPUploader\u0026gt;, GenericUploader\u0026lt;FTPUploader\u0026gt;\u0026gt;() ).Build(); }  \nIGenericUploader is defined as below. 1  public interface IGenericUploader\u0026lt;T\u0026gt; : IFileUploader where T : IFileUploader { }  \nGenericUploader is defined as below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class GenericUploader\u0026lt;T\u0026gt; : IGenericUploader\u0026lt;T\u0026gt; where T : IFileUploader { private readonly T _implementation; public GenericUploader(T implementation) { _implementation = implementation; } public string GetName() { return _implementation.GetName(); } public void UploadFile() { _implementation.UploadFile(); } }  \n  A new generic provider is defined (implementing the relevant interface) and the generic provider wraps the \u0026ldquo;true provider\u0026rdquo; implementation. As the generic implementation takes a T argument, this can be used to uniquely distinguish them and retrieve the correct implementation.\n  Usage:\nThe generic interface with the required implementation is now injected into the relevant class (line 4) and is then invoked (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13  public class DistinctHandler { private readonly IGenericUploader\u0026lt;AWSUploader\u0026gt; _uploader; public DistinctHandler(IGenericUploader\u0026lt;AWSUploader\u0026gt; uploader) { _uploader = uploader; } public void Execute() { _uploader.UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated The default DI container is doing all the retrieval work (as a unique item is being asked for), so is very efficient By far the best performing (in both time and memory usage) technique so far    Cons:\n Implementation can NOT be selected/changed at runtime Bit of a convoluted process having a wrapper interface    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B       Distinct Factory This technique extends the Distinct approach, resolving the limitation of not being able to select or change the implementation at runtime.\n  Configuration:\nSetup very similar to the Distinct setup, with the addition of the DistinctFactory (line 9) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  private readonly IHost host; public DistinctFactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddScoped\u0026lt;AWSUploader\u0026gt;() .AddScoped\u0026lt;AzureUploader\u0026gt;() .AddScoped\u0026lt;FTPUploader\u0026gt;() .AddTransient\u0026lt;DistinctFactory\u0026gt;() .AddTransient\u0026lt;DistinctFactoryHandler\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AWSUploader\u0026gt;, GenericUploader\u0026lt;AWSUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;AzureUploader\u0026gt;, GenericUploader\u0026lt;AzureUploader\u0026gt;\u0026gt;() .AddScoped\u0026lt;IGenericUploader\u0026lt;FTPUploader\u0026gt;, GenericUploader\u0026lt;FTPUploader\u0026gt;\u0026gt;() ).Build(); }  \nIGenericUploader and GenericUploader are exactly as defined in the Distinct technique.\nDistinctFactoryHandler is defined as below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class DistinctFactory { private readonly IServiceProvider _provider; public DistinctFactory(IServiceProvider provider) { _provider = provider; } public IFileUploader Resolve(string providerName) { switch (providerName) { case \u0026#34;aws\u0026#34;: return _provider.GetService(typeof( IGenericUploader\u0026lt;AWSUploader\u0026gt;)) as IFileUploader; case \u0026#34;azure\u0026#34;: return _provider.GetService(typeof( IGenericUploader\u0026lt;AzureUploader\u0026gt;)) as IFileUploader; case \u0026#34;ftp\u0026#34;: return _provider.GetService(typeof( IGenericUploader\u0026lt;FTPUploader\u0026gt;)) as IFileUploader; default: throw new ArgumentException($\u0026#34;No uploader with \u0026#34; + $\u0026#34;name {providerName} could be found\u0026#34;); } } }  \n  Usage:\nThe factory is now injected into the relevant class (line 4) and is then invoked to get the requested implementation by name (line 11) 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class DistinctFactoryHandler { private readonly DistinctFactory _distinctFactory; public DistinctFactoryHandler(DistinctFactory distinctFactory) { _distinctFactory = distinctFactory; } public void Execute() { _distinctFactory.Resolve(\u0026#34;ftp\u0026#34;).UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance    Cons:\n Switch statement is hardcoded and needs to be manually maintained every time a new provider is added Bit of a convoluted process    Performance:\n   Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B       Distinct Lookup Factory This approach gives implementations names as they are added to the DI container, keeps track of the name-implementation link, and facilitates lookup and retrieval of the correct implementation.\n  Configuration:\nThis setup is different, in that implementations of the same interface are grouped together by the AddNamedUploader extension method (line 6), and as implementations are added, they are given a name. 1 2 3 4 5 6 7 8 9 10 11 12 13  private readonly IHost host; public DistinctLookupFactoryBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddNamedUploader\u0026lt;IFileUploader\u0026gt;(builder =\u0026gt; builder .AddTransient(\u0026#34;aws\u0026#34;, typeof(AWSUploader)) .AddTransient(\u0026#34;azure\u0026#34;, typeof(AzureUploader)) .AddTransient(\u0026#34;ftp\u0026#34;, typeof(FTPUploader)) ) .AddTransient\u0026lt;DistinctLookupFactoryHandler\u0026gt;() ).Build(); }  \nThere are a number of new components here:\n AddNamedUploader extension method (line 6): this will setup base functionality required as expose the UploaderBuilder as a parameter builder, of type UploaderBuilder (line 6): this is an Action which handles keeping track of the name-implementation link. AddTransient extension method (lines 7-9): this is not the same as the normal AddTransient method on IServiceCollection, but an extension method on the builder (UploaderBuilder) which wraps the usual .NET AddTransient method.  The full definition of the classes (along with all other code) can be found on Github, here\nIn summary though, it works as follows:\n  AddNamedUploader creates an instance of UploaderTypes, which keeps track of the name and the implementation Type. UploaderTypes is added to the DI container as a singleton. 1 2 3 4 5 6 7 8 9 10 11 12  public static IServiceCollection AddNamedUploader\u0026lt;T\u0026gt;( this IServiceCollection services, Action\u0026lt;UploaderBuilder\u0026lt;T\u0026gt;\u0026gt; builder) where T : class { var uploaderType = new UploaderTypes\u0026lt;T\u0026gt;(); services.AddSingleton(uploaderType); services.AddTransient(typeof(DistinctLookupFactory\u0026lt;T\u0026gt;)); builder.Invoke(new UploaderBuilder\u0026lt;T\u0026gt;(services, uploaderType)); return services; }  \n  The AddTransient method will add records to the UploaderTypes class, as well as add the implementation to the DI container. 1 2 3 4 5 6 7 8 9 10  public static UploaderBuilder\u0026lt;T\u0026gt; AddTransient\u0026lt;T\u0026gt;( this UploaderBuilder\u0026lt;T\u0026gt; builder, string name, Type implementation) where T : class { builder.Types.Add(name, implementation); builder.Services.AddTransient(implementation); return builder; }  \n    Usage:\nThe factory is now injected into the relevant class (line 4) for a specific interface, and is then invoked to get the requested implementation by name (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class DistinctLookupFactoryHandler { private readonly DistinctLookupFactory\u0026lt;IFileUploader\u0026gt; _distinctFactory; public DistinctLookupFactoryHandler( DistinctLookupFactory\u0026lt;IFileUploader\u0026gt; distinctFactory) { _distinctFactory = distinctFactory; } public void Execute() { _distinctFactory.Resolve(\u0026#34;ftp\u0026#34;).UploadFile(); } }  \n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance No hard coded switch statement which needs to be maintained    Cons:\n The most complicated to setup, with the most moving parts    Performance:\n     Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B   DistinctLookupFactory Execute 92.96 ns 0.764 ns 0.714 ns 1.07 0.01 0.0126 80 B     Rollcall Rollcall is a library (written by me) which extends the DistinctLookupFactory approach and makes it generic so that it will function with any interface and implementation. Rollcall is available on Nuget\n  Configuration:\nThe setup is almost identical to the DistinctLookupFactory, but without the need for the factory, as this is built into the Rollcall library. 1 2 3 4 5 6 7 8 9 10 11 12 13  private readonly IHost host; public RollcallBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;RollcallHandler\u0026gt;() .AddNamedService\u0026lt;IFileUploader\u0026gt;(builder =\u0026gt; builder .AddTransient(\u0026#34;aws\u0026#34;, typeof(AWSUploader)) .AddTransient(\u0026#34;azure\u0026#34;, typeof(AzureUploader)) .AddTransient(\u0026#34;ftp\u0026#34;, typeof(FTPUploader)) ) ).Build(); }  \n  Usage:\nThe Rollcall provider/factory is now injected into the relevant class (line 4) for a specific interface, and is then invoked to get the requested implementation by name (line 12) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class RollcallHandler { private readonly IRollcallProvider\u0026lt;IFileUploader\u0026gt; _provider; public RollcallHandler(IRollcallProvider\u0026lt;IFileUploader\u0026gt; provider) { _provider = provider; } public void Execute() { var providerName = \u0026#34;aws\u0026#34;; var uploader = _provider.GetService(providerName); uploader.UploadFile(); } }   Not shown above, but one could also inject IServiceProvider and used the provided GetService extension method to get the service by name.\n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance No hard coded switch statement which needs to be maintained Works with any interface + implementation, and provides all functionality out the box    Cons:\n Slight performance overhead when compared to the non-generic method    Performance:\n     Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B   DistinctLookupFactory Execute 92.96 ns 0.764 ns 0.714 ns 1.07 0.01 0.0126 80 B   Rollcall Execute 124.52 ns 1.485 ns 1.389 ns 1.43 0.02 0.0076 48 B     Rollcall with Func Rollcall can also be used with a implementation factory, a Func\u0026lt;IServiceProvider,object\u0026gt; method. This method is called when requesting the implementation by name from the DI container. Available on NuGet.\n  Configuration:\nThe setup is a little more complicated than before, as some of the configuration needs to be done manually (instead of by the Rollcall package) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  private readonly IHost host; public RollcallFuncBenchmark() { host = Host.CreateDefaultBuilder() .ConfigureServices((context, services) =\u0026gt; services .AddTransient\u0026lt;RollcallFuncHandler\u0026gt;() .AddTransient\u0026lt;AWSUploader\u0026gt;() .AddTransient\u0026lt;AzureUploader\u0026gt;() .AddTransient\u0026lt;FTPUploader\u0026gt;() .AddNamedService\u0026lt;IFileUploader\u0026gt;(builder =\u0026gt; builder .AddTransient(\u0026#34;aws\u0026#34;, sp =\u0026gt; sp.GetService(typeof(AWSUploader))) .AddTransient(\u0026#34;azure\u0026#34;, sp =\u0026gt; sp.GetService(typeof(AzureUploader))) .AddTransient(\u0026#34;ftp\u0026#34;, sp =\u0026gt; sp.GetService(typeof(FTPUploader))) )).Build(); }  \n  Usage:\nThe usage is exactly the same with the Func\u0026lt;\u0026gt; as with the normal interface + implementation (as shown above) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class RollcallFuncHandler { private readonly IRollcallProvider\u0026lt;IFileUploader\u0026gt; _provider; public RollcallFuncHandler(IRollcallProvider\u0026lt;IFileUploader\u0026gt; provider) { _provider = provider; } public void Execute() { var providerName = \u0026#34;aws\u0026#34;; var uploader = _provider.GetService(providerName); uploader.UploadFile(); } }   Not shown above, but one could also inject IServiceProvider and used the provided GetService extension method to get the service by name.\n  Pros:\n Not all implementations are instantiated Implementation can be selected/changed at runtime Good overall performance No hard coded switch statement which needs to be maintained Works with any interface + func\u0026lt;\u0026gt;, and provides all functionality out the box    Cons:\n Slight performance overhead when compared to the non-generic method, and when compared to the interface + implementation method.    Performance:\n     Type Method Mean Error StdDev Ratio RatioSD Gen 0 Allocated     Enumerable Execute 86.99 ns 0.987 ns 0.924 ns 1.00 0.00 0.0421 264 B   Factory Execute 103.20 ns 1.324 ns 1.238 ns 1.19 0.02 0.0459 288 B   TypeFactory Execute 525.19 ns 2.624 ns 2.455 ns 6.04 0.07 0.0277 176 B   Delegate Execute 111.45 ns 1.456 ns 1.291 ns 1.28 0.02 0.0178 112 B   TypeDelegate Execute 861.84 ns 6.599 ns 5.850 ns 9.90 0.15 0.0343 216 B   Distinct Execute 50.78 ns 0.441 ns 0.413 ns 0.58 0.01 0.0038 24 B   DistinctFactory Execute 96.22 ns 1.378 ns 1.289 ns 1.11 0.02 0.0076 48 B   DistinctLookupFactory Execute 92.96 ns 0.764 ns 0.714 ns 1.07 0.01 0.0126 80 B   Rollcall Execute 124.52 ns 1.485 ns 1.389 ns 1.43 0.02 0.0076 48 B   RollcallFunc Execute 134.68 ns 1.224 ns 1.085 ns 1.55 0.02 0.0076 48 B     Conclusion There are a variety of ways to handle multiple implementations of the same interface, none of which are wrong. However, not all are suitable for every situation and using the incorrect one for the situation could result in a performance impact.\nThere are trade-offs and pros and cons to using each technique - the most performant might be the most difficult to maintain for your situation.\nTest the various methods and find which works best and is most optimal for your particular situation.\nReferences and links Rollcall Github repo\nRollcall Nuget package\n ","date":"2021-11-06T01:00:00+02:00","permalink":"https://always-developing.github.io/p/multiple-implementations/","title":"Multiple implementations of same interface - the options"},{"content":"Why learn keyboard shortcuts? So I confess I have no empirical evidence to backup the up to 20% more productive claim. That number is just made up, but with years of experience on my side, it honestly feels fairly accurate to me!\nHaving often been involved in assisting, troubleshooting and debugging code with fellow developers, it is apparent that the developers which are familiar with their IDE, and make use of the shortcuts, generally (but not always!) resolve tasks quicker and more efficiently than those that don\u0026rsquo;t.\nEvery hand reach for the mouse, every unnecessary cursor movement, every menu click is potentially a waste of time. It\u0026rsquo;s time two hands are not on the keyboard writing code. The more shortcuts a person is familiar with, the more the unnecessary time wasting can be minimized. Thus, more programming time and more productivity!\n Is there anything wrong with not making use of keyboard shortcuts? Definitely not. Does not using keyboard shortcuts make a person any less of a developer? Definitely not. Could using keyboard shortcuts make a person more productive? Definitely yes.  Visual Studio shortcuts to learn Below is a list of useful Visual Studio shortcuts I use the most often and find the more useful in my day to day development. This is by no means an exhaustive list - however I have no doubt a massive benefit can be gained by learning just a few of these.\nSome of these shortcuts are not just Visual Studio shortcuts, and also be leveraged in other applications (such as VS Code).\n       + indicates a combination of keys is to be pressed to perform the action.\nIn some cases (like the example below), the final key can be tapped to perform the action multiple times (while still holding down the initial two keys)\nE.g. Ctrl + Shift + -: Ctrl and Shift can be held down at the same time while the - key is pressed multiple times.\n  , is used to indicate a sequence of keys is to be pressed.\nE.g. Ctrl + M, O: Ctrl is held down, while M is pressed and then O is pressed.\n     View shortcuts   Ctrl + - and Ctrl + Shift + -: Navigate backwards and forwards \nMoves the cursor, backwards and forwards through the history of visited cursor locations in file(s). This is incredibly useful especially when used in conjunction with the Go to Definition / Ctrl + F12 function.\n  Ctrl + .: Quick actions and refactoring \nWhen the cursor is over a block of code, this shortcut will bring up the quick actions and refactoring (Lightbulb or screwdriver icon) menu\n  Ctrl + Spacebar: Trigger Intellisense\n  Editor shortcuts   Ctrl +  and Ctrl + : Moves cursor one word to the left or right \nGreat when used in combination with the Shift key (e.g. Ctrl + Shift + ) to highlight/select entire word(s).\n  Ctrl + Del: Delete an entire line \nWhen you dislike your code and you want it gone quickly.\n  Ctrl + M, O: Collapse to definitions \nCollapse all methods, regions, comment blocks etc in the current document.\n  Ctrl + F: Find in current file \nDefaults to search in only the current document, but this can be changed to include more documents (e.g. entire solution)\n  Ctrl + Shift + F: Find in all files \nOpens the Find in files dialog. Defaults to search the entire solution, but this can be changed to include less documents (e.g. current document)\n  Ctrl + H: Replace in current file \nDefaults to search in only the current document, but this can be changed to include more documents (e.g. entire solution)\n  Ctrl + Shift + H: Replace in all files \nOpens the Replace in files_ dialog. Defaults to replace in the entire solution, but this can be changed to include less documents (e.g. current document)\n  Ctrl + K, C and Ctrl + K, U: Comments and uncomment code selection \nComment and uncomment code selection. If no selection is made, the line of code the cursor is current on will be commented/un-commented.\n  Refactor shortcuts   'ctor', Tab, Tab: Constructor creation \nThis is a prebuilt code snippet and not really a keyboard shortcut. This will create a default parameter-less constructor for the current class\n  Ctrl + R, R: Rename \nAllows for the rename of a class, method, variable etc. as well as all usages of said code. Place the cursor on a method name, for example, press Ctrl + R, R, type in the new name and hit enter. The method name and all usages of the name have now been renamed.\n  Ctrl + R, M: Extract to method \nCreate a new method containing the selected code, and invoke the new method from the current code location. Great for code clean up.\n  Ctrl + R, G: Remove and sort usings  Performing this shortcut anywhere in a document will remove any unused usings in the file, as well as sort the remaining ones alphabetically.\n  Build shortcuts   F5: Build and start application with the debugger attached. \nBreakpoints will pause code execution, code can be stepped through, etc.\n  Ctrl + F5: Build and start application without the debugger attached. \nNo debug symbols will be loaded, so breakpoints will not be hit. Most often used when:\n Running multiple dependent services/applications in the same solution (without the need for debugging all the projects) Running benchmarking (using BenchmarkDotNet)    Code quality shortcuts  ///: Adds comments \nUsed above a method or class to create and partially auto populate the comments.\nThese comments can be used to generate an XML document file (especially useful for library authors)  Conclusion It does take a conscious effort when starting to actually slow down, lookup the shortcut to be used and force yourself to use it. But adaption happens quickly, and before you know it you\u0026rsquo;ll be using the keyboard shortcuts without even realising it.\nIt is an on-going learning process - if you find yourself performing the same time consuming action over and over in the IDE, consider investigating and learning the shortcut.\nThe list of VS2019 Keyboard shortcuts. (this mostly apply to VS2017 and VS2022 as well)\nUse shortcuts. Be more productive.\n","date":"2021-10-25T01:00:00+02:00","permalink":"https://always-developing.github.io/p/vs-keyboard-shortcuts/","title":"Useful Visual Studio keyboard shortcuts"},{"content":"What\u0026rsquo;s the issue? When working with strings in C# one can either use String (uppercase) or string (lowercase) and in both cases the code will compile and execute.\nExplicitly typed string variables can be done in either of the following ways:\nstring variable = \u0026#34;Always Developing\u0026#34;; String variable = \u0026#34;Always Developing\u0026#34;; Or when invoking string related methods, both of the following examples are valid:\nstring variable = string.Format(\u0026#34;Always Developing using {0}\u0026#34;, \u0026#34;C#\u0026#34;); String variable = String.Format(\u0026#34;Always Developing using {0}\u0026#34;, \u0026#34;Typescript\u0026#34;); Whats the difference between using String and using string? Is there a difference? Does it really matter?\nIs there a difference?   System.String is a .NET CLR (Common Runtime Library) class. This means it\u0026rsquo;s part of the core .NET environment, which sits one level below the specific language implementation.\n  string is a C# specific keyword, which is an alias for the CLR System.String type.\n  What this means is that string is just another name for System.String and they are effectively equivalent.\n     The same way int is an alias and maps to the CLR type System.Int32 and long is an alias and map to CLR type System.Int64, string is an alias and maps to the CLR type System.String\n   Deeper comparisons Variable declaration We can further confirm String and string are equivalent by comparing the IL (Intermediate Language) code generated when declaring variables using both of the types.\n     This post is primarily to compare the C# String and string types, but VB.NET examples have also been included in the comparison for completeness.\n   Take these three methods, all functionally equivalent, but declaring the variable using the different types:\npublic string GetString() { String variable = \u0026#34;string value\u0026#34;; return variable; } public string GetString() { string variable = \u0026#34;string value\u0026#34;; return variable; } Public Function GetString() As String Dim variable As String = \u0026#34;string value\u0026#34; Return variable End Function The IL code generated by all three examples is all effectively identical:\n// Methods .method public hidebysig instance string GetString () cil managed { // Method begins at RVA 0x2050  // Code size 6 (0x6)  .maxstack 8 IL_0000: ldstr \u0026#34;string value\u0026#34; IL_0005: ret } // end of method CClass::GetString  String method invocation So it\u0026rsquo;s confirmed that String and string are equivalent when declaring variables, but what about with method invocation?\nAgain, three functionally equivalent methods, but invoking the Format method differently:\npublic string StringFormat() { var insertString = \u0026#34;C#\u0026#34;; var variable = String.Format(\u0026#34;Always Developing using {0}\u0026#34;, insertString); return variable; } public string StringFormat() { var insertString = \u0026#34;C#\u0026#34;; var variable = string.Format(\u0026#34;Always Developing using {0}\u0026#34;, insertString); return variable; } Public Function StringFormat() As String Dim insertString = \u0026#34;C#\u0026#34; Dim variable = String.Format(\u0026#34;Always Developing using {0}\u0026#34;, insertString) Return variable End Function When the generated IL code is compared, in all three cases, it is equivalent:\n// Methods .method public hidebysig instance string StringFormat () cil managed { // Method begins at RVA 0x2050  // Code size 18 (0x12)  .maxstack 2 .locals init ( [0] string insertString ) IL_0000: ldstr \u0026#34;C#\u0026#34; IL_0005: stloc.0 IL_0006: ldstr \u0026#34;Always Developing using {0}\u0026#34; IL_000b: ldloc.0 IL_000c: call string [System.Private.CoreLib]System.String::Format(string, object) IL_0011: ret } // end of method CClass::StringFormat  Conclusion Use either String or string, they are effectively equivalent.\nHowever, the recommended approach is to use the C# language specific keyword string, as it works without having to include using System;\n     The recommendation method of using string comes from the official Microsoft documentation, and is included as a default style rule in Visual Studio\n        It is recommended to use implicitly type local variables (where appropriate) by using the var keyword (instead of string, in the above examples), and having the type inferred by the compiled.\nThe use of var versus explicate declaration is a personal preference, and will not effect the execution or performance of the code.\nPersonally I use var in my code: I find the code cleaner and easier to read. One can see the type being inferred by the compiler by hovering the mouse cursor over the var keyword in Visual Studio.\n   References and links Microsoft string guidance\nMicrosoft style rule\nImplicitly typed variables\nSharp lab - IL generator\n","date":"2021-10-21T01:00:00+02:00","permalink":"https://always-developing.github.io/p/string-vs-string/","title":"C# String vs string"}]